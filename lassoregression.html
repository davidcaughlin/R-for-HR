<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 53 Supervised Statistical Learning Using Lasso Regression | R for HR: An Introduction to Human Resource Analytics Using R BOOK UNDER CONSTRUCTION</title>
  <meta name="description" content="Human resource (HR) analytics is a growing area of HR manage, and the purpose of this book is to show how the R programming language can be used as tool to manage, analyze, and visualize HR data in order to derive insights and to inform decision making. [NOTE: This book is currently under construction.]" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 53 Supervised Statistical Learning Using Lasso Regression | R for HR: An Introduction to Human Resource Analytics Using R BOOK UNDER CONSTRUCTION" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://rforhr.com" />
  <meta property="og:image" content="https://rforhr.comcover.png" />
  <meta property="og:description" content="Human resource (HR) analytics is a growing area of HR manage, and the purpose of this book is to show how the R programming language can be used as tool to manage, analyze, and visualize HR data in order to derive insights and to inform decision making. [NOTE: This book is currently under construction.]" />
  <meta name="github-repo" content="davidcaughlin/R-for-HR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 53 Supervised Statistical Learning Using Lasso Regression | R for HR: An Introduction to Human Resource Analytics Using R BOOK UNDER CONSTRUCTION" />
  
  <meta name="twitter:description" content="Human resource (HR) analytics is a growing area of HR manage, and the purpose of this book is to show how the R programming language can be used as tool to manage, analyze, and visualize HR data in order to derive insights and to inform decision making. [NOTE: This book is currently under construction.]" />
  <meta name="twitter:image" content="https://rforhr.comcover.png" />

<meta name="author" content="David E. Caughlin" />


<meta name="date" content="2022-01-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="polynomialregression.html"/>
<link rel="next" href="create-portfolio.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R for HR</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#hragrowth"><i class="fa fa-check"></i><b>0.1</b> Growth of HR Analytics</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#hranalytics_skillsgap"><i class="fa fa-check"></i><b>0.2</b> Skills Gap</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#hraplc"><i class="fa fa-check"></i><b>0.3</b> Project Life Cycle Perspective</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#hranalytics_hris_overview"><i class="fa fa-check"></i><b>0.4</b> Overview of HRIS &amp; HR Analytics</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#philosophy"><i class="fa fa-check"></i><b>0.5</b> My Philosophy for This Book</a>
<ul>
<li class="chapter" data-level="0.5.1" data-path="index.html"><a href="index.html#rationalerpref"><i class="fa fa-check"></i><b>0.5.1</b> Rationale for Using R</a></li>
<li class="chapter" data-level="0.5.2" data-path="index.html"><a href="index.html#audiencepref"><i class="fa fa-check"></i><b>0.5.2</b> Audience</a></li>
</ul></li>
<li class="chapter" data-level="0.6" data-path="index.html"><a href="index.html#structurepref"><i class="fa fa-check"></i><b>0.6</b> Structure</a></li>
<li class="chapter" data-level="0.7" data-path="index.html"><a href="index.html#aboutauthor"><i class="fa fa-check"></i><b>0.7</b> About the Author</a></li>
<li class="chapter" data-level="0.8" data-path="index.html"><a href="index.html#acknowpref"><i class="fa fa-check"></i><b>0.8</b> Acknowledgements</a></li>
</ul></li>
<li class="part"><span><b>I HR Analytics Project Life Cycle</b></span></li>
<li class="chapter" data-level="1" data-path="overviewhraplc.html"><a href="overviewhraplc.html"><i class="fa fa-check"></i><b>1</b> Overview of HR Analytics Project Life Cycle</a></li>
<li class="chapter" data-level="2" data-path="questionformulation.html"><a href="questionformulation.html"><i class="fa fa-check"></i><b>2</b> Question Formulation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="questionformulation.html"><a href="questionformulation.html#adoptstrategicmindset"><i class="fa fa-check"></i><b>2.1</b> Adopting a Strategic Mindset</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="questionformulation.html"><a href="questionformulation.html#strategy"><i class="fa fa-check"></i><b>2.1.1</b> Strategy</a></li>
<li class="chapter" data-level="2.1.2" data-path="questionformulation.html"><a href="questionformulation.html#strategyformulation"><i class="fa fa-check"></i><b>2.1.2</b> Strategy Formulation</a></li>
<li class="chapter" data-level="2.1.3" data-path="questionformulation.html"><a href="questionformulation.html#strategyimplementation"><i class="fa fa-check"></i><b>2.1.3</b> Strategy Implementation</a></li>
<li class="chapter" data-level="2.1.4" data-path="questionformulation.html"><a href="questionformulation.html#strategichrm"><i class="fa fa-check"></i><b>2.1.4</b> Strategic Human Resource Management</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="questionformulation.html"><a href="questionformulation.html#defining-problems-formulating-questions"><i class="fa fa-check"></i><b>2.2</b> Defining Problems &amp; Formulating Questions</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="questionformulation.html"><a href="questionformulation.html#definingaproblem"><i class="fa fa-check"></i><b>2.2.1</b> Defining a Problem</a></li>
<li class="chapter" data-level="2.2.2" data-path="questionformulation.html"><a href="questionformulation.html#formulatingaquestion"><i class="fa fa-check"></i><b>2.2.2</b> Formulating a Question</a></li>
<li class="chapter" data-level="2.2.3" data-path="questionformulation.html"><a href="questionformulation.html#divergentconvergentthinking"><i class="fa fa-check"></i><b>2.2.3</b> Thinking Divergently &amp; Convergently</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="questionformulation.html"><a href="questionformulation.html#summary"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="dataacquisition.html"><a href="dataacquisition.html"><i class="fa fa-check"></i><b>3</b> Data Acquisition</a>
<ul>
<li class="chapter" data-level="3.1" data-path="dataacquisition.html"><a href="dataacquisition.html#employee-surveys"><i class="fa fa-check"></i><b>3.1</b> Employee Surveys</a></li>
<li class="chapter" data-level="3.2" data-path="dataacquisition.html"><a href="dataacquisition.html#rating-forms"><i class="fa fa-check"></i><b>3.2</b> Rating Forms</a></li>
<li class="chapter" data-level="3.3" data-path="dataacquisition.html"><a href="dataacquisition.html#surveillance-monitoring"><i class="fa fa-check"></i><b>3.3</b> Surveillance &amp; Monitoring</a></li>
<li class="chapter" data-level="3.4" data-path="dataacquisition.html"><a href="dataacquisition.html#database-queries"><i class="fa fa-check"></i><b>3.4</b> Database Queries</a></li>
<li class="chapter" data-level="3.5" data-path="dataacquisition.html"><a href="dataacquisition.html#scraping"><i class="fa fa-check"></i><b>3.5</b> Scraping</a></li>
<li class="chapter" data-level="3.6" data-path="dataacquisition.html"><a href="dataacquisition.html#summary-1"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="datamanagement.html"><a href="datamanagement.html"><i class="fa fa-check"></i><b>4</b> Data Management</a>
<ul>
<li class="chapter" data-level="4.1" data-path="datamanagement.html"><a href="datamanagement.html#datamanage_clean"><i class="fa fa-check"></i><b>4.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="4.2" data-path="datamanagement.html"><a href="datamanagement.html#datamanage_manipulate"><i class="fa fa-check"></i><b>4.2</b> Data Manipulation &amp; Structuring</a></li>
<li class="chapter" data-level="4.3" data-path="datamanagement.html"><a href="datamanagement.html#datamanage_tools"><i class="fa fa-check"></i><b>4.3</b> Common Data-Management Tools</a></li>
<li class="chapter" data-level="4.4" data-path="datamanagement.html"><a href="datamanagement.html#summary-2"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dataanalysis.html"><a href="dataanalysis.html"><i class="fa fa-check"></i><b>5</b> Data Analysis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="dataanalysis.html"><a href="dataanalysis.html#dataanalysis_toolstechniques"><i class="fa fa-check"></i><b>5.1</b> Tools &amp; Techniques</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="dataanalysis.html"><a href="dataanalysis.html#mathematics"><i class="fa fa-check"></i><b>5.1.1</b> Mathematics</a></li>
<li class="chapter" data-level="5.1.2" data-path="dataanalysis.html"><a href="dataanalysis.html#statistics"><i class="fa fa-check"></i><b>5.1.2</b> Statistics</a></li>
<li class="chapter" data-level="5.1.3" data-path="dataanalysis.html"><a href="dataanalysis.html#machinelearning"><i class="fa fa-check"></i><b>5.1.3</b> Machine Learning</a></li>
<li class="chapter" data-level="5.1.4" data-path="dataanalysis.html"><a href="dataanalysis.html#computationalmodelsimulation"><i class="fa fa-check"></i><b>5.1.4</b> Computational Modeling &amp; Simulations</a></li>
<li class="chapter" data-level="5.1.5" data-path="dataanalysis.html"><a href="dataanalysis.html#textqualitativeanalyses"><i class="fa fa-check"></i><b>5.1.5</b> Text Analyses &amp; Qualitative Analyses</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="dataanalysis.html"><a href="dataanalysis.html#continuum_dataanalytics"><i class="fa fa-check"></i><b>5.2</b> Continuum of Data Analytics</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="dataanalysis.html"><a href="dataanalysis.html#descriptive_analytics"><i class="fa fa-check"></i><b>5.2.1</b> Descriptive Analytics</a></li>
<li class="chapter" data-level="5.2.2" data-path="dataanalysis.html"><a href="dataanalysis.html#predictish_analytics"><i class="fa fa-check"></i><b>5.2.2</b> Predict-ish Analytics</a></li>
<li class="chapter" data-level="5.2.3" data-path="dataanalysis.html"><a href="dataanalysis.html#predictive_analytics"><i class="fa fa-check"></i><b>5.2.3</b> Predictive Analytics</a></li>
<li class="chapter" data-level="5.2.4" data-path="dataanalysis.html"><a href="dataanalysis.html#prescriptive_analytics"><i class="fa fa-check"></i><b>5.2.4</b> Prescriptive Analytics</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="dataanalysis.html"><a href="dataanalysis.html#summary-3"><i class="fa fa-check"></i><b>5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html"><i class="fa fa-check"></i><b>6</b> Data Interpretation &amp; Storytelling</a>
<ul>
<li class="chapter" data-level="6.1" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#datainterpretation"><i class="fa fa-check"></i><b>6.1</b> Data Interpretation</a></li>
<li class="chapter" data-level="6.2" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#storytelling"><i class="fa fa-check"></i><b>6.2</b> Storytelling</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#structure"><i class="fa fa-check"></i><b>6.2.1</b> Structure</a></li>
<li class="chapter" data-level="6.2.2" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#clarity-parsimony"><i class="fa fa-check"></i><b>6.2.2</b> Clarity &amp; Parsimony</a></li>
<li class="chapter" data-level="6.2.3" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#influence-persuasion"><i class="fa fa-check"></i><b>6.2.3</b> Influence &amp; Persuasion</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#storytelling_withdata"><i class="fa fa-check"></i><b>6.3</b> Storytelling with Data</a></li>
<li class="chapter" data-level="6.4" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#summary-4"><i class="fa fa-check"></i><b>6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="deploymentimplementation.html"><a href="deploymentimplementation.html"><i class="fa fa-check"></i><b>7</b> Deployment &amp; Implementation</a></li>
<li class="part"><span><b>II Introduction to R</b></span></li>
<li class="chapter" data-level="8" data-path="overviewR.html"><a href="overviewR.html"><i class="fa fa-check"></i><b>8</b> Overview of R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="8.1" data-path="overviewR.html"><a href="overviewR.html#R_overview"><i class="fa fa-check"></i><b>8.1</b> R Programming Language</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="overviewR.html"><a href="overviewR.html#R_what"><i class="fa fa-check"></i><b>8.1.1</b> What Is R?</a></li>
<li class="chapter" data-level="8.1.2" data-path="overviewR.html"><a href="overviewR.html#R_why"><i class="fa fa-check"></i><b>8.1.2</b> Why Use R?</a></li>
<li class="chapter" data-level="8.1.3" data-path="overviewR.html"><a href="overviewR.html#R_who"><i class="fa fa-check"></i><b>8.1.3</b> Who Uses R?</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="overviewR.html"><a href="overviewR.html#RStudio_overview"><i class="fa fa-check"></i><b>8.2</b> RStudio</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="overviewR.html"><a href="overviewR.html#RStudio_what"><i class="fa fa-check"></i><b>8.2.1</b> What is RStudio?</a></li>
<li class="chapter" data-level="8.2.2" data-path="overviewR.html"><a href="overviewR.html#RStudio_why"><i class="fa fa-check"></i><b>8.2.2</b> Why RStudio?</a></li>
<li class="chapter" data-level="8.2.3" data-path="overviewR.html"><a href="overviewR.html#RStudio_who"><i class="fa fa-check"></i><b>8.2.3</b> Who Uses RStudio?</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="overviewR.html"><a href="overviewR.html#packages_overview"><i class="fa fa-check"></i><b>8.3</b> Packages</a></li>
<li class="chapter" data-level="8.4" data-path="overviewR.html"><a href="overviewR.html#summary-5"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="install.html"><a href="install.html"><i class="fa fa-check"></i><b>9</b> Installing R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="9.1" data-path="install.html"><a href="install.html#videotutorial_install"><i class="fa fa-check"></i><b>9.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="9.2" data-path="install.html"><a href="install.html#installR"><i class="fa fa-check"></i><b>9.2</b> Downloading &amp; Installing R</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="install.html"><a href="install.html#installR_windows"><i class="fa fa-check"></i><b>9.2.1</b> For Windows Operation Systems</a></li>
<li class="chapter" data-level="9.2.2" data-path="install.html"><a href="install.html#installR_macos"><i class="fa fa-check"></i><b>9.2.2</b> For Mac Operating Systems</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="install.html"><a href="install.html#installRStudio"><i class="fa fa-check"></i><b>9.3</b> Downloading &amp; Installing RStudio</a></li>
<li class="chapter" data-level="9.4" data-path="install.html"><a href="install.html#summary_install"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="gettingstarted.html"><a href="gettingstarted.html"><i class="fa fa-check"></i><b>10</b> Getting Started with R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="10.1" data-path="gettingstarted.html"><a href="gettingstarted.html#orientation_gettingstarted"><i class="fa fa-check"></i><b>10.1</b> Orientation to RStudio</a></li>
<li class="chapter" data-level="10.2" data-path="gettingstarted.html"><a href="gettingstarted.html#createRscript"><i class="fa fa-check"></i><b>10.2</b> Creating &amp; Saving an R Script</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="gettingstarted.html"><a href="gettingstarted.html#createnewRscript_gettingstarted"><i class="fa fa-check"></i><b>10.2.1</b> Creating a New R Script</a></li>
<li class="chapter" data-level="10.2.2" data-path="gettingstarted.html"><a href="gettingstarted.html#usenewRscript_gettingstarted"><i class="fa fa-check"></i><b>10.2.2</b> Using an R Script</a></li>
<li class="chapter" data-level="10.2.3" data-path="gettingstarted.html"><a href="gettingstarted.html#saveRscript_gettingstarted"><i class="fa fa-check"></i><b>10.2.3</b> Saving an R Script</a></li>
<li class="chapter" data-level="10.2.4" data-path="gettingstarted.html"><a href="gettingstarted.html#openRscript_gettingstarted"><i class="fa fa-check"></i><b>10.2.4</b> Opening a Saved R Script</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="gettingstarted.html"><a href="gettingstarted.html#RStudioproject_gettingstarted"><i class="fa fa-check"></i><b>10.3</b> Creating an RStudio Project</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="gettingstarted.html"><a href="gettingstarted.html#createRStudioproject_gettingstarted"><i class="fa fa-check"></i><b>10.3.1</b> Creating a New RStudio Project</a></li>
<li class="chapter" data-level="10.3.2" data-path="gettingstarted.html"><a href="gettingstarted.html#openRStudioproject_gettingstarted"><i class="fa fa-check"></i><b>10.3.2</b> Opening an Existing RStudio Project</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="gettingstarted.html"><a href="gettingstarted.html#writtentutorials_gettingstarted"><i class="fa fa-check"></i><b>10.4</b> Orientation to Written Tutorials</a></li>
<li class="chapter" data-level="10.5" data-path="gettingstarted.html"><a href="gettingstarted.html#summary_gettingstarted"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="gentleintro.html"><a href="gentleintro.html"><i class="fa fa-check"></i><b>11</b> Basic Features and Operations of the R Language</a>
<ul>
<li class="chapter" data-level="11.1" data-path="gentleintro.html"><a href="gentleintro.html#videotutorial_gentleintro"><i class="fa fa-check"></i><b>11.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="11.2" data-path="gentleintro.html"><a href="gentleintro.html#functions_gentleintro"><i class="fa fa-check"></i><b>11.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="11.3" data-path="gentleintro.html"><a href="gentleintro.html#r_as_calculator"><i class="fa fa-check"></i><b>11.3</b> R as a Calculator</a></li>
<li class="chapter" data-level="11.4" data-path="gentleintro.html"><a href="gentleintro.html#functions"><i class="fa fa-check"></i><b>11.4</b> Functions</a></li>
<li class="chapter" data-level="11.5" data-path="gentleintro.html"><a href="gentleintro.html#packages"><i class="fa fa-check"></i><b>11.5</b> Packages</a></li>
<li class="chapter" data-level="11.6" data-path="gentleintro.html"><a href="gentleintro.html#variableassignment"><i class="fa fa-check"></i><b>11.6</b> Variable Assignment</a></li>
<li class="chapter" data-level="11.7" data-path="gentleintro.html"><a href="gentleintro.html#typesofdata"><i class="fa fa-check"></i><b>11.7</b> Types of Data</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="gentleintro.html"><a href="gentleintro.html#numeric-data"><i class="fa fa-check"></i><b>11.7.1</b> <code>numeric</code> Data</a></li>
<li class="chapter" data-level="11.7.2" data-path="gentleintro.html"><a href="gentleintro.html#character-data"><i class="fa fa-check"></i><b>11.7.2</b> <code>character</code> Data</a></li>
<li class="chapter" data-level="11.7.3" data-path="gentleintro.html"><a href="gentleintro.html#date-data"><i class="fa fa-check"></i><b>11.7.3</b> <code>Date</code> Data</a></li>
<li class="chapter" data-level="11.7.4" data-path="gentleintro.html"><a href="gentleintro.html#logical-data"><i class="fa fa-check"></i><b>11.7.4</b> <code>logical</code> Data</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="gentleintro.html"><a href="gentleintro.html#vectors"><i class="fa fa-check"></i><b>11.8</b> Vectors</a></li>
<li class="chapter" data-level="11.9" data-path="gentleintro.html"><a href="gentleintro.html#lists"><i class="fa fa-check"></i><b>11.9</b> Lists</a></li>
<li class="chapter" data-level="11.10" data-path="gentleintro.html"><a href="gentleintro.html#dataframes"><i class="fa fa-check"></i><b>11.10</b> Data Frames</a></li>
<li class="chapter" data-level="11.11" data-path="gentleintro.html"><a href="gentleintro.html#annotate"><i class="fa fa-check"></i><b>11.11</b> Annotations</a></li>
<li class="chapter" data-level="11.12" data-path="gentleintro.html"><a href="gentleintro.html#summary_gentleintro"><i class="fa fa-check"></i><b>11.12</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="setwd.html"><a href="setwd.html"><i class="fa fa-check"></i><b>12</b> Setting a Working Directory</a>
<ul>
<li class="chapter" data-level="12.1" data-path="setwd.html"><a href="setwd.html#videotutorial_setwd"><i class="fa fa-check"></i><b>12.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="12.2" data-path="setwd.html"><a href="setwd.html#functions_setwd"><i class="fa fa-check"></i><b>12.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="12.3" data-path="setwd.html"><a href="setwd.html#getwd_setwd"><i class="fa fa-check"></i><b>12.3</b> Identify the Current Working Directory</a></li>
<li class="chapter" data-level="12.4" data-path="setwd.html"><a href="setwd.html#setwd_setwd"><i class="fa fa-check"></i><b>12.4</b> Set a New Working Directory</a></li>
<li class="chapter" data-level="12.5" data-path="setwd.html"><a href="setwd.html#summary_setwd"><i class="fa fa-check"></i><b>12.5</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>III Data Acquisition &amp; Management</b></span></li>
<li class="chapter" data-level="13" data-path="read.html"><a href="read.html"><i class="fa fa-check"></i><b>13</b> Reading Data into R</a>
<ul>
<li class="chapter" data-level="13.1" data-path="read.html"><a href="read.html#conceptualoverview_read"><i class="fa fa-check"></i><b>13.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="13.2" data-path="read.html"><a href="read.html#tutorial_read"><i class="fa fa-check"></i><b>13.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="read.html"><a href="read.html#videotutorial_read"><i class="fa fa-check"></i><b>13.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="13.2.2" data-path="read.html"><a href="read.html#functions_read"><i class="fa fa-check"></i><b>13.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="13.2.3" data-path="read.html"><a href="read.html#initialsteps_read"><i class="fa fa-check"></i><b>13.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="13.2.4" data-path="read.html"><a href="read.html#readcsv"><i class="fa fa-check"></i><b>13.2.4</b> Read a .csv File</a></li>
<li class="chapter" data-level="13.2.5" data-path="read.html"><a href="read.html#readxlsx"><i class="fa fa-check"></i><b>13.2.5</b> Read a .xlsx File</a></li>
<li class="chapter" data-level="13.2.6" data-path="read.html"><a href="read.html#read_summary"><i class="fa fa-check"></i><b>13.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="read.html"><a href="read.html#read_supplement"><i class="fa fa-check"></i><b>13.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="read.html"><a href="read.html#read_supplement_functions"><i class="fa fa-check"></i><b>13.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="13.3.2" data-path="read.html"><a href="read.html#read_initsteps_supplement"><i class="fa fa-check"></i><b>13.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="13.3.3" data-path="read.html"><a href="read.html#read_additionalfunctions"><i class="fa fa-check"></i><b>13.3.3</b> Additional Functions for Reading a .csv File</a></li>
<li class="chapter" data-level="13.3.4" data-path="read.html"><a href="read.html#read_skiprows"><i class="fa fa-check"></i><b>13.3.4</b> Skip Rows of Data During Read</a></li>
<li class="chapter" data-level="13.3.5" data-path="read.html"><a href="read.html#listdatafiles"><i class="fa fa-check"></i><b>13.3.5</b> List Data File Names in Working Directory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="addnames.html"><a href="addnames.html"><i class="fa fa-check"></i><b>14</b> Removing, Adding, &amp; Changing Variable Names</a>
<ul>
<li class="chapter" data-level="14.1" data-path="addnames.html"><a href="addnames.html#conceptualoverview_addnames"><i class="fa fa-check"></i><b>14.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="14.2" data-path="addnames.html"><a href="addnames.html#tutorial_addnames"><i class="fa fa-check"></i><b>14.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="addnames.html"><a href="addnames.html#videotutorial_addnames"><i class="fa fa-check"></i><b>14.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="14.2.2" data-path="addnames.html"><a href="addnames.html#function_addnames"><i class="fa fa-check"></i><b>14.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="14.2.3" data-path="addnames.html"><a href="addnames.html#initsteps_addnames"><i class="fa fa-check"></i><b>14.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="14.2.4" data-path="addnames.html"><a href="addnames.html#remove_variablenames"><i class="fa fa-check"></i><b>14.2.4</b> Remove Variable Names from a Data Frame Object</a></li>
<li class="chapter" data-level="14.2.5" data-path="addnames.html"><a href="addnames.html#add_variablenames"><i class="fa fa-check"></i><b>14.2.5</b> Add Variable Names to a Data Frame Object</a></li>
<li class="chapter" data-level="14.2.6" data-path="addnames.html"><a href="addnames.html#change_variablenames"><i class="fa fa-check"></i><b>14.2.6</b> Change Specific Variable Names in a Data Frame Object</a></li>
<li class="chapter" data-level="14.2.7" data-path="addnames.html"><a href="addnames.html#summary_addnames"><i class="fa fa-check"></i><b>14.2.7</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="write.html"><a href="write.html"><i class="fa fa-check"></i><b>15</b> Writing Data from R</a>
<ul>
<li class="chapter" data-level="15.1" data-path="write.html"><a href="write.html#conceptualoverview_write"><i class="fa fa-check"></i><b>15.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="15.2" data-path="write.html"><a href="write.html#tutorial_write"><i class="fa fa-check"></i><b>15.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="write.html"><a href="write.html#videotutorial_write"><i class="fa fa-check"></i><b>15.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="15.2.2" data-path="write.html"><a href="write.html#functions_write"><i class="fa fa-check"></i><b>15.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="15.2.3" data-path="write.html"><a href="write.html#initialsteps_write"><i class="fa fa-check"></i><b>15.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="15.2.4" data-path="write.html"><a href="write.html#write_dataframe"><i class="fa fa-check"></i><b>15.2.4</b> Write Data Frame to Working Directory</a></li>
<li class="chapter" data-level="15.2.5" data-path="write.html"><a href="write.html#write_table"><i class="fa fa-check"></i><b>15.2.5</b> Write Table to Working Directory</a></li>
<li class="chapter" data-level="15.2.6" data-path="write.html"><a href="write.html#summary_write"><i class="fa fa-check"></i><b>15.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="arrange.html"><a href="arrange.html"><i class="fa fa-check"></i><b>16</b> Arranging (Sorting) Data</a>
<ul>
<li class="chapter" data-level="16.1" data-path="arrange.html"><a href="arrange.html#conceptualoverview_arrange"><i class="fa fa-check"></i><b>16.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="16.2" data-path="arrange.html"><a href="arrange.html#tutorial_arrange"><i class="fa fa-check"></i><b>16.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="arrange.html"><a href="arrange.html#videotutorial_arrange"><i class="fa fa-check"></i><b>16.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="16.2.2" data-path="arrange.html"><a href="arrange.html#functions_arrange"><i class="fa fa-check"></i><b>16.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="16.2.3" data-path="arrange.html"><a href="arrange.html#initsteps_arrange"><i class="fa fa-check"></i><b>16.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="16.2.4" data-path="arrange.html"><a href="arrange.html#arrangebyvalues"><i class="fa fa-check"></i><b>16.2.4</b> Arrange (Sort) Data</a></li>
<li class="chapter" data-level="16.2.5" data-path="arrange.html"><a href="arrange.html#summary_arrange"><i class="fa fa-check"></i><b>16.2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="arrange.html"><a href="arrange.html#arrange_supplement"><i class="fa fa-check"></i><b>16.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="arrange.html"><a href="arrange.html#arrange_supplement_functions"><i class="fa fa-check"></i><b>16.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="16.3.2" data-path="arrange.html"><a href="arrange.html#arrange_initsteps_supplement"><i class="fa fa-check"></i><b>16.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="16.3.3" data-path="arrange.html"><a href="arrange.html#arrange_orderfunction"><i class="fa fa-check"></i><b>16.3.3</b> <code>order</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="join.html"><a href="join.html"><i class="fa fa-check"></i><b>17</b> Joining (Merging) Data</a>
<ul>
<li class="chapter" data-level="17.1" data-path="join.html"><a href="join.html#conceptualoverview_join"><i class="fa fa-check"></i><b>17.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="join.html"><a href="join.html#review_horizontaljoin"><i class="fa fa-check"></i><b>17.1.1</b> Review of Horizontal Joins (Merges)</a></li>
<li class="chapter" data-level="17.1.2" data-path="join.html"><a href="join.html#review_verticaljoin"><i class="fa fa-check"></i><b>17.1.2</b> Review of Vertical Joins (Merges)</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="join.html"><a href="join.html#tutorial_join"><i class="fa fa-check"></i><b>17.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="join.html"><a href="join.html#videotutorial_join"><i class="fa fa-check"></i><b>17.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="17.2.2" data-path="join.html"><a href="join.html#functions-packages-introduced"><i class="fa fa-check"></i><b>17.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="17.2.3" data-path="join.html"><a href="join.html#initsteps_join"><i class="fa fa-check"></i><b>17.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="17.2.4" data-path="join.html"><a href="join.html#horizontaljoin"><i class="fa fa-check"></i><b>17.2.4</b> Horizontal Join (Merge)</a></li>
<li class="chapter" data-level="17.2.5" data-path="join.html"><a href="join.html#verticaljoin"><i class="fa fa-check"></i><b>17.2.5</b> Vertical Join (Merge)</a></li>
<li class="chapter" data-level="17.2.6" data-path="join.html"><a href="join.html#summary_join"><i class="fa fa-check"></i><b>17.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="join.html"><a href="join.html#join_supplement"><i class="fa fa-check"></i><b>17.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="join.html"><a href="join.html#supp_join_video"><i class="fa fa-check"></i><b>17.3.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="17.3.2" data-path="join.html"><a href="join.html#join_supplement_functions"><i class="fa fa-check"></i><b>17.3.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="17.3.3" data-path="join.html"><a href="join.html#join_initsteps_supplement"><i class="fa fa-check"></i><b>17.3.3</b> Initial Steps</a></li>
<li class="chapter" data-level="17.3.4" data-path="join.html"><a href="join.html#join_mergefunction"><i class="fa fa-check"></i><b>17.3.4</b> <code>merge</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="filter.html"><a href="filter.html"><i class="fa fa-check"></i><b>18</b> Filtering (Subsetting) Data</a>
<ul>
<li class="chapter" data-level="18.1" data-path="filter.html"><a href="filter.html#conceptualoverview_filter"><i class="fa fa-check"></i><b>18.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="filter.html"><a href="filter.html#review_logicaloperators"><i class="fa fa-check"></i><b>18.1.1</b> Review of Logical Operators</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="filter.html"><a href="filter.html#tutorial_filter"><i class="fa fa-check"></i><b>18.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="filter.html"><a href="filter.html#videotutorial_filter"><i class="fa fa-check"></i><b>18.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="18.2.2" data-path="filter.html"><a href="filter.html#function_filter"><i class="fa fa-check"></i><b>18.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="18.2.3" data-path="filter.html"><a href="filter.html#initsteps_filter"><i class="fa fa-check"></i><b>18.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="18.2.4" data-path="filter.html"><a href="filter.html#filter_cases"><i class="fa fa-check"></i><b>18.2.4</b> Filter Cases from Data Frame</a></li>
<li class="chapter" data-level="18.2.5" data-path="filter.html"><a href="filter.html#remove-single-variable-from-data-frame"><i class="fa fa-check"></i><b>18.2.5</b> Remove Single Variable from Data Frame</a></li>
<li class="chapter" data-level="18.2.6" data-path="filter.html"><a href="filter.html#select_multiplevariables"><i class="fa fa-check"></i><b>18.2.6</b> Select Multiple Variables from Data Frame</a></li>
<li class="chapter" data-level="18.2.7" data-path="filter.html"><a href="filter.html#remove_multiplevariables"><i class="fa fa-check"></i><b>18.2.7</b> Remove Multiple Variables from Data Frame</a></li>
<li class="chapter" data-level="18.2.8" data-path="filter.html"><a href="filter.html#summary_filter"><i class="fa fa-check"></i><b>18.2.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="filter.html"><a href="filter.html#filter_supplement"><i class="fa fa-check"></i><b>18.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="filter.html"><a href="filter.html#supp_filter_video"><i class="fa fa-check"></i><b>18.3.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="18.3.2" data-path="filter.html"><a href="filter.html#filter_supplement_functions"><i class="fa fa-check"></i><b>18.3.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="18.3.3" data-path="filter.html"><a href="filter.html#filter_initsteps_supplement"><i class="fa fa-check"></i><b>18.3.3</b> Initial Steps</a></li>
<li class="chapter" data-level="18.3.4" data-path="filter.html"><a href="filter.html#filter_subset_supplement"><i class="fa fa-check"></i><b>18.3.4</b> <code>subset</code> Function from Base R</a></li>
<li class="chapter" data-level="18.3.5" data-path="filter.html"><a href="filter.html#str_detect_supp"><i class="fa fa-check"></i><b>18.3.5</b> Filter by Pattern Contained within String</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="clean.html"><a href="clean.html"><i class="fa fa-check"></i><b>19</b> Cleaning Data</a>
<ul>
<li class="chapter" data-level="19.1" data-path="clean.html"><a href="clean.html#conceptualoverview_clean"><i class="fa fa-check"></i><b>19.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="19.2" data-path="clean.html"><a href="clean.html#tutorial_clean"><i class="fa fa-check"></i><b>19.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="clean.html"><a href="clean.html#videotutorial_clean"><i class="fa fa-check"></i><b>19.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="19.2.2" data-path="clean.html"><a href="clean.html#functions_clean"><i class="fa fa-check"></i><b>19.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="19.2.3" data-path="clean.html"><a href="clean.html#initsteps_clean"><i class="fa fa-check"></i><b>19.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="19.2.4" data-path="clean.html"><a href="clean.html#reviewdata_clean"><i class="fa fa-check"></i><b>19.2.4</b> Review Data</a></li>
<li class="chapter" data-level="19.2.5" data-path="clean.html"><a href="clean.html#cleandata_clean"><i class="fa fa-check"></i><b>19.2.5</b> Clean Data</a></li>
<li class="chapter" data-level="19.2.6" data-path="clean.html"><a href="clean.html#renamevariables_clean"><i class="fa fa-check"></i><b>19.2.6</b> Rename Variables</a></li>
<li class="chapter" data-level="19.2.7" data-path="clean.html"><a href="clean.html#otherapproaches_clean"><i class="fa fa-check"></i><b>19.2.7</b> Other Approaches to Cleaning Data</a></li>
<li class="chapter" data-level="19.2.8" data-path="clean.html"><a href="clean.html#summary_clean"><i class="fa fa-check"></i><b>19.2.8</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="manipulate.html"><a href="manipulate.html"><i class="fa fa-check"></i><b>20</b> Manipulating &amp; Restructuring Data</a>
<ul>
<li class="chapter" data-level="20.1" data-path="manipulate.html"><a href="manipulate.html#conceptualoverview_manipulate"><i class="fa fa-check"></i><b>20.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="20.2" data-path="manipulate.html"><a href="manipulate.html#tutorial_manipulate"><i class="fa fa-check"></i><b>20.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="manipulate.html"><a href="manipulate.html#videotutorial_manipulate"><i class="fa fa-check"></i><b>20.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="20.2.2" data-path="manipulate.html"><a href="manipulate.html#functions_manipulate"><i class="fa fa-check"></i><b>20.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="20.2.3" data-path="manipulate.html"><a href="manipulate.html#initsteps_manipulate"><i class="fa fa-check"></i><b>20.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="20.2.4" data-path="manipulate.html"><a href="manipulate.html#manipulate_widetolong"><i class="fa fa-check"></i><b>20.2.4</b> Wide-to-Long Format Data Manipulation</a></li>
<li class="chapter" data-level="20.2.5" data-path="manipulate.html"><a href="manipulate.html#manipulate_longtowide"><i class="fa fa-check"></i><b>20.2.5</b> Long-to-Wide Format Data Manipulation</a></li>
<li class="chapter" data-level="20.2.6" data-path="manipulate.html"><a href="manipulate.html#summary_manipulate"><i class="fa fa-check"></i><b>20.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="center.html"><a href="center.html"><i class="fa fa-check"></i><b>21</b> Centering &amp; Standardizing Variables</a>
<ul>
<li class="chapter" data-level="21.1" data-path="center.html"><a href="center.html#conceptualoverview_center"><i class="fa fa-check"></i><b>21.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="center.html"><a href="center.html#review_center"><i class="fa fa-check"></i><b>21.1.1</b> Review of Centering Variables</a></li>
<li class="chapter" data-level="21.1.2" data-path="center.html"><a href="center.html#review_standardize"><i class="fa fa-check"></i><b>21.1.2</b> Review of Standardizing Variables</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="center.html"><a href="center.html#tutorial_center"><i class="fa fa-check"></i><b>21.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="center.html"><a href="center.html#videotutorial_center"><i class="fa fa-check"></i><b>21.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="21.2.2" data-path="center.html"><a href="center.html#functions_center"><i class="fa fa-check"></i><b>21.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="21.2.3" data-path="center.html"><a href="center.html#initsteps_center"><i class="fa fa-check"></i><b>21.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="21.2.4" data-path="center.html"><a href="center.html#grandmean_center"><i class="fa fa-check"></i><b>21.2.4</b> Grand-Mean Center Variables</a></li>
<li class="chapter" data-level="21.2.5" data-path="center.html"><a href="center.html#groupmean_center"><i class="fa fa-check"></i><b>21.2.5</b> Group-Mean Center Variables</a></li>
<li class="chapter" data-level="21.2.6" data-path="center.html"><a href="center.html#standardize_center"><i class="fa fa-check"></i><b>21.2.6</b> Standardize Variables</a></li>
<li class="chapter" data-level="21.2.7" data-path="center.html"><a href="center.html#summary_center"><i class="fa fa-check"></i><b>21.2.7</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="removeobjects.html"><a href="removeobjects.html"><i class="fa fa-check"></i><b>22</b> Removing Objects from the R Environment</a>
<ul>
<li class="chapter" data-level="22.1" data-path="removeobjects.html"><a href="removeobjects.html#conceptualoverview_removeobjects"><i class="fa fa-check"></i><b>22.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="22.2" data-path="removeobjects.html"><a href="removeobjects.html#tutorial_removeobjects"><i class="fa fa-check"></i><b>22.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="removeobjects.html"><a href="removeobjects.html#videotutorial_removeobjects"><i class="fa fa-check"></i><b>22.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="22.2.2" data-path="removeobjects.html"><a href="removeobjects.html#function_removeobjects"><i class="fa fa-check"></i><b>22.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="22.2.3" data-path="removeobjects.html"><a href="removeobjects.html#initsteps_removeobjects"><i class="fa fa-check"></i><b>22.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="22.2.4" data-path="removeobjects.html"><a href="removeobjects.html#listobjects_removeobjects"><i class="fa fa-check"></i><b>22.2.4</b> List Objects in R Environment</a></li>
<li class="chapter" data-level="22.2.5" data-path="removeobjects.html"><a href="removeobjects.html#removeobjects_removeobjects"><i class="fa fa-check"></i><b>22.2.5</b> Remove Objects from R Environment</a></li>
<li class="chapter" data-level="22.2.6" data-path="removeobjects.html"><a href="removeobjects.html#summary_removeobjects"><i class="fa fa-check"></i><b>22.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Employee Demographics</b></span></li>
<li class="chapter" data-level="23" data-path="employeedemographics.html"><a href="employeedemographics.html"><i class="fa fa-check"></i><b>23</b> Introduction to Employee Demographics</a></li>
<li class="chapter" data-level="24" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>24</b> Describing Employee Demographics Using Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="24.1" data-path="descriptives.html"><a href="descriptives.html#conceptualoverview_descriptives"><i class="fa fa-check"></i><b>24.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="24.1.1" data-path="descriptives.html"><a href="descriptives.html#measurementscales"><i class="fa fa-check"></i><b>24.1.1</b> Review of Measurement Scales</a></li>
<li class="chapter" data-level="24.1.2" data-path="descriptives.html"><a href="descriptives.html#constructs_measures_measurementscales"><i class="fa fa-check"></i><b>24.1.2</b> Constructs, Measures, &amp; Measurement Scales</a></li>
<li class="chapter" data-level="24.1.3" data-path="descriptives.html"><a href="descriptives.html#typesof_descriptivestatistics"><i class="fa fa-check"></i><b>24.1.3</b> Types of Descriptive Statistics</a></li>
<li class="chapter" data-level="24.1.4" data-path="descriptives.html"><a href="descriptives.html#samplewriteup_descriptives"><i class="fa fa-check"></i><b>24.1.4</b> Sample Write-Up</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="descriptives.html"><a href="descriptives.html#tutorial_descriptives"><i class="fa fa-check"></i><b>24.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="descriptives.html"><a href="descriptives.html#videotutorial_descriptives"><i class="fa fa-check"></i><b>24.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="24.2.2" data-path="descriptives.html"><a href="descriptives.html#functions_descriptives"><i class="fa fa-check"></i><b>24.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="24.2.3" data-path="descriptives.html"><a href="descriptives.html#initsteps_descriptives"><i class="fa fa-check"></i><b>24.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="24.2.4" data-path="descriptives.html"><a href="descriptives.html#determine_measurementscale"><i class="fa fa-check"></i><b>24.2.4</b> Determine the Measurement Scale</a></li>
<li class="chapter" data-level="24.2.5" data-path="descriptives.html"><a href="descriptives.html#describe_nominal_ordinal"><i class="fa fa-check"></i><b>24.2.5</b> Describe Nominal &amp; Ordinal (Categorical) Variables</a></li>
<li class="chapter" data-level="24.2.6" data-path="descriptives.html"><a href="descriptives.html#describe_interval_ratio"><i class="fa fa-check"></i><b>24.2.6</b> Describe Interval &amp; Ratio (Continuous) Variables</a></li>
<li class="chapter" data-level="24.2.7" data-path="descriptives.html"><a href="descriptives.html#summary_descriptives"><i class="fa fa-check"></i><b>24.2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="descriptives.html"><a href="descriptives.html#descriptives_supplement"><i class="fa fa-check"></i><b>24.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="descriptives.html"><a href="descriptives.html#descriptives_supplement_functions"><i class="fa fa-check"></i><b>24.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="24.3.2" data-path="descriptives.html"><a href="descriptives.html#descriptives_initsteps_supplement"><i class="fa fa-check"></i><b>24.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="24.3.3" data-path="descriptives.html"><a href="descriptives.html#descriptives_coefficientofvariation_supplement"><i class="fa fa-check"></i><b>24.3.3</b> Compute Coefficient of Variation (CV)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="crosstabs.html"><a href="crosstabs.html"><i class="fa fa-check"></i><b>25</b> Summarizing Two or More Categorical Variables Using Cross-Tabulations</a>
<ul>
<li class="chapter" data-level="25.1" data-path="crosstabs.html"><a href="crosstabs.html#conceptualoverview_crosstabs"><i class="fa fa-check"></i><b>25.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="25.1.1" data-path="crosstabs.html"><a href="crosstabs.html#review_crosstabs"><i class="fa fa-check"></i><b>25.1.1</b> Review of Cross-Tabulation</a></li>
<li class="chapter" data-level="25.1.2" data-path="crosstabs.html"><a href="crosstabs.html#samplewriteup_crosstabs"><i class="fa fa-check"></i><b>25.1.2</b> Sample Write-Up</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="crosstabs.html"><a href="crosstabs.html#tutorial_crosstabs"><i class="fa fa-check"></i><b>25.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="crosstabs.html"><a href="crosstabs.html#videotutorial_crosstabs"><i class="fa fa-check"></i><b>25.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="25.2.2" data-path="crosstabs.html"><a href="crosstabs.html#functions_crosstabs"><i class="fa fa-check"></i><b>25.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="25.2.3" data-path="crosstabs.html"><a href="crosstabs.html#initsteps_tables"><i class="fa fa-check"></i><b>25.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="25.2.4" data-path="crosstabs.html"><a href="crosstabs.html#twoway_crosstabs"><i class="fa fa-check"></i><b>25.2.4</b> Two-Way Cross-Tabulation</a></li>
<li class="chapter" data-level="25.2.5" data-path="crosstabs.html"><a href="crosstabs.html#threeway_crosstabs"><i class="fa fa-check"></i><b>25.2.5</b> Three-Way Cross-Tabulation</a></li>
<li class="chapter" data-level="25.2.6" data-path="crosstabs.html"><a href="crosstabs.html#summary_crosstabs"><i class="fa fa-check"></i><b>25.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="pivottables.html"><a href="pivottables.html"><i class="fa fa-check"></i><b>26</b> Applying Pivot Tables to Explore Employee Demographic Data</a>
<ul>
<li class="chapter" data-level="26.1" data-path="pivottables.html"><a href="pivottables.html#conceptualoverview_pivottables"><i class="fa fa-check"></i><b>26.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="26.2" data-path="pivottables.html"><a href="pivottables.html#tutorial_pivottables"><i class="fa fa-check"></i><b>26.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="pivottables.html"><a href="pivottables.html#videotutorial_pivottables"><i class="fa fa-check"></i><b>26.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="26.2.2" data-path="pivottables.html"><a href="pivottables.html#functions_pivottables"><i class="fa fa-check"></i><b>26.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="26.2.3" data-path="pivottables.html"><a href="pivottables.html#initsteps_pivottables"><i class="fa fa-check"></i><b>26.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="26.2.4" data-path="pivottables.html"><a href="pivottables.html#create_pivottables"><i class="fa fa-check"></i><b>26.2.4</b> Create a Pivot Table</a></li>
<li class="chapter" data-level="26.2.5" data-path="pivottables.html"><a href="pivottables.html#summary_pivottables"><i class="fa fa-check"></i><b>26.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Employee Surveys</b></span></li>
<li class="chapter" data-level="27" data-path="employeesurveys.html"><a href="employeesurveys.html"><i class="fa fa-check"></i><b>27</b> Introduction to Employee Surveys</a></li>
<li class="chapter" data-level="28" data-path="aggregatesegment.html"><a href="aggregatesegment.html"><i class="fa fa-check"></i><b>28</b> Aggregating &amp; Segmenting Employee Survey Data</a>
<ul>
<li class="chapter" data-level="28.1" data-path="aggregatesegment.html"><a href="aggregatesegment.html#conceptualoverview_aggregatesegment"><i class="fa fa-check"></i><b>28.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="28.2" data-path="aggregatesegment.html"><a href="aggregatesegment.html#tutorial_aggregatesegment"><i class="fa fa-check"></i><b>28.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="28.2.1" data-path="aggregatesegment.html"><a href="aggregatesegment.html#videotutorial_aggregatesegment"><i class="fa fa-check"></i><b>28.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="28.2.2" data-path="aggregatesegment.html"><a href="aggregatesegment.html#functions_aggregatesegment"><i class="fa fa-check"></i><b>28.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="28.2.3" data-path="aggregatesegment.html"><a href="aggregatesegment.html#initsteps_aggregatesegment"><i class="fa fa-check"></i><b>28.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="28.2.4" data-path="aggregatesegment.html"><a href="aggregatesegment.html#counts_bygroup"><i class="fa fa-check"></i><b>28.2.4</b> Counts By Group</a></li>
<li class="chapter" data-level="28.2.5" data-path="aggregatesegment.html"><a href="aggregatesegment.html#centraldispersion_bygroup"><i class="fa fa-check"></i><b>28.2.5</b> Measures of Central Tendency and Dispersion By Group</a></li>
<li class="chapter" data-level="28.2.6" data-path="aggregatesegment.html"><a href="aggregatesegment.html#addaggregatedvariable"><i class="fa fa-check"></i><b>28.2.6</b> Add Variable to Data Frame Containing Aggregated Values</a></li>
<li class="chapter" data-level="28.2.7" data-path="aggregatesegment.html"><a href="aggregatesegment.html#visualize_bygroup"><i class="fa fa-check"></i><b>28.2.7</b> Visualize Data By Group</a></li>
<li class="chapter" data-level="28.2.8" data-path="aggregatesegment.html"><a href="aggregatesegment.html#summary_aggregatesegment"><i class="fa fa-check"></i><b>28.2.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_supplement"><i class="fa fa-check"></i><b>28.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="28.3.1" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_supplement_functions"><i class="fa fa-check"></i><b>28.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="28.3.2" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_initsteps_supplement"><i class="fa fa-check"></i><b>28.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="28.3.3" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_describeby_supplement"><i class="fa fa-check"></i><b>28.3.3</b> <code>describeBy</code> Function from <code>psych</code> Package</a></li>
<li class="chapter" data-level="28.3.4" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_aggregate_supplement"><i class="fa fa-check"></i><b>28.3.4</b> <code>aggregate</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html"><i class="fa fa-check"></i><b>29</b> Estimating Internal Consistency Reliability Using Cronbachs alpha</a>
<ul>
<li class="chapter" data-level="29.1" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#conceptualoverview_cronbachsalpha"><i class="fa fa-check"></i><b>29.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="29.2" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#tutorial_cronbachsalpha"><i class="fa fa-check"></i><b>29.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#videotutorial_cronbachsalpha"><i class="fa fa-check"></i><b>29.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="29.2.2" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#functions_cronbachsalpha"><i class="fa fa-check"></i><b>29.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="29.2.3" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#initsteps_cronbachsalpha"><i class="fa fa-check"></i><b>29.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="29.2.4" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#cronbachsalpha_alpha"><i class="fa fa-check"></i><b>29.2.4</b> Compute Cronbachs alpha</a></li>
<li class="chapter" data-level="29.2.5" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#summary_cronbachsalpha"><i class="fa fa-check"></i><b>29.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="compositevariable.html"><a href="compositevariable.html"><i class="fa fa-check"></i><b>30</b> Creating a Composite Variable Based on a Multi-Item Measure</a>
<ul>
<li class="chapter" data-level="30.1" data-path="compositevariable.html"><a href="compositevariable.html#conceptualoverview_compositevariable"><i class="fa fa-check"></i><b>30.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="30.2" data-path="compositevariable.html"><a href="compositevariable.html#tutorial_compositevariable"><i class="fa fa-check"></i><b>30.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="compositevariable.html"><a href="compositevariable.html#videotutorial_compositevariable"><i class="fa fa-check"></i><b>30.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="30.2.2" data-path="compositevariable.html"><a href="compositevariable.html#functions_compositevariable"><i class="fa fa-check"></i><b>30.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="30.2.3" data-path="compositevariable.html"><a href="compositevariable.html#initsteps_compositevariable"><i class="fa fa-check"></i><b>30.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="30.2.4" data-path="compositevariable.html"><a href="compositevariable.html#compositevariable_cronbachsalpha"><i class="fa fa-check"></i><b>30.2.4</b> Compute Cronbachs alpha</a></li>
<li class="chapter" data-level="30.2.5" data-path="compositevariable.html"><a href="compositevariable.html#compositevariable_composite"><i class="fa fa-check"></i><b>30.2.5</b> Create a Composite Variable</a></li>
<li class="chapter" data-level="30.2.6" data-path="compositevariable.html"><a href="compositevariable.html#summary_compositevariable"><i class="fa fa-check"></i><b>30.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VI Employee Training</b></span></li>
<li class="chapter" data-level="31" data-path="employeetraining.html"><a href="employeetraining.html"><i class="fa fa-check"></i><b>31</b> Introduction to Employee Training</a>
<ul>
<li class="chapter" data-level="31.1" data-path="employeetraining.html"><a href="employeetraining.html#trainingevaluation_employeetraining"><i class="fa fa-check"></i><b>31.1</b> Training Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="pretestposttest.html"><a href="pretestposttest.html"><i class="fa fa-check"></i><b>32</b> Evaluating a Pre-Test/Post-Test without Control Group Design Using Paired-Samples <em>t</em>-test</a>
<ul>
<li class="chapter" data-level="32.1" data-path="pretestposttest.html"><a href="pretestposttest.html#conceptualoverview_pretestposttest_psttest"><i class="fa fa-check"></i><b>32.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="32.1.1" data-path="pretestposttest.html"><a href="pretestposttest.html#review_pretestposttest"><i class="fa fa-check"></i><b>32.1.1</b> Review of Pre-Test/Post-Test without Control Group Design</a></li>
<li class="chapter" data-level="32.1.2" data-path="pretestposttest.html"><a href="pretestposttest.html#review_psttest"><i class="fa fa-check"></i><b>32.1.2</b> Review of Paired-Samples <em>t</em>-test</a></li>
</ul></li>
<li class="chapter" data-level="32.2" data-path="pretestposttest.html"><a href="pretestposttest.html#tutorial_psttest"><i class="fa fa-check"></i><b>32.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="32.2.1" data-path="pretestposttest.html"><a href="pretestposttest.html#videotutorial_psttest"><i class="fa fa-check"></i><b>32.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="32.2.2" data-path="pretestposttest.html"><a href="pretestposttest.html#functions_psttest"><i class="fa fa-check"></i><b>32.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="32.2.3" data-path="pretestposttest.html"><a href="pretestposttest.html#initsteps_psttest"><i class="fa fa-check"></i><b>32.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="32.2.4" data-path="pretestposttest.html"><a href="pretestposttest.html#estimate_psttest"><i class="fa fa-check"></i><b>32.2.4</b> Estimate Paired-Samples <em>t</em>-test</a></li>
<li class="chapter" data-level="32.2.5" data-path="pretestposttest.html"><a href="pretestposttest.html#barchart_psttest"><i class="fa fa-check"></i><b>32.2.5</b> Visualize Results Using Bar Chart</a></li>
<li class="chapter" data-level="32.2.6" data-path="pretestposttest.html"><a href="pretestposttest.html#summary_psttest"><i class="fa fa-check"></i><b>32.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="pretestposttest.html"><a href="pretestposttest.html#psttest_supplement"><i class="fa fa-check"></i><b>32.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="32.3.1" data-path="pretestposttest.html"><a href="pretestposttest.html#psttest_supplement_functions"><i class="fa fa-check"></i><b>32.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="32.3.2" data-path="pretestposttest.html"><a href="pretestposttest.html#psttest_initsteps_supplement"><i class="fa fa-check"></i><b>32.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="32.3.3" data-path="pretestposttest.html"><a href="pretestposttest.html#t.test_function_psttest"><i class="fa fa-check"></i><b>32.3.3</b> <code>t.test</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="33" data-path="posttestonly.html"><a href="posttestonly.html"><i class="fa fa-check"></i><b>33</b> Evaluating a Post-Test-Only with Control Group Design Using Independent-Samples <em>t</em>-test</a>
<ul>
<li class="chapter" data-level="33.1" data-path="posttestonly.html"><a href="posttestonly.html#conceptualoverview_posttestonly_isttest"><i class="fa fa-check"></i><b>33.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="33.1.1" data-path="posttestonly.html"><a href="posttestonly.html#review_posttestonly"><i class="fa fa-check"></i><b>33.1.1</b> Review of Post-Test-Only with Control Group Design</a></li>
<li class="chapter" data-level="33.1.2" data-path="posttestonly.html"><a href="posttestonly.html#review_isttest"><i class="fa fa-check"></i><b>33.1.2</b> Review of Independent-Samples <em>t</em>-test</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="posttestonly.html"><a href="posttestonly.html#tutorial_isttest"><i class="fa fa-check"></i><b>33.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="33.2.1" data-path="posttestonly.html"><a href="posttestonly.html#videotutorial_isttest"><i class="fa fa-check"></i><b>33.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="33.2.2" data-path="posttestonly.html"><a href="posttestonly.html#functions_isttest"><i class="fa fa-check"></i><b>33.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="33.2.3" data-path="posttestonly.html"><a href="posttestonly.html#initsteps_isttest"><i class="fa fa-check"></i><b>33.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="33.2.4" data-path="posttestonly.html"><a href="posttestonly.html#estimate_isttest"><i class="fa fa-check"></i><b>33.2.4</b> Estimate Independent-Samples <em>t</em>-test</a></li>
<li class="chapter" data-level="33.2.5" data-path="posttestonly.html"><a href="posttestonly.html#barchart_isttest"><i class="fa fa-check"></i><b>33.2.5</b> Visualize Results Using Bar Chart</a></li>
<li class="chapter" data-level="33.2.6" data-path="posttestonly.html"><a href="posttestonly.html#summary_isttest"><i class="fa fa-check"></i><b>33.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="33.3" data-path="posttestonly.html"><a href="posttestonly.html#isttest_supplement"><i class="fa fa-check"></i><b>33.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="posttestonly.html"><a href="posttestonly.html#isttest_supplement_functions"><i class="fa fa-check"></i><b>33.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="33.3.2" data-path="posttestonly.html"><a href="posttestonly.html#isttest_initsteps_supplement"><i class="fa fa-check"></i><b>33.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="33.3.3" data-path="posttestonly.html"><a href="posttestonly.html#t.test_function_isttest"><i class="fa fa-check"></i><b>33.3.3</b> <code>t.test</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="34" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html"><i class="fa fa-check"></i><b>34</b> Evaluating a Post-Test-Only with Two Comparison Groups Design Using One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="34.1" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#conceptualoverview_posttestonly_threegroups_onewayanova"><i class="fa fa-check"></i><b>34.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="34.1.1" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#review_posttestonly_threegroups"><i class="fa fa-check"></i><b>34.1.1</b> Review of Post-Test-Only with Two Comparison Groups Design</a></li>
<li class="chapter" data-level="34.1.2" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#review_onewayanova"><i class="fa fa-check"></i><b>34.1.2</b> Review of One-Way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="34.2" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#tutorial_onewayanova"><i class="fa fa-check"></i><b>34.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="34.2.1" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#videotutorial_onewayanova"><i class="fa fa-check"></i><b>34.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="34.2.2" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#functions_onewayanova"><i class="fa fa-check"></i><b>34.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="34.2.3" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#initsteps_onewayanova"><i class="fa fa-check"></i><b>34.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="34.2.4" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#teststatisticalassumptions_onewayanova"><i class="fa fa-check"></i><b>34.2.4</b> Test Statistical Assumptions</a></li>
<li class="chapter" data-level="34.2.5" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#estimate_onewayanova"><i class="fa fa-check"></i><b>34.2.5</b> Estimate One-Way ANOVA</a></li>
<li class="chapter" data-level="34.2.6" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#barchart_onewayanova"><i class="fa fa-check"></i><b>34.2.6</b> Visualize Results Using Bar Chart</a></li>
<li class="chapter" data-level="34.2.7" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#summary_onewayanova"><i class="fa fa-check"></i><b>34.2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="34.3" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#onewayanova_supplement"><i class="fa fa-check"></i><b>34.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="34.3.1" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#onewayanova_supplement_functions"><i class="fa fa-check"></i><b>34.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="34.3.2" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#onewayanova_initsteps_supplement"><i class="fa fa-check"></i><b>34.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="34.3.3" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#aov_function_onewayanova"><i class="fa fa-check"></i><b>34.3.3</b> <code>aov</code> Function from Base R</a></li>
<li class="chapter" data-level="34.3.4" data-path="posttestonly-threegroups.html"><a href="posttestonly-threegroups.html#apatable_onewayanova"><i class="fa fa-check"></i><b>34.3.4</b> APA-Style Table of Results</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VII Employee Selection</b></span></li>
<li class="chapter" data-level="35" data-path="selection.html"><a href="selection.html"><i class="fa fa-check"></i><b>35</b> Introduction to Employee Selection</a></li>
<li class="chapter" data-level="36" data-path="disparateimpact.html"><a href="disparateimpact.html"><i class="fa fa-check"></i><b>36</b> Investigating Disparate Impact</a>
<ul>
<li class="chapter" data-level="36.1" data-path="disparateimpact.html"><a href="disparateimpact.html#conceptualoverview_disparateimpact"><i class="fa fa-check"></i><b>36.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="36.2" data-path="disparateimpact.html"><a href="disparateimpact.html#tutorial_disparateimpact"><i class="fa fa-check"></i><b>36.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="36.2.1" data-path="disparateimpact.html"><a href="disparateimpact.html#videotutorial_disparateimpact"><i class="fa fa-check"></i><b>36.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="36.2.2" data-path="disparateimpact.html"><a href="disparateimpact.html#functions_disparateimpact"><i class="fa fa-check"></i><b>36.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="36.2.3" data-path="disparateimpact.html"><a href="disparateimpact.html#initsteps_disparateimpact"><i class="fa fa-check"></i><b>36.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="36.2.4" data-path="disparateimpact.html"><a href="disparateimpact.html#fourfifthsrule"><i class="fa fa-check"></i><b>36.2.4</b> 4/5ths Rule</a></li>
<li class="chapter" data-level="36.2.5" data-path="disparateimpact.html"><a href="disparateimpact.html#chisquaretest_disparateimpact"><i class="fa fa-check"></i><b>36.2.5</b> chi-square (<span class="math inline">\(\chi^2\)</span>) Test of Independence</a></li>
<li class="chapter" data-level="36.2.6" data-path="disparateimpact.html"><a href="disparateimpact.html#fisherexacttest"><i class="fa fa-check"></i><b>36.2.6</b> Fisher Exact Test</a></li>
<li class="chapter" data-level="36.2.7" data-path="disparateimpact.html"><a href="disparateimpact.html#zdifference_test_disparateimpact"><i class="fa fa-check"></i><b>36.2.7</b> <span class="math inline">\(Z_{D}\)</span> Test</a></li>
<li class="chapter" data-level="36.2.8" data-path="disparateimpact.html"><a href="disparateimpact.html#z_impactratiotest"><i class="fa fa-check"></i><b>36.2.8</b> <span class="math inline">\(Z_{IR}\)</span> Test</a></li>
<li class="chapter" data-level="36.2.9" data-path="disparateimpact.html"><a href="disparateimpact.html#summary_disparatetreatment"><i class="fa fa-check"></i><b>36.2.9</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="37" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html"><i class="fa fa-check"></i><b>37</b> Estimating Criterion-Related Validity of a Selection Tool Using Correlation</a>
<ul>
<li class="chapter" data-level="37.1" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#conceptualoverview_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="37.1.1" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#review_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.1.1</b> Review of Criterion-Related Validity</a></li>
<li class="chapter" data-level="37.1.2" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#review_correlation"><i class="fa fa-check"></i><b>37.1.2</b> Review of Correlation</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#tutorial_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="37.2.1" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#videotutorial_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="37.2.2" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#functions_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="37.2.3" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#initsteps_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="37.2.4" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#scatterplot_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.4</b> Visualize Association Using a Scatter Plot</a></li>
<li class="chapter" data-level="37.2.5" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#estimate_correlation"><i class="fa fa-check"></i><b>37.2.5</b> Estimate Correlation</a></li>
<li class="chapter" data-level="37.2.6" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#summary_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="37.3" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#criterionrelatedvalidity_supplement"><i class="fa fa-check"></i><b>37.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="37.3.1" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#criterionrelatedvalidity_supplement_functions"><i class="fa fa-check"></i><b>37.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="37.3.2" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#criterionrelatedvalidity_initsteps_supplement"><i class="fa fa-check"></i><b>37.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="37.3.3" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#cor_function"><i class="fa fa-check"></i><b>37.3.3</b> <code>cor</code> Function from Base R</a></li>
<li class="chapter" data-level="37.3.4" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#cortest_function"><i class="fa fa-check"></i><b>37.3.4</b> <code>cor.test</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="38" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html"><i class="fa fa-check"></i><b>38</b> Predicting Criterion Scores Based on Selection Tool Scores Using Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="38.1" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#conceptualoverview_predictingcriterionscores"><i class="fa fa-check"></i><b>38.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="38.1.1" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#review_slr"><i class="fa fa-check"></i><b>38.1.1</b> Review of Simple Linear Regression</a></li>
<li class="chapter" data-level="38.1.2" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#review_prediction_slr"><i class="fa fa-check"></i><b>38.1.2</b> Predicting Future Criterion Scores Using Simple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="38.2" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#tutorial_predictingcriterionscores"><i class="fa fa-check"></i><b>38.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="38.2.1" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#videotutorial_predictingcriterionscores"><i class="fa fa-check"></i><b>38.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="38.2.2" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#functions_predictingcriterionscores"><i class="fa fa-check"></i><b>38.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="38.2.3" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#initsteps_slr"><i class="fa fa-check"></i><b>38.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="38.2.4" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#estimate_slr"><i class="fa fa-check"></i><b>38.2.4</b> Estimate Simple Linear Regression Model</a></li>
<li class="chapter" data-level="38.2.5" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predictingcriterionscores_slr"><i class="fa fa-check"></i><b>38.2.5</b> Predict Criterion Scores</a></li>
<li class="chapter" data-level="38.2.6" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#summary_predictingcriterionscores"><i class="fa fa-check"></i><b>38.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="38.3" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predictingcriterionscores_supplement"><i class="fa fa-check"></i><b>38.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="38.3.1" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predictingcriterionscores_supplement_functions"><i class="fa fa-check"></i><b>38.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="38.3.2" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predictingcriterionscores_initsteps_supplement"><i class="fa fa-check"></i><b>38.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="38.3.3" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#lm_function_slr"><i class="fa fa-check"></i><b>38.3.3</b> <code>lm</code> Function from Base R</a></li>
<li class="chapter" data-level="38.3.4" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predict_function_slr"><i class="fa fa-check"></i><b>38.3.4</b> <code>predict</code> Function from Base R</a></li>
<li class="chapter" data-level="38.3.5" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#apatable_slr"><i class="fa fa-check"></i><b>38.3.5</b> APA-Style Results Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="39" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html"><i class="fa fa-check"></i><b>39</b> Estimating Incremental Validity of a Selection Tool Using Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="39.1" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#conceptualoverview_incrementalvalidity"><i class="fa fa-check"></i><b>39.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="39.1.1" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#review_mlr"><i class="fa fa-check"></i><b>39.1.1</b> Review of Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="39.2" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#tutorial_incrementalvalidity"><i class="fa fa-check"></i><b>39.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="39.2.1" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#videotutorial_incrementalvalidity"><i class="fa fa-check"></i><b>39.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="39.2.2" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#function_incrementalvalidity"><i class="fa fa-check"></i><b>39.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="39.2.3" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#initsteps_mlr"><i class="fa fa-check"></i><b>39.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="39.2.4" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#estimate_mlr"><i class="fa fa-check"></i><b>39.2.4</b> Estimate Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="39.2.5" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#summary_incrementalvalidity"><i class="fa fa-check"></i><b>39.2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="39.3" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#incrementalvalidity_supplement"><i class="fa fa-check"></i><b>39.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="39.3.1" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#incrementalvalidity_supplement_functions"><i class="fa fa-check"></i><b>39.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="39.3.2" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#incrementalvalidity_initsteps_supplement"><i class="fa fa-check"></i><b>39.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="39.3.3" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#lm_function_mlr"><i class="fa fa-check"></i><b>39.3.3</b> <code>lm</code> Function from Base R</a></li>
<li class="chapter" data-level="39.3.4" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#apatable_mlr"><i class="fa fa-check"></i><b>39.3.4</b> APA-Style Results Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="40" data-path="compensatory.html"><a href="compensatory.html"><i class="fa fa-check"></i><b>40</b> Applying a Compensatory Approach to Selection Decisions Using Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="40.1" data-path="compensatory.html"><a href="compensatory.html#conceptualoverview_compensatory"><i class="fa fa-check"></i><b>40.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="40.1.1" data-path="compensatory.html"><a href="compensatory.html#review_compensatory_mlr"><i class="fa fa-check"></i><b>40.1.1</b> Review of Multiple Linear Regression</a></li>
<li class="chapter" data-level="40.1.2" data-path="compensatory.html"><a href="compensatory.html#review_compensatory"><i class="fa fa-check"></i><b>40.1.2</b> Review of Compensatory Approach</a></li>
</ul></li>
<li class="chapter" data-level="40.2" data-path="compensatory.html"><a href="compensatory.html#tutorial_compensatory"><i class="fa fa-check"></i><b>40.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="40.2.1" data-path="compensatory.html"><a href="compensatory.html#videotutorial_compensatory"><i class="fa fa-check"></i><b>40.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="40.2.2" data-path="compensatory.html"><a href="compensatory.html#function_compensatory"><i class="fa fa-check"></i><b>40.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="40.2.3" data-path="compensatory.html"><a href="compensatory.html#initsteps_compensatory"><i class="fa fa-check"></i><b>40.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="40.2.4" data-path="compensatory.html"><a href="compensatory.html#estimate_compensatory"><i class="fa fa-check"></i><b>40.2.4</b> Estimate Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="40.2.5" data-path="compensatory.html"><a href="compensatory.html#predictcriterionscores_compensatory"><i class="fa fa-check"></i><b>40.2.5</b> Predict Criterion Scores</a></li>
<li class="chapter" data-level="40.2.6" data-path="compensatory.html"><a href="compensatory.html#summary_compensatory"><i class="fa fa-check"></i><b>40.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="compensatory.html"><a href="compensatory.html#compensatory_supplement"><i class="fa fa-check"></i><b>40.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="40.3.1" data-path="compensatory.html"><a href="compensatory.html#compensatory_supplement_functions"><i class="fa fa-check"></i><b>40.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="40.3.2" data-path="compensatory.html"><a href="compensatory.html#compensatory_initsteps_supplement"><i class="fa fa-check"></i><b>40.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="40.3.3" data-path="compensatory.html"><a href="compensatory.html#lm_predict_functions_compensatory"><i class="fa fa-check"></i><b>40.3.3</b> <code>lm</code> &amp; <code>predict</code> Functions from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="41" data-path="multiplecutoff.html"><a href="multiplecutoff.html"><i class="fa fa-check"></i><b>41</b> Applying a Noncompensatory Approach to Selection Decisions Using Angoff Method</a>
<ul>
<li class="chapter" data-level="41.1" data-path="multiplecutoff.html"><a href="multiplecutoff.html#conceptualoverview_multiplecutoff"><i class="fa fa-check"></i><b>41.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="41.1.1" data-path="multiplecutoff.html"><a href="multiplecutoff.html#review_multiplecutoff"><i class="fa fa-check"></i><b>41.1.1</b> Review of Noncompensatory Approach</a></li>
</ul></li>
<li class="chapter" data-level="41.2" data-path="multiplecutoff.html"><a href="multiplecutoff.html#tutorial_multiplecutoff"><i class="fa fa-check"></i><b>41.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="41.2.1" data-path="multiplecutoff.html"><a href="multiplecutoff.html#function_multiplecutoff"><i class="fa fa-check"></i><b>41.2.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="41.2.2" data-path="multiplecutoff.html"><a href="multiplecutoff.html#initsteps_multiplecutoff"><i class="fa fa-check"></i><b>41.2.2</b> Initial Steps</a></li>
<li class="chapter" data-level="41.2.3" data-path="multiplecutoff.html"><a href="multiplecutoff.html#createcutoffscores_multiplecutoff"><i class="fa fa-check"></i><b>41.2.3</b> Create Cutoff Scores</a></li>
<li class="chapter" data-level="41.2.4" data-path="multiplecutoff.html"><a href="multiplecutoff.html#applycutoffscores_multiplecutoff"><i class="fa fa-check"></i><b>41.2.4</b> Apply Cutoff Scores to Make Selection Decisions</a></li>
<li class="chapter" data-level="41.2.5" data-path="multiplecutoff.html"><a href="multiplecutoff.html#summary_multiplecutoff"><i class="fa fa-check"></i><b>41.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="differentialprediction.html"><a href="differentialprediction.html"><i class="fa fa-check"></i><b>42</b> Testing for Differential Prediction Using Moderated Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="42.1" data-path="differentialprediction.html"><a href="differentialprediction.html#conceptualoverview_differentialprediction"><i class="fa fa-check"></i><b>42.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="42.1.1" data-path="differentialprediction.html"><a href="differentialprediction.html#review_mmlr"><i class="fa fa-check"></i><b>42.1.1</b> Review of Moderated Multiple Linear Regression</a></li>
<li class="chapter" data-level="42.1.2" data-path="differentialprediction.html"><a href="differentialprediction.html#review_differentialprediction"><i class="fa fa-check"></i><b>42.1.2</b> Review of Differential Prediction</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="differentialprediction.html"><a href="differentialprediction.html#tutorial_differentialprediction"><i class="fa fa-check"></i><b>42.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="42.2.1" data-path="differentialprediction.html"><a href="differentialprediction.html#videotutorial_differentialprediction"><i class="fa fa-check"></i><b>42.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="42.2.2" data-path="differentialprediction.html"><a href="differentialprediction.html#function_mmlr"><i class="fa fa-check"></i><b>42.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="42.2.3" data-path="differentialprediction.html"><a href="differentialprediction.html#initsteps_mmlr"><i class="fa fa-check"></i><b>42.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="42.2.4" data-path="differentialprediction.html"><a href="differentialprediction.html#center_mmlr"><i class="fa fa-check"></i><b>42.2.4</b> Grand-Mean Center Continuous Predictor Variables</a></li>
<li class="chapter" data-level="42.2.5" data-path="differentialprediction.html"><a href="differentialprediction.html#estimate_mmlr"><i class="fa fa-check"></i><b>42.2.5</b> Estimate Moderated Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="42.2.6" data-path="differentialprediction.html"><a href="differentialprediction.html#summary_differentialprediction"><i class="fa fa-check"></i><b>42.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="differentialprediction.html"><a href="differentialprediction.html#differentialprediction_supplement"><i class="fa fa-check"></i><b>42.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="42.3.1" data-path="differentialprediction.html"><a href="differentialprediction.html#differentialprediction_supplement_functions"><i class="fa fa-check"></i><b>42.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="42.3.2" data-path="differentialprediction.html"><a href="differentialprediction.html#differentialprediction_initsteps_supplement"><i class="fa fa-check"></i><b>42.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="42.3.3" data-path="differentialprediction.html"><a href="differentialprediction.html#lm_function_mmlr"><i class="fa fa-check"></i><b>42.3.3</b> <code>lm</code> Function from Base R</a></li>
<li class="chapter" data-level="42.3.4" data-path="differentialprediction.html"><a href="differentialprediction.html#apatable_mmlr"><i class="fa fa-check"></i><b>42.3.4</b> APA-Style Results Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="43" data-path="crossvalidation.html"><a href="crossvalidation.html"><i class="fa fa-check"></i><b>43</b> Statistically &amp; Empirically Cross-Validating a Selection Tool</a>
<ul>
<li class="chapter" data-level="43.1" data-path="crossvalidation.html"><a href="crossvalidation.html#conceptualoverview_crossvalidation"><i class="fa fa-check"></i><b>43.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="43.1.1" data-path="crossvalidation.html"><a href="crossvalidation.html#review_statistical_crossvalidation"><i class="fa fa-check"></i><b>43.1.1</b> Review of Statistical Cross-Validation</a></li>
<li class="chapter" data-level="43.1.2" data-path="crossvalidation.html"><a href="crossvalidation.html#review_empirical_crossvalidation"><i class="fa fa-check"></i><b>43.1.2</b> Review of Empirical Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="43.2" data-path="crossvalidation.html"><a href="crossvalidation.html#tutorial_crossvalidation"><i class="fa fa-check"></i><b>43.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="43.2.1" data-path="crossvalidation.html"><a href="crossvalidation.html#function_crossvalidation"><i class="fa fa-check"></i><b>43.2.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="43.2.2" data-path="crossvalidation.html"><a href="crossvalidation.html#initsteps_crossvalidation"><i class="fa fa-check"></i><b>43.2.2</b> Initial Steps</a></li>
<li class="chapter" data-level="43.2.3" data-path="crossvalidation.html"><a href="crossvalidation.html#crossvalidation_statistical"><i class="fa fa-check"></i><b>43.2.3</b> Perform Statistical Cross-Validation</a></li>
<li class="chapter" data-level="43.2.4" data-path="crossvalidation.html"><a href="crossvalidation.html#crossvalidation_empirical"><i class="fa fa-check"></i><b>43.2.4</b> Perform Empirical Cross-Validation</a></li>
<li class="chapter" data-level="43.2.5" data-path="crossvalidation.html"><a href="crossvalidation.html#summary_crossvalidation"><i class="fa fa-check"></i><b>43.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VIII Employee Separation &amp; Retention</b></span></li>
<li class="chapter" data-level="44" data-path="turnover.html"><a href="turnover.html"><i class="fa fa-check"></i><b>44</b> Introduction to Employee Separation &amp; Retention</a></li>
<li class="chapter" data-level="45" data-path="turnoverrate.html"><a href="turnoverrate.html"><i class="fa fa-check"></i><b>45</b> Computing Monthly &amp; Annual Turnover Rates</a>
<ul>
<li class="chapter" data-level="45.1" data-path="turnoverrate.html"><a href="turnoverrate.html#conceptualoverview_turnoverrate"><i class="fa fa-check"></i><b>45.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="45.2" data-path="turnoverrate.html"><a href="turnoverrate.html#tutorial_turnoverrate"><i class="fa fa-check"></i><b>45.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="45.2.1" data-path="turnoverrate.html"><a href="turnoverrate.html#videotutorial_turnoverrate"><i class="fa fa-check"></i><b>45.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="45.2.2" data-path="turnoverrate.html"><a href="turnoverrate.html#functions_turnoverrate"><i class="fa fa-check"></i><b>45.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="45.2.3" data-path="turnoverrate.html"><a href="turnoverrate.html#initsteps_turnoverrate"><i class="fa fa-check"></i><b>45.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="45.2.4" data-path="turnoverrate.html"><a href="turnoverrate.html#turnoverrate_monthlyturnoverrate"><i class="fa fa-check"></i><b>45.2.4</b> Compute Monthly Turnover Rates</a></li>
<li class="chapter" data-level="45.2.5" data-path="turnoverrate.html"><a href="turnoverrate.html#turnoverrate_annualturnoverrate"><i class="fa fa-check"></i><b>45.2.5</b> Compute Annual Turnover Rate</a></li>
<li class="chapter" data-level="45.2.6" data-path="turnoverrate.html"><a href="turnoverrate.html#summary_turnoverrate"><i class="fa fa-check"></i><b>45.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="46" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html"><i class="fa fa-check"></i><b>46</b> Estimating the Association Between Two Categorical Variables Using Chi-Square (<span class="math inline">\(\chi^2\)</span>) Test of Independence</a>
<ul>
<li class="chapter" data-level="46.1" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#conceptualoverview_turnoverchisquare"><i class="fa fa-check"></i><b>46.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="46.2" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#tutorial_turnoverchisquare"><i class="fa fa-check"></i><b>46.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="46.2.1" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#videotutorial_turnoverchisquare"><i class="fa fa-check"></i><b>46.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="46.2.2" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#functions_turnoverchisquare"><i class="fa fa-check"></i><b>46.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="46.2.3" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#initsteps_turnoverchisquare"><i class="fa fa-check"></i><b>46.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="46.2.4" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_contingencytable"><i class="fa fa-check"></i><b>46.2.4</b> Create a Contingency Table for Observed Data</a></li>
<li class="chapter" data-level="46.2.5" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_chisquare"><i class="fa fa-check"></i><b>46.2.5</b> Estimate Chi-Square (<span class="math inline">\(\chi^2\)</span>) Test of Independence</a></li>
<li class="chapter" data-level="46.2.6" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#summary_turnoverchisquare"><i class="fa fa-check"></i><b>46.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="46.3" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_supplement"><i class="fa fa-check"></i><b>46.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="46.3.1" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_supplement_functions"><i class="fa fa-check"></i><b>46.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="46.3.2" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_initsteps_supplement"><i class="fa fa-check"></i><b>46.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="46.3.3" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#supplement_turnoverchisquare_oddsratio"><i class="fa fa-check"></i><b>46.3.3</b> Compute Odds Ratio for 2x2 Contingency Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>47</b> Identifying Predictors of Turnover Using Logistic Regression</a>
<ul>
<li class="chapter" data-level="47.1" data-path="logistic.html"><a href="logistic.html#conceptualoverview_logistic"><i class="fa fa-check"></i><b>47.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="47.1.1" data-path="logistic.html"><a href="logistic.html#review_logistic"><i class="fa fa-check"></i><b>47.1.1</b> Review of Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="47.2" data-path="logistic.html"><a href="logistic.html#tutorial_logistic"><i class="fa fa-check"></i><b>47.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="47.2.1" data-path="logistic.html"><a href="logistic.html#videotutorial_logistic"><i class="fa fa-check"></i><b>47.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="47.2.2" data-path="logistic.html"><a href="logistic.html#functions_logistic"><i class="fa fa-check"></i><b>47.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="47.2.3" data-path="logistic.html"><a href="logistic.html#initsteps_logistic"><i class="fa fa-check"></i><b>47.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="47.2.4" data-path="logistic.html"><a href="logistic.html#estimate_simple_logistic"><i class="fa fa-check"></i><b>47.2.4</b> Estimate Simple Logistic Regression Model</a></li>
<li class="chapter" data-level="47.2.5" data-path="logistic.html"><a href="logistic.html#estimate_multiple_logistic"><i class="fa fa-check"></i><b>47.2.5</b> Estimate Multiple Logistic Regression Model</a></li>
<li class="chapter" data-level="47.2.6" data-path="logistic.html"><a href="logistic.html#summary_logistic"><i class="fa fa-check"></i><b>47.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="47.3" data-path="logistic.html"><a href="logistic.html#logistic_supplement"><i class="fa fa-check"></i><b>47.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="47.3.1" data-path="logistic.html"><a href="logistic.html#logistic_supplement_functions"><i class="fa fa-check"></i><b>47.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="47.3.2" data-path="logistic.html"><a href="logistic.html#logistic_initsteps_supplement"><i class="fa fa-check"></i><b>47.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="47.3.3" data-path="logistic.html"><a href="logistic.html#glm_function_simple_logistic"><i class="fa fa-check"></i><b>47.3.3</b> Simple Logistic Regression Model Using <code>glm</code> Function from Base R</a></li>
<li class="chapter" data-level="47.3.4" data-path="logistic.html"><a href="logistic.html#glm_function_multiple_logistic"><i class="fa fa-check"></i><b>47.3.4</b> Multiple Logistic Regression Using <code>glm</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="48" data-path="kfold.html"><a href="kfold.html"><i class="fa fa-check"></i><b>48</b> Applying <em>k</em>-Fold Cross-Validation to Logistic Regression</a>
<ul>
<li class="chapter" data-level="48.1" data-path="kfold.html"><a href="kfold.html#conceptualoverview_kfold"><i class="fa fa-check"></i><b>48.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="48.1.1" data-path="kfold.html"><a href="kfold.html#review_predictiveanalytics"><i class="fa fa-check"></i><b>48.1.1</b> Review of Predictive Analytics</a></li>
<li class="chapter" data-level="48.1.2" data-path="kfold.html"><a href="kfold.html#review_kfold"><i class="fa fa-check"></i><b>48.1.2</b> Review of <em>k</em>-Fold Cross-Validation</a></li>
<li class="chapter" data-level="48.1.3" data-path="kfold.html"><a href="kfold.html#conceptualvideo_kfold"><i class="fa fa-check"></i><b>48.1.3</b> Conceptual Video</a></li>
</ul></li>
<li class="chapter" data-level="48.2" data-path="kfold.html"><a href="kfold.html#tutorial_kfold"><i class="fa fa-check"></i><b>48.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="48.2.1" data-path="kfold.html"><a href="kfold.html#videotutorial_kfold"><i class="fa fa-check"></i><b>48.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="48.2.2" data-path="kfold.html"><a href="kfold.html#functions_kfold"><i class="fa fa-check"></i><b>48.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="48.2.3" data-path="kfold.html"><a href="kfold.html#initsteps_kfold"><i class="fa fa-check"></i><b>48.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="48.2.4" data-path="kfold.html"><a href="kfold.html#estimate_kfold_logistic"><i class="fa fa-check"></i><b>48.2.4</b> Apply <em>k</em>-Fold Cross-Validation Using Logistic Regression</a></li>
<li class="chapter" data-level="48.2.5" data-path="kfold.html"><a href="kfold.html#summary_kfold"><i class="fa fa-check"></i><b>48.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="survival.html"><a href="survival.html"><i class="fa fa-check"></i><b>49</b> Understanding Length of Service Using Survival Analysis</a>
<ul>
<li class="chapter" data-level="49.1" data-path="survival.html"><a href="survival.html#conceptualoverview_survival"><i class="fa fa-check"></i><b>49.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="49.1.1" data-path="survival.html"><a href="survival.html#review_censoring_survival"><i class="fa fa-check"></i><b>49.1.1</b> Censoring</a></li>
<li class="chapter" data-level="49.1.2" data-path="survival.html"><a href="survival.html#review_types_survival"><i class="fa fa-check"></i><b>49.1.2</b> Types of Survival Analysis</a></li>
<li class="chapter" data-level="49.1.3" data-path="survival.html"><a href="survival.html#conceptualvideo_survival"><i class="fa fa-check"></i><b>49.1.3</b> Conceptual Video</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="survival.html"><a href="survival.html#tutorial_survival"><i class="fa fa-check"></i><b>49.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="49.2.1" data-path="survival.html"><a href="survival.html#videotutorial_survival"><i class="fa fa-check"></i><b>49.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="49.2.2" data-path="survival.html"><a href="survival.html#functions_survival"><i class="fa fa-check"></i><b>49.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="49.2.3" data-path="survival.html"><a href="survival.html#initsteps_survival"><i class="fa fa-check"></i><b>49.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="49.2.4" data-path="survival.html"><a href="survival.html#createcensoring_survival"><i class="fa fa-check"></i><b>49.2.4</b> Create a Censoring Variable</a></li>
<li class="chapter" data-level="49.2.5" data-path="survival.html"><a href="survival.html#inspectlosdistribution_survival"><i class="fa fa-check"></i><b>49.2.5</b> Inspect Distribution of Length of Service</a></li>
<li class="chapter" data-level="49.2.6" data-path="survival.html"><a href="survival.html#conductkmanalysis_lifetable_survival"><i class="fa fa-check"></i><b>49.2.6</b> Conduct Kaplan-Meier Analysis &amp; Create Life Table</a></li>
<li class="chapter" data-level="49.2.7" data-path="survival.html"><a href="survival.html#estimatecox_survival"><i class="fa fa-check"></i><b>49.2.7</b> Estimate Cox Proportional Hazards Model</a></li>
<li class="chapter" data-level="49.2.8" data-path="survival.html"><a href="survival.html#summary_survival"><i class="fa fa-check"></i><b>49.2.8</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IX Employee Performance Management</b></span></li>
<li class="chapter" data-level="50" data-path="performancemanagement.html"><a href="performancemanagement.html"><i class="fa fa-check"></i><b>50</b> Introduction to Employee Performance Management</a></li>
<li class="chapter" data-level="51" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html"><i class="fa fa-check"></i><b>51</b> Evaluating Convergent &amp; Discriminant Validity Using Scatter Plots &amp; Correlations</a>
<ul>
<li class="chapter" data-level="51.1" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#conceptualoverview_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="51.1.1" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#review_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.1.1</b> Review of Concurrent &amp; Discriminant Validity</a></li>
<li class="chapter" data-level="51.1.2" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#review_pearson_pointbiserial_correlation"><i class="fa fa-check"></i><b>51.1.2</b> Review of Pearson Product-Moment &amp; Point-Biserial Correlation</a></li>
<li class="chapter" data-level="51.1.3" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#review_bivariatescatterplot"><i class="fa fa-check"></i><b>51.1.3</b> Review of Bivariate Scatter Plot</a></li>
</ul></li>
<li class="chapter" data-level="51.2" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#tutorial_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="51.2.1" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#videotutorial_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="51.2.2" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#functions_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="51.2.3" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#initsteps_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="51.2.4" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#bivariatescatterplot_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.4</b> Visualize Association Using a Bivariate Scatter Plot</a></li>
<li class="chapter" data-level="51.2.5" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#estimate_correlation_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.5</b> Estimate Correlations</a></li>
<li class="chapter" data-level="51.2.6" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#correlationmatrix_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.6</b> Create Correlation Matrix</a></li>
<li class="chapter" data-level="51.2.7" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#summary_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#convergentdiscriminantvalidity_supplement"><i class="fa fa-check"></i><b>51.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="51.3.1" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#convergentdiscriminantvalidity_supplement_functions"><i class="fa fa-check"></i><b>51.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="51.3.2" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#convergentdiscriminantvalidity_initsteps_supplement"><i class="fa fa-check"></i><b>51.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="51.3.3" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#shapiro.test_function"><i class="fa fa-check"></i><b>51.3.3</b> <code>shapiro.test</code> Function from Base R</a></li>
<li class="chapter" data-level="51.3.4" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#apatable_correlationmatrix"><i class="fa fa-check"></i><b>51.3.4</b> APA-Style Results Table</a></li>
<li class="chapter" data-level="51.3.5" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#cor.plot_psych_function"><i class="fa fa-check"></i><b>51.3.5</b> <code>cor.plot</code> Function from <code>psych</code> package</a></li>
<li class="chapter" data-level="51.3.6" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#corrgram_corrgram_function"><i class="fa fa-check"></i><b>51.3.6</b> <code>corrgram</code> Function from <code>corrgram</code> package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="52" data-path="polynomialregression.html"><a href="polynomialregression.html"><i class="fa fa-check"></i><b>52</b> Investigating Nonlinear Associations Using Polynomial Regression</a>
<ul>
<li class="chapter" data-level="52.1" data-path="polynomialregression.html"><a href="polynomialregression.html#conceptualoverview_polynomialregression"><i class="fa fa-check"></i><b>52.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="52.1.1" data-path="polynomialregression.html"><a href="polynomialregression.html#statisticalassumptions_polynomialregression"><i class="fa fa-check"></i><b>52.1.1</b> Statistical Assumptions</a></li>
<li class="chapter" data-level="52.1.2" data-path="polynomialregression.html"><a href="polynomialregression.html#statisticalsignficance_polynomialregression"><i class="fa fa-check"></i><b>52.1.2</b> Statistical Significance</a></li>
</ul></li>
<li class="chapter" data-level="52.2" data-path="polynomialregression.html"><a href="polynomialregression.html#tutorial_polynomialregression"><i class="fa fa-check"></i><b>52.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="52.2.1" data-path="polynomialregression.html"><a href="polynomialregression.html#functions_polynomialregression"><i class="fa fa-check"></i><b>52.2.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="52.2.2" data-path="polynomialregression.html"><a href="polynomialregression.html#initsteps_polynomialregression"><i class="fa fa-check"></i><b>52.2.2</b> Initial Steps</a></li>
<li class="chapter" data-level="52.2.3" data-path="polynomialregression.html"><a href="polynomialregression.html#bivariatescatterplot_polynomialregression"><i class="fa fa-check"></i><b>52.2.3</b> Visualize Association Using a Bivariate Scatter Plot</a></li>
<li class="chapter" data-level="52.2.4" data-path="polynomialregression.html"><a href="polynomialregression.html#estimate_polynomialregression"><i class="fa fa-check"></i><b>52.2.4</b> Estimate Polynomial Regression Model</a></li>
<li class="chapter" data-level="52.2.5" data-path="polynomialregression.html"><a href="polynomialregression.html#summary_polynomialregression"><i class="fa fa-check"></i><b>52.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="53" data-path="lassoregression.html"><a href="lassoregression.html"><i class="fa fa-check"></i><b>53</b> Supervised Statistical Learning Using Lasso Regression</a>
<ul>
<li class="chapter" data-level="53.1" data-path="lassoregression.html"><a href="lassoregression.html#conceptualoverview_lassoregression"><i class="fa fa-check"></i><b>53.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="53.1.1" data-path="lassoregression.html"><a href="lassoregression.html#shrinkage_lassoregression"><i class="fa fa-check"></i><b>53.1.1</b> Shrinkage</a></li>
<li class="chapter" data-level="53.1.2" data-path="lassoregression.html"><a href="lassoregression.html#regularization_lassoregression"><i class="fa fa-check"></i><b>53.1.2</b> Regularization</a></li>
<li class="chapter" data-level="53.1.3" data-path="lassoregression.html"><a href="lassoregression.html#tuning_lassoregression"><i class="fa fa-check"></i><b>53.1.3</b> Tuning</a></li>
<li class="chapter" data-level="53.1.4" data-path="lassoregression.html"><a href="lassoregression.html#modeltype_selection_lassoregression"><i class="fa fa-check"></i><b>53.1.4</b> Model Type Selection</a></li>
<li class="chapter" data-level="53.1.5" data-path="lassoregression.html"><a href="lassoregression.html#crossvalidation_lassoregression"><i class="fa fa-check"></i><b>53.1.5</b> Cross-Validation</a></li>
<li class="chapter" data-level="53.1.6" data-path="lassoregression.html"><a href="lassoregression.html#predictiveanalytics_lassoregression"><i class="fa fa-check"></i><b>53.1.6</b> Predictive Analytics</a></li>
</ul></li>
<li class="chapter" data-level="53.2" data-path="lassoregression.html"><a href="lassoregression.html#tutorial_lassoregression"><i class="fa fa-check"></i><b>53.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="53.2.1" data-path="lassoregression.html"><a href="lassoregression.html#videotutorial_lassoregression"><i class="fa fa-check"></i><b>53.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="53.2.2" data-path="lassoregression.html"><a href="lassoregression.html#functions_lassoregression"><i class="fa fa-check"></i><b>53.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="53.2.3" data-path="lassoregression.html"><a href="lassoregression.html#initsteps_lassoregression"><i class="fa fa-check"></i><b>53.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="53.2.4" data-path="lassoregression.html"><a href="lassoregression.html#processoverview_lasso"><i class="fa fa-check"></i><b>53.2.4</b> Process Overview</a></li>
<li class="chapter" data-level="53.2.5" data-path="lassoregression.html"><a href="lassoregression.html#partitiondata_lasso"><i class="fa fa-check"></i><b>53.2.5</b> Partition the Data</a></li>
<li class="chapter" data-level="53.2.6" data-path="lassoregression.html"><a href="lassoregression.html#specify-k-fold-cross-validation"><i class="fa fa-check"></i><b>53.2.6</b> Specify <em>k</em>-Fold Cross-Validation</a></li>
<li class="chapter" data-level="53.2.7" data-path="lassoregression.html"><a href="lassoregression.html#trainlasso_lasso"><i class="fa fa-check"></i><b>53.2.7</b> Specify and Train Lasso Regression Model</a></li>
<li class="chapter" data-level="53.2.8" data-path="lassoregression.html"><a href="lassoregression.html#compare_ols_lasso"><i class="fa fa-check"></i><b>53.2.8</b> Optional: Compare to Lasso Model to OLS Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="53.2.9" data-path="lassoregression.html"><a href="lassoregression.html#summary_lasso"><i class="fa fa-check"></i><b>53.2.9</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>X Odds &amp; Ends</b></span></li>
<li class="chapter" data-level="54" data-path="create-portfolio.html"><a href="create-portfolio.html"><i class="fa fa-check"></i><b>54</b> Creating a Data Analytics Portfolio</a></li>
<li class="chapter" data-level="55" data-path="literature-search-review.html"><a href="literature-search-review.html"><i class="fa fa-check"></i><b>55</b> Conducting a Literature Search &amp; Review</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R for HR:<br />
<em>An Introduction to Human Resource Analytics Using R</em><br />
BOOK UNDER CONSTRUCTION</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lassoregression" class="section level1" number="53">
<h1><span class="header-section-number">Chapter 53</span> Supervised Statistical Learning Using Lasso Regression</h1>
<p>In this chapter, we will learn how to apply <em>k</em>-fold cross-validation to train a lasso (LASSO) regression model.</p>
<div id="conceptualoverview_lassoregression" class="section level2" number="53.1">
<h2><span class="header-section-number">53.1</span> Conceptual Overview</h2>
<p><strong>Least absolute shrinkage and selection operator (lasso, Lasso, LASSO) regression</strong> is a regularization method and a form of supervised statistical learning (i.e., machine learning) that is often applied when there are many potential predictor variables. Typically, when applying lasso regression the analysts primary goal is to improve model prediction, and other scientific research goals goals, such as understanding, explaining, or determining the cause of the outcome/phenomenon of interest, are of little or no interest. In other words, lasso regression can be a great exploratory tool for building a model that accurately predicts a particular outcome, especially when the model includes a large number of predictor variables. Of note, given its emphasis on prediction, there is often little if any attention paid to whether a non-zero lasso regression coefficient is statistically significant; with that said, there has been some preliminary work toward developing significance tests for lasso regression coefficients <span class="citation">(<a href="references.html#ref-lockhart2014" role="doc-biblioref">Lockhart, Taylor, and Tibshirani 2014</a>)</span>.</p>
<div id="shrinkage_lassoregression" class="section level3" number="53.1.1">
<h3><span class="header-section-number">53.1.1</span> Shrinkage</h3>
<p>Lasso regression selects only the most important predictor variables for predicting an outcome by shrinking the regression coefficients associated with the least important predictor variables to zero. In doing so, lasso regression can reduce the amount of <strong>shrinkage</strong> that occurs when a trained (i.e., estimated) model is applied to new data, where shrinkage refers to a reduction in model performance (e.g., variance explained in the outcome) when applied to a new data sample. In general, lasso regression is most often applied for the following reasons: (a) to avoid overfitting a model to the data on which it was trained (i.e., estimated), which can be problematic with conventional regression techniques (e.g., ordinary least squares linear regression models, generalized linear models), especially when there is a large number of predictor variables, and (b) to select only the most important predictor variables (i.e., features) from a much larger number of predictor variables.</p>
</div>
<div id="regularization_lassoregression" class="section level3" number="53.1.2">
<h3><span class="header-section-number">53.1.2</span> Regularization</h3>
<p>Lasso regression is a specific <strong>regularization method</strong> refereed to as a <em>L1 regularization method</em>, and it is related to other regularization methods like <em>ridge regression</em> and <em>elastic net</em>. The purpose of regularization is to reduce the variance of parameter estimates (i.e., regression coefficients), even if such a reduction comes with the cost of introducing or allowing for additional bias; ultimately, this means finding the optimal level of model complexity.</p>
</div>
<div id="tuning_lassoregression" class="section level3" number="53.1.3">
<h3><span class="header-section-number">53.1.3</span> Tuning</h3>
<p>Lasso regression involves two <strong>tuning parameters</strong> called alpha and lambda. For lasso regression, the <strong>alpha</strong> tuning parameter responsible for what is called the <em>mixing percentage</em> and is set to one. When alpha is set to one (<span class="math inline">\(\alpha\)</span> = 1), we are estimating a lasso regression model, and when alpha is set to zero (<span class="math inline">\(\alpha\)</span> = 0), we are estimating a ridge regression model. Thus, given that alpha remains constant for lasso regression, all we need to remember is to set alpha to one when specifying the model.</p>
<p>The more important turning parameter for lasso regression is <strong>lambda</strong> (<span class="math inline">\(\lambda\)</span>), which is our regularization parameter. Different values of lambda are evaluated to arrive at a final model that strikes a balance between model parsimony and accuracy. To achieve this end, the lambda tuning parameter places a constraint on the maximum absolute value of the regression coefficients in the model and adds a penalty to non-zero regression coefficients. So what are the effects of different lambda values? First, <em>when lambda is zero</em>, the model regression coefficients (i.e., parameter estimates) will approximate a conventional (e.g., ordinary least squares regression) model, and no regression coefficients will shrink to zero (i.e., be eliminated). Second, <em>when lambda is large</em>, regression coefficients with smaller absolute values will shrink toward zero. Third, <em>when lambda becomes too large</em>, all regression coefficients shrink to zero, resulting in a very parsimonious but (likely) inaccurate model.</p>
<p>Moreover, the value of the lambda tuning parameter influences variance and bias. Specifically, <em>as lambda gets smaller</em>, <strong>variance</strong> grows larger, where variance refers to the uncertainty (or dispersion) of the regression coefficient estimates. Conversely, <em>as lambda gets larger</em>, <strong>bias</strong> grows larger, where bias refers to the differences between the regression coefficient estimates and the true population parameters. In lasso regression, variance is minimized at the expense of greater bias. In this way, lasso regression differs from more traditional forms of regression. For example, in ordinary least squares (OLS) regression, bias is minimized at the expense of greater variance.</p>
<p>When training a lasso regression model, an array of possible lambda values are used to tune the model. To arrive at an <strong>optimal lambda</strong> value, model <em>accuracy</em> (e.g., amount of error) is noted at each level of lambda, with examples of model accuracy indices including (pseudo) <em>R</em><sup>2</sup>, mean-squared error (MSE), root mean-squared error (RMSE), classification accuracy, and Cohens kappa (<span class="math inline">\(\kappa\)</span>) (see Figure 1 for an example); the model accuracy index used will depend, in part, on the type of LASSO regression model specified (e.g., linear, logistic). Given that larger lambda result in a larger penalty to non-zero regression coefficients, model <em>parsimony</em> is also affected as model lambda is adjusted; specifically, models become more parsimonious (i.e., fewer predictor variables with non-zero regression coefficients) as lambda increases in magnitude, but at some point, model predictive accuracy starts to suffer when a model becomes too parsimonious and most (or all) of regression coefficients fall to zero (see Figure 2 for an example). Consequently, the optimal lambda value will strike a balance between model accuracy and model parsimony. <em>[Note: To facilitate interpretation, we often apply a logarithmic (log) transformation to lambda.]</em></p>
<div class="figure">
<img src="MSEplot.png" alt="" />
<p class="caption">This plot is an example of a logarithmic tranformation of lambda in relation to mean-squared error (MSE).</p>
</div>
<div class="figure">
<img src="CoefficientSizeplot.png" alt="" />
<p class="caption">This plot is an example of a logarithmic tranformation of lambda in relation to regression coefficient magnitude, where x1-x10 refer to 10 predictor variables</p>
</div>
</div>
<div id="modeltype_selection_lassoregression" class="section level3" number="53.1.4">
<h3><span class="header-section-number">53.1.4</span> Model Type Selection</h3>
<p>An important part of the lasso regression model building process is selecting the appropriate model type. Often, the characteristics of the outcome variable will inform which type of model should be used within lasso regression. For example, if the outcome variable is continuous in terms of its measurement scale (i.e., interval or ratio scale), then a linear model is likely appropriate. As another example, if the outcome variable is dichotomous (i.e., binary), then a generalized linear model like a logistic regression model (i.e., logit model) is likely appropriate. Traditionally, lasso regression has been applied to linear regression models; however, it can, however, also be applied to other families of models, such as generalized linear models. The model type selected will also influence what statistical assumptions should be met; with that said, lasso regression can help address multicollinearity that can pose problems for traditional forms of regression (e.g., OLS linear, logistic).</p>
</div>
<div id="crossvalidation_lassoregression" class="section level3" number="53.1.5">
<h3><span class="header-section-number">53.1.5</span> Cross-Validation</h3>
<p>It is advisable to use <strong>cross-validation</strong> when training a model, as cross-validation can improve model prediction performance and how well the model generalizes to other data from the same population. There are different approaches to carrying out cross-validation, with one of the simplest being simple empirical cross-validation, which you can learn more about in the <a href="crossvalidation.html#crossvalidation">chapter on statistical and empirical cross-validation</a>. Another approach is called <strong><em>k</em>-fold cross-validation</strong>, which is quite popular among practitioners and is introduced in the <a href="kfold.html#kfold">chapter on <em>k</em>-fold cross-validation applied to logistic regression</a>. In this chapter, we will apply lasso regression using a <em>k</em>-fold cross-validation framework, as this approach is useful when tuning the lambda parameter.</p>
<p>Regardless of the type of cross-validation used, it is advisable to apply cross-validation in a predictive analytics framework, which is described next.</p>
</div>
<div id="predictiveanalytics_lassoregression" class="section level3" number="53.1.6">
<h3><span class="header-section-number">53.1.6</span> Predictive Analytics</h3>
<p>As a reminder, true <strong>predictive analytics</strong> (predictive modeling) involves training (estimating, building) a model in one or more samples (e.g., training data) and then evaluating (testing) how well the model performs in a separate sample (i.e., test data) from the same population. The term predictive analytics is a big umbrella term, and predictive analytics can be applied to many different types of models, including lasso regression. When building a model using a predictive analytics framework, one of our goals is to minimize prediction errors (i.e., improve prediction accuracy) when the model is applied to fresh or new data (e.g., test data). Fewer prediction errors when applying the model to new data indicate that the model is more accurate. At the same time, we want to avoid overfitting our model such that it predicts with a high level of accuracy in our training data but doesnt generalize well to our test data; applying a trained model to new data can help us evaluate with the extent to which we might have overfit a model to the original data. Fortunately, as described above, a major selling point of lasso regression is that it can help reduce model overfitting.</p>
</div>
</div>
<div id="tutorial_lassoregression" class="section level2" number="53.2">
<h2><span class="header-section-number">53.2</span> Tutorial</h2>
<p>This chapters tutorial demonstrates training a lasso regression model using <em>k</em>-fold cross-validation.</p>
<div id="videotutorial_lassoregression" class="section level3" number="53.2.1">
<h3><span class="header-section-number">53.2.1</span> Video Tutorials</h3>
<p>As usual, you have the choice to follow along with the written tutorial in this chapter or to watch the video tutorial below.</p>
<iframe src="https://youtube.com/embed/5GZ5BHOugBQ?rel=0" width="672" height="400px">
</iframe>
<p>Link to video tutorial: <a href="https://youtu.be/5GZ5BHOugBQ" class="uri">https://youtu.be/5GZ5BHOugBQ</a></p>
<p>Additionally, in the following video tutorial, I show how to compare the results of an OLS multiple linear regression model to a lasso regression model, where both are trained using <em>k</em>-fold cross-validation.</p>
<iframe src="https://youtube.com/embed/NUfbl7ijZ0Q?rel=0" width="672" height="400px">
</iframe>
<p>Link to video tutorial: <a href="https://youtu.be/NUfbl7ijZ0Q" class="uri">https://youtu.be/NUfbl7ijZ0Q</a></p>
</div>
<div id="functions_lassoregression" class="section level3" number="53.2.2">
<h3><span class="header-section-number">53.2.2</span> Functions &amp; Packages Introduced</h3>
<table>
<thead>
<tr class="header">
<th align="center">Function</th>
<th align="center">Package</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>set.seed</code></td>
<td align="center">base R</td>
</tr>
<tr class="even">
<td align="center"><code>nrow</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>as.data.frame</code></td>
<td align="center">base R</td>
</tr>
<tr class="even">
<td align="center"><code>createDataPartition</code></td>
<td align="center"><code>caret</code></td>
</tr>
<tr class="odd">
<td align="center"><code>trainControl</code></td>
<td align="center"><code>caret</code></td>
</tr>
<tr class="even">
<td align="center"><code>seq</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>train</code></td>
<td align="center"><code>caret</code></td>
</tr>
<tr class="even">
<td align="center"><code>log</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>plot</code></td>
<td align="center">base R</td>
</tr>
<tr class="even">
<td align="center"><code>summary</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>varImp</code></td>
<td align="center"><code>caret</code></td>
</tr>
<tr class="even">
<td align="center"><code>ggplot</code></td>
<td align="center"><code>ggplot2</code></td>
</tr>
<tr class="odd">
<td align="center"><code>predict</code></td>
<td align="center">base R</td>
</tr>
<tr class="even">
<td align="center"><code>print</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>RMSE</code></td>
<td align="center"><code>caret</code></td>
</tr>
<tr class="even">
<td align="center"><code>R2</code></td>
<td align="center"><code>caret</code></td>
</tr>
<tr class="odd">
<td align="center"><code>coef</code></td>
<td align="center">base R</td>
</tr>
<tr class="even">
<td align="center"><code>function</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>data.frame</code></td>
<td align="center">base R</td>
</tr>
<tr class="even">
<td align="center"><code>matrix</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>colnames</code></td>
<td align="center">base R</td>
</tr>
<tr class="even">
<td align="center"><code>rownames</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>round</code></td>
<td align="center">base R</td>
</tr>
<tr class="even">
<td align="center"><code>c</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>list</code></td>
<td align="center">base R</td>
</tr>
<tr class="even">
<td align="center"><code>as.table</code></td>
<td align="center">base R</td>
</tr>
<tr class="odd">
<td align="center"><code>resamples</code></td>
<td align="center"><code>caret</code></td>
</tr>
<tr class="even">
<td align="center"><code>compare_models</code></td>
<td align="center"><code>caret</code></td>
</tr>
</tbody>
</table>
</div>
<div id="initsteps_lassoregression" class="section level3" number="53.2.3">
<h3><span class="header-section-number">53.2.3</span> Initial Steps</h3>
<p>If you havent already, save the file called <strong>lasso.csv</strong> into a folder that you will subsequently set as your working directory. Your working directory will likely be different than the one shown below (i.e., <code>"H:/RWorkshop"</code>). As a reminder, you can access all of the data files referenced in this book by downloading them as a compressed (zipped) folder from the my GitHub site: <a href="https://github.com/davidcaughlin/R-Tutorial-Data-Files" class="uri">https://github.com/davidcaughlin/R-Tutorial-Data-Files</a>; once youve followed the link to GitHub, just click Code (or Download) followed by Download ZIP, which will download all of the data files referenced in this book. For the sake of parsimony, I recommend downloading all of the data files into the same folder on your computer, which will allow you to set that same folder as your working directory for each of the chapters in this book.</p>
<p>Next, using the <code>setwd</code> function, set your working directory to the folder in which you saved the data file for this chapter. Alternatively, you can manually set your working directory folder in your drop-down menus by going to <em>Session &gt; Set Working Directory &gt; Choose Directory</em>. Be sure to create a new R script file (.R) or update an existing R script file so that you can save your script and annotations. If you need refreshers on how to set your working directory and how to create and save an R script, please refer to <a href="setwd.html#setwd">Setting a Working Directory</a> and <a href="gettingstarted.html#createRscript">Creating &amp; Saving an R Script</a>.</p>
<div class="sourceCode" id="cb2057"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2057-1"><a href="lassoregression.html#cb2057-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set your working directory</span></span>
<span id="cb2057-2"><a href="lassoregression.html#cb2057-2" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">&quot;H:/RWorkshop&quot;</span>)</span></code></pre></div>
<p>Next, read in the .csv data file called <strong>lasso.csv</strong> using your choice of read function. In this example, I use the <code>read_csv</code> function from the <code>readr</code> package <span class="citation">(<a href="references.html#ref-R-readr" role="doc-biblioref">Wickham and Hester 2020</a>)</span>. If you choose to use the <code>read_csv</code> function, be sure that you have installed and accessed the <code>readr</code> package using the <code>install.packages</code> and <code>library</code> functions. <em>Note: You dont need to install a package every time you wish to access it; in general, I would recommend updating a package installation once ever 1-3 months.</em> For refreshers on installing packages and reading data into R, please refer to <a href="gentleintro.html#packages">Packages</a> and <a href="read.html#read">Reading Data into R</a>.</p>
<div class="sourceCode" id="cb2058"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2058-1"><a href="lassoregression.html#cb2058-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install readr package if you haven&#39;t already</span></span>
<span id="cb2058-2"><a href="lassoregression.html#cb2058-2" aria-hidden="true" tabindex="-1"></a><span class="co"># [Note: You don&#39;t need to install a package every </span></span>
<span id="cb2058-3"><a href="lassoregression.html#cb2058-3" aria-hidden="true" tabindex="-1"></a><span class="co"># time you wish to access it]</span></span>
<span id="cb2058-4"><a href="lassoregression.html#cb2058-4" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;readr&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2059"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2059-1"><a href="lassoregression.html#cb2059-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Access readr package</span></span>
<span id="cb2059-2"><a href="lassoregression.html#cb2059-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb2059-3"><a href="lassoregression.html#cb2059-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2059-4"><a href="lassoregression.html#cb2059-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Read data and name data frame (tibble) object</span></span>
<span id="cb2059-5"><a href="lassoregression.html#cb2059-5" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;lasso.csv&quot;</span>)</span></code></pre></div>
<pre><code>## 
## -- Column specification ---------------------------------------------------------------------------------
## cols(
##   .default = col_double()
## )
## i Use `spec()` for the full column specifications.</code></pre>
<div class="sourceCode" id="cb2061"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2061-1"><a href="lassoregression.html#cb2061-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the names of the variables in the data frame (tibble) object</span></span>
<span id="cb2061-2"><a href="lassoregression.html#cb2061-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(df)</span></code></pre></div>
<pre><code>##  [1] &quot;y&quot;   &quot;x1&quot;  &quot;x2&quot;  &quot;x3&quot;  &quot;x4&quot;  &quot;x5&quot;  &quot;x6&quot;  &quot;x7&quot;  &quot;x8&quot;  &quot;x9&quot;  &quot;x10&quot; &quot;x11&quot; &quot;x12&quot; &quot;x13&quot; &quot;x14&quot; &quot;x15&quot;
## [17] &quot;x16&quot; &quot;x17&quot; &quot;x18&quot; &quot;x19&quot; &quot;x20&quot; &quot;x21&quot; &quot;x22&quot; &quot;x23&quot; &quot;x24&quot; &quot;x25&quot; &quot;x26&quot; &quot;x27&quot; &quot;x28&quot; &quot;x29&quot; &quot;x30&quot; &quot;x31&quot;
## [33] &quot;x32&quot; &quot;x33&quot; &quot;x34&quot; &quot;x35&quot; &quot;x36&quot;</code></pre>
<div class="sourceCode" id="cb2063"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2063-1"><a href="lassoregression.html#cb2063-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print variable type for each variable in data frame (tibble) object</span></span>
<span id="cb2063-2"><a href="lassoregression.html#cb2063-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(df)</span></code></pre></div>
<pre><code>## spec_tbl_df[,37] [1,000 x 37] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ y  : num [1:1000] -0.886 0.763 0.209 1.746 0.22 ...
##  $ x1 : num [1:1000] -0.57 1.763 -0.016 1.476 -1.288 ...
##  $ x2 : num [1:1000] -0.669 1.077 0.264 0.153 -1.091 ...
##  $ x3 : num [1:1000] -0.978 1.094 -1.302 1.804 0.226 ...
##  $ x4 : num [1:1000] -0.948 2.427 -0.493 -1 0.713 ...
##  $ x5 : num [1:1000] -1.703 1.011 -0.049 -0.768 1.731 ...
##  $ x6 : num [1:1000] -0.623 2.574 -0.61 0.008 -1.21 ...
##  $ x7 : num [1:1000] 0.176 1.32 -0.565 -0.083 1.125 ...
##  $ x8 : num [1:1000] -1.624 2.917 -1.626 0.478 -1.053 ...
##  $ x9 : num [1:1000] -1.189 1.997 -0.95 0.204 0.622 ...
##  $ x10: num [1:1000] -0.519 0.882 0.676 1.182 0.234 ...
##  $ x11: num [1:1000] -0.495 1.155 0.531 0.687 0.596 ...
##  $ x12: num [1:1000] 0.008 2.895 0.434 1.195 -0.004 ...
##  $ x13: num [1:1000] 0.269 1.996 0.499 -0.523 -1.714 ...
##  $ x14: num [1:1000] 0.017 3.665 1.998 -2.024 0.754 ...
##  $ x15: num [1:1000] -0.32 0.885 -0.776 4.072 -0.335 ...
##  $ x16: num [1:1000] -0.849 1.132 -0.404 0.658 -0.154 ...
##  $ x17: num [1:1000] -4.33 6.26 1.66 1.11 -2.2 ...
##  $ x18: num [1:1000] -2.405 6.338 1.684 6.423 0.379 ...
##  $ x19: num [1:1000] -0.195 0.236 0.011 0.036 0.082 -0.419 -0.327 0.034 -0.422 -0.164 ...
##  $ x20: num [1:1000] 0.634 0.356 0.422 1.693 0.593 ...
##  $ x21: num [1:1000] -0.853 1.685 0.557 -0.498 1.248 ...
##  $ x22: num [1:1000] -1.537 1.771 -0.882 -0.316 -0.028 ...
##  $ x23: num [1:1000] -0.675 0.715 0.623 -0.885 0.246 ...
##  $ x24: num [1:1000] -1.077 0.007 -0.223 0.315 1.728 ...
##  $ x25: num [1:1000] -0.851 1.382 -0.1 0.384 -0.212 ...
##  $ x26: num [1:1000] -1.578 0.172 1.537 1.268 0.616 ...
##  $ x27: num [1:1000] -2 2.62 -2.11 1.64 2.14 ...
##  $ x28: num [1:1000] -0.641 3.905 -0.914 0.357 0.266 ...
##  $ x29: num [1:1000] -1.223 1.874 0.792 0.509 1.008 ...
##  $ x30: num [1:1000] -0.615 1.862 0.64 0.483 1.469 ...
##  $ x31: num [1:1000] -0.751 1.291 0.147 -1.321 0.268 ...
##  $ x32: num [1:1000] -0.464 3.085 0.558 0.917 0.762 ...
##  $ x33: num [1:1000] -1.749 0.424 0.584 1.264 1.445 ...
##  $ x34: num [1:1000] -0.841 -0.189 0.58 2.599 2.538 ...
##  $ x35: num [1:1000] -0.933 0.448 -1.856 -0.091 2.658 ...
##  $ x36: num [1:1000] -1.296 1.706 0.707 0.454 1.118 ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   y = col_double(),
##   ..   x1 = col_double(),
##   ..   x2 = col_double(),
##   ..   x3 = col_double(),
##   ..   x4 = col_double(),
##   ..   x5 = col_double(),
##   ..   x6 = col_double(),
##   ..   x7 = col_double(),
##   ..   x8 = col_double(),
##   ..   x9 = col_double(),
##   ..   x10 = col_double(),
##   ..   x11 = col_double(),
##   ..   x12 = col_double(),
##   ..   x13 = col_double(),
##   ..   x14 = col_double(),
##   ..   x15 = col_double(),
##   ..   x16 = col_double(),
##   ..   x17 = col_double(),
##   ..   x18 = col_double(),
##   ..   x19 = col_double(),
##   ..   x20 = col_double(),
##   ..   x21 = col_double(),
##   ..   x22 = col_double(),
##   ..   x23 = col_double(),
##   ..   x24 = col_double(),
##   ..   x25 = col_double(),
##   ..   x26 = col_double(),
##   ..   x27 = col_double(),
##   ..   x28 = col_double(),
##   ..   x29 = col_double(),
##   ..   x30 = col_double(),
##   ..   x31 = col_double(),
##   ..   x32 = col_double(),
##   ..   x33 = col_double(),
##   ..   x34 = col_double(),
##   ..   x35 = col_double(),
##   ..   x36 = col_double()
##   .. )</code></pre>
<div class="sourceCode" id="cb2065"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2065-1"><a href="lassoregression.html#cb2065-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print first 6 rows of data frame (tibble) object</span></span>
<span id="cb2065-2"><a href="lassoregression.html#cb2065-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 37
##        y     x1     x2     x3     x4     x5     x6     x7     x8     x9    x10    x11    x12    x13
##    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 -0.886 -0.57  -0.669 -0.978 -0.948 -1.70  -0.623  0.176 -1.62  -1.19  -0.519 -0.495  0.008  0.269
## 2  0.763  1.76   1.08   1.09   2.43   1.01   2.57   1.32   2.92   2.00   0.882  1.16   2.90   2.00 
## 3  0.209 -0.016  0.264 -1.30  -0.493 -0.049 -0.61  -0.565 -1.63  -0.95   0.676  0.531  0.434  0.499
## 4  1.75   1.48   0.153  1.80  -1     -0.768  0.008 -0.083  0.478  0.204  1.18   0.687  1.20  -0.523
## 5  0.22  -1.29  -1.09   0.226  0.713  1.73  -1.21   1.12  -1.05   0.622  0.234  0.596 -0.004 -1.71 
## 6 -0.458 -0.619 -1.82  -1.35  -0.036 -3.79  -2.02  -0.072 -1.26  -0.999 -1.12  -2.61  -1.85  -2.16 
## # ... with 23 more variables: x14 &lt;dbl&gt;, x15 &lt;dbl&gt;, x16 &lt;dbl&gt;, x17 &lt;dbl&gt;, x18 &lt;dbl&gt;, x19 &lt;dbl&gt;,
## #   x20 &lt;dbl&gt;, x21 &lt;dbl&gt;, x22 &lt;dbl&gt;, x23 &lt;dbl&gt;, x24 &lt;dbl&gt;, x25 &lt;dbl&gt;, x26 &lt;dbl&gt;, x27 &lt;dbl&gt;, x28 &lt;dbl&gt;,
## #   x29 &lt;dbl&gt;, x30 &lt;dbl&gt;, x31 &lt;dbl&gt;, x32 &lt;dbl&gt;, x33 &lt;dbl&gt;, x34 &lt;dbl&gt;, x35 &lt;dbl&gt;, x36 &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb2067"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2067-1"><a href="lassoregression.html#cb2067-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print number of rows in data frame (tibble) object</span></span>
<span id="cb2067-2"><a href="lassoregression.html#cb2067-2" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(df)</span></code></pre></div>
<pre><code>## [1] 1000</code></pre>
<p>The data frame (<code>df</code>) has 1000 cases and the following 37 variables: <code>y</code> and <code>x1</code> through <code>x36</code>. Well use <code>y</code> as our outcome variable and <code>x1</code> - <code>x36</code> as our predictor variables. Per the output of the <code>str</code> (structure) function above, all of the variables are of type <em>numeric</em>. Sticking with the theme of performance management for this part of the book, well imagine that the <code>y</code> variable is some kind of measure of job performance.</p>
</div>
<div id="processoverview_lasso" class="section level3" number="53.2.4">
<h3><span class="header-section-number">53.2.4</span> Process Overview</h3>
<p>In this tutorial, we will implement lasso regression using <em>k</em>-fold cross-validation. If you wish to learn more about <em>k</em>-fold cross-validation, please refer to the <a href="crossvalidation.html#crossvalidation">chapter on statistical and empirical cross-validation</a>. As a reminder, you can perform <em>k</em>-fold cross-validation with different types of statistical models. We will also engage in true predictive analytics (i.e., predictive modeling), such that we will partition the data into training and test data, train the model on the training data using <em>k</em>-fold cross-validation, and evaluate the final models predictive accuracy based on the test data.</p>
</div>
<div id="partitiondata_lasso" class="section level3" number="53.2.5">
<h3><span class="header-section-number">53.2.5</span> Partition the Data</h3>
<p>Lets begin by randomly partitioning (i.e., splitting) our data into training and test data frames. To get this process started, we will install and access the <code>caret</code> package (if you havent already). The <code>caret</code> package has a number of different functions that are useful for implementing predictive analytics and a variety of machine learning models.</p>
<div class="sourceCode" id="cb2069"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2069-1"><a href="lassoregression.html#cb2069-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install caret package if you haven&#39;t already</span></span>
<span id="cb2069-2"><a href="lassoregression.html#cb2069-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;caret&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2070"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2070-1"><a href="lassoregression.html#cb2070-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Access caret package</span></span>
<span id="cb2070-2"><a href="lassoregression.html#cb2070-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code></pre></div>
<p>Using the <code>createDataPartition</code> function from the <code>caret</code> package, we will partition the data such that 80% of the cases will be randomly assigned to one split, and the remaining 20% of cases will be assigned to the other split. However, immediately before doing so, I recommend using the <code>set.seed</code> function from base R and include a number of your choosing as the sole parenthetical argument; this will create random operations that are reproducible. With your seed set, create a name for the index of unique cases that will identify which cases should be included in the first split involving 80% of the original data frame cases; here, I call this matrix object <code>index</code> and assign values to it using the <code>&lt;-</code> operator. To the right of the <code>&lt;-</code>, enter the name of the <code>createDataPartition</code> function. As the first argument, type the name of the data frame (<code>df</code>), followed by the <code>$</code> and the name of the outcome variable (<code>y</code>). <strong>[Note: I have noticed that the <code>createDataPartition</code> sometimes adds an extra case to the partitioned data <code>index</code> object, which seems to occur more frequently when the outcome variable is of type factor as opposed to numeric, integer, or character. An extra case added to the training data frame is not a big deal when we have this many cases, so if it happens, we wont worry about it. If you would like to avoid this, you can try converting the outcome variable from type factor to type numeric, integer, or character, whichever makes the most sense given the variable. You can always convert the outcome back to type factor after this process, which I demonstrate in this tutorial. This fix works some of the time but not all of the time.]</strong> As a the second argument, set <code>p=.8</code> to note that you wish to randomly select 80% (.8) of the cases from the data frame. As the third argument, type <code>list=FALSE</code> to indicate that we want to the values in matrix form to facilitate reference to them in a subsequent step. As the fourth argument, type <code>times=1</code> to indicate that we only want to request a single partition of the data frame.</p>
<div class="sourceCode" id="cb2071"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2071-1"><a href="lassoregression.html#cb2071-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducible random partitioning of data</span></span>
<span id="cb2071-2"><a href="lassoregression.html#cb2071-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1985</span>)</span>
<span id="cb2071-3"><a href="lassoregression.html#cb2071-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2071-4"><a href="lassoregression.html#cb2071-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Partition data and create index matrix of selected values</span></span>
<span id="cb2071-5"><a href="lassoregression.html#cb2071-5" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(df<span class="sc">$</span>y, <span class="at">p=</span>.<span class="dv">8</span>, <span class="at">list=</span><span class="cn">FALSE</span>, <span class="at">times=</span><span class="dv">1</span>)</span></code></pre></div>
<p>Now its time to use the <code>index</code> matrix object we created above to assign cases to the training data frame (which we will name <code>train_df</code>) and to the testing data frame (which we will name <code>test_df</code>). Beginning with the training data frame, we assign the random sample of 80% of the original data frame (<code>df</code>) to the <code>train_df</code> object by using the <code>&lt;-</code> operator. Specifically, we specify the name of the original data frame (<code>df</code>), followed by brackets (<code>[ ]</code>). In the brackets, include the name of the <code>index</code> object we created above, followed by a comma (<code>,</code>). The placement of the <code>index</code> object before the comma indicates that we are selecting rows with the selected unique row numbers (i.e., index) from the <code>index</code> matrix. Next, we do essentially the same thing with the <code>test_df</code>, except that we insert a minus (<code>-</code>) symbol before <code>index</code> to indicate that we <em>dont</em> want cases associated with the unique row numbers contained in the <code>index</code> matrix.</p>
<div class="sourceCode" id="cb2072"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2072-1"><a href="lassoregression.html#cb2072-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create test and train data frames</span></span>
<span id="cb2072-2"><a href="lassoregression.html#cb2072-2" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> df[index,]</span>
<span id="cb2072-3"><a href="lassoregression.html#cb2072-3" aria-hidden="true" tabindex="-1"></a>test_df <span class="ot">&lt;-</span> df[<span class="sc">-</span>index,]</span></code></pre></div>
<p>If you received the error message shown below, then please proceed to convert the original data frame <code>df</code> from a tibble to a conventional data frame; after that, repeat the steps above from which you received the error message originally, which I will do below. If you did not receive this message, then you can skip this step and proceed on to the step in which you verify the number of rows in each data frame.</p>
<p><span class="math inline">\(\color{red}{\text{Error: `i` must have one dimension, not 2.}}\)</span></p>
<div class="sourceCode" id="cb2073"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2073-1"><a href="lassoregression.html#cb2073-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert data frame object (df) to a conventional data frame object</span></span>
<span id="cb2073-2"><a href="lassoregression.html#cb2073-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(df)</span>
<span id="cb2073-3"><a href="lassoregression.html#cb2073-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2073-4"><a href="lassoregression.html#cb2073-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create test and train data frames</span></span>
<span id="cb2073-5"><a href="lassoregression.html#cb2073-5" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> df[index,]</span>
<span id="cb2073-6"><a href="lassoregression.html#cb2073-6" aria-hidden="true" tabindex="-1"></a>test_df <span class="ot">&lt;-</span> df[<span class="sc">-</span>index,]</span></code></pre></div>
<p>To check our work and to be sure that 80% of the cases ended up in the <code>train_df</code> data frame and the remaining 20% ended up in the <code>test_df</code> data frame, lets apply the <code>nrow</code> function from base R.</p>
<div class="sourceCode" id="cb2074"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2074-1"><a href="lassoregression.html#cb2074-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify number of rows (cases) in each data frame</span></span>
<span id="cb2074-2"><a href="lassoregression.html#cb2074-2" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(train_df)</span></code></pre></div>
<pre><code>## [1] 801</code></pre>
<div class="sourceCode" id="cb2076"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2076-1"><a href="lassoregression.html#cb2076-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(test_df)</span></code></pre></div>
<pre><code>## [1] 199</code></pre>
<p>Indeed, 801 (~ 80%) of the original 1,000 cases ended up in the <code>train_df</code> data frame, and 199 (~ 20%) of the original 1,000 cases ended up in the <code>test_df</code> data frame, which is close enough to a perfect 80/20 partition.</p>
</div>
<div id="specify-k-fold-cross-validation" class="section level3" number="53.2.6">
<h3><span class="header-section-number">53.2.6</span> Specify <em>k</em>-Fold Cross-Validation</h3>
<p>Now its time to specify the type of training method we want to apply, which in this tutorial is <em>k</em>-fold cross-validation. Lets create and name our specifications object <code>ctrlspecs</code> using the <code>&lt;-</code> operator. To the right of the <code>&lt;-</code> operator, type the name of the <code>trainControl</code> function from the <code>caret</code> package. As the first argument, specify the method by setting <code>method="cv"</code>, where <code>"cv"</code> represents cross-validation. As the second argument, set <code>number=10</code> to indicate that we want 10 folds (i.e., 10 resamples), which means we will specifically use 10-fold cross-validation. As the third argument, type <code>savePredictions="all"</code> to save all of the hold-out predictions for each of our resamples from the <code>train_df</code> data frame, where hold-out predictions refer to those cases that werent used in training each iteration of the model based on each fold of data but were used for validating the model trained at each fold.</p>
<div class="sourceCode" id="cb2078"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2078-1"><a href="lassoregression.html#cb2078-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify 10-fold cross-validation as training method</span></span>
<span id="cb2078-2"><a href="lassoregression.html#cb2078-2" aria-hidden="true" tabindex="-1"></a>ctrlspecs <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&quot;cv&quot;</span>, </span>
<span id="cb2078-3"><a href="lassoregression.html#cb2078-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">number=</span><span class="dv">10</span>,</span>
<span id="cb2078-4"><a href="lassoregression.html#cb2078-4" aria-hidden="true" tabindex="-1"></a>                          <span class="at">savePredictions=</span><span class="st">&quot;all&quot;</span>)</span></code></pre></div>
</div>
<div id="trainlasso_lasso" class="section level3" number="53.2.7">
<h3><span class="header-section-number">53.2.7</span> Specify and Train Lasso Regression Model</h3>
<p>Before we specify our lasso regression model, we need to create a vector of potential lambda tuning parameter values. Well begin by creating an object to which we can assign the potential values; lets make things clear and simple by naming this object <code>lambda_vector</code> using the <code>&lt;-</code> operator. Next, we will create a vector of possible lambda by setting the base to 10 and then exponentiating it by a sequence of 500 values ranging from 5 to -5. Remember, that the <code>^</code> operator is how we assign exponents. The <code>seq</code> (sequence) function from base R is specified with the first argument being one end of the sequence (e.g., 5) and the second argument being the other end of the sequence (e.g., -5); the upper and lower limits of the sequence probably do not need to be this wide, but to be on the safe side, I recommend using these same limits for other sequences of lambdas. The third argument of the <code>seq</code> function is the length of the sequence in terms of the number of values generated within the sequence; lets set the length to 500 (<code>length=500</code>); I also recommend using this same length of 500 for other vectors of potential lambdas you might generate. We will reference this <code>lambda_vector</code> object we created when we specify our model training parameters.</p>
<div class="sourceCode" id="cb2079"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2079-1"><a href="lassoregression.html#cb2079-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create vector of potential lambda values</span></span>
<span id="cb2079-2"><a href="lassoregression.html#cb2079-2" aria-hidden="true" tabindex="-1"></a>lambda_vector <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">5</span>, <span class="sc">-</span><span class="dv">5</span>, <span class="at">length=</span><span class="dv">500</span>)</span></code></pre></div>
<p>To specify (and ultimately train) our lasso regression model, we will use the <code>train</code> function from the <code>caret</code> package.</p>
<ol style="list-style-type: decimal">
<li>I recommend using the <code>set.seed</code> function from base R and include a number of your choosing as the sole parenthetical argument; this will create random operations that are reproducible.</li>
<li>Moving on to the <code>train</code> function, come up with a name for your model object; here, I name the model object <code>model1</code> and use the <code>&lt;-</code> operator to assign the model specifications to it.</li>
<li>Next, type the name of the <code>train</code> function.</li>
</ol>
<ul>
<li>As the first argument, lets specify our linear model. To the left of the tilde (<code>~</code>) symbol, type the name of the continuous outcome variable called <code>y</code>. To the right of the tilde (<code>~</code>) symbol, type <code>.</code>, which will automatically specify all remaining variables in the data frame as predictor variables; if you dont want to specify all remaining variables as predictor variables, then you can do it the old-fashioned way by entering each variable name separated by a <code>+</code> symbol.</li>
<li>As the second argument in the <code>train</code> function, type <code>data=</code> followed by the name of the training data frame object (<code>train_df</code>).</li>
<li>As the third argument, use the <code>preProcess</code> argument to mean center (i.e., subtract the mean of the variable from each value) and standardize (i.e., divide each value of the variable by the variables standard deviation) the predictor variables prior to training the model, which is advisable when using lasso regression; to do so, use the <code>c</code> (combine) function from base R with <code>"center"</code> and <code>"scale"</code> as the two arguments.</li>
<li>As the fourth argument, specify <code>method="glmnet"</code>, which will allow us to access regularization method models such as lasso regression or ridge regression.</li>
<li>As the fifth argument, use <code>tuneGrid</code> to specify the alpha and lambda tuning parameters. Specifically, type the name of the <code>expand.grid</code> function from base R with <code>alpha</code> set to 1 (<code>alpha=1</code>) as the first argument (to specify that we want a lasso regression model) and <code>lambda</code> set to <code>lambda_vector</code> (which is the vector of potential lambda values we generated) as the second argument. Behind the scenes, this specification of the <code>expand.grid</code> function creates a data frame with all of our potential lambda values as unique rows and alpha set as a constant of 1 for each corresponding row.</li>
<li>As the sixth argument, type <code>trControl=</code> followed by the name of the object that includes your <em>k</em>-fold cross-validation specifications, which we created above (<code>ctrlspecs</code>). As the final argument, specify <code>na.action=na.omit</code>, which will listwise delete any cases with missing data on any of the variables specified in the model; we dont have any missing data in our data, but if we did, we would need to specify this argument.</li>
<li>[When lasso regression models are estimated, the <code>train</code> function by default selects the optimal model based on <em>root mean-squared error (RMSE)</em>, but this can be changed to <em>R</em><sup>2</sup> by including the argument <code>weights="Rsquared"</code>.]</li>
</ul>
<p><em>Note:</em> Currently, available <code>caret</code> package models do not support maximum likelihood (ML) estimation, where ML has advantages when data are missing (completely) at random. It is beyond the scope of this tutorial to show how ML might be incorporated, but the <code>caret</code> package <a href="http://topepo.github.io/caret/using-your-own-model-in-train.html#introduction-1">handbook</a> has information on how you can specify your own model and presumably an outside estimator like ML.</p>
<div class="sourceCode" id="cb2080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2080-1"><a href="lassoregression.html#cb2080-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducible random selection and assignment operations</span></span>
<span id="cb2080-2"><a href="lassoregression.html#cb2080-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1985</span>)</span>
<span id="cb2080-3"><a href="lassoregression.html#cb2080-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2080-4"><a href="lassoregression.html#cb2080-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify lasso regression model to be estimated using training data</span></span>
<span id="cb2080-5"><a href="lassoregression.html#cb2080-5" aria-hidden="true" tabindex="-1"></a><span class="co"># and k-fold cross-validation process</span></span>
<span id="cb2080-6"><a href="lassoregression.html#cb2080-6" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">train</span>(y <span class="sc">~</span> ., </span>
<span id="cb2080-7"><a href="lassoregression.html#cb2080-7" aria-hidden="true" tabindex="-1"></a>                <span class="at">data=</span>train_df,</span>
<span id="cb2080-8"><a href="lassoregression.html#cb2080-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">preProcess=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>),</span>
<span id="cb2080-9"><a href="lassoregression.html#cb2080-9" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">&quot;glmnet&quot;</span>, </span>
<span id="cb2080-10"><a href="lassoregression.html#cb2080-10" aria-hidden="true" tabindex="-1"></a>                <span class="at">tuneGrid=</span><span class="fu">expand.grid</span>(<span class="at">alpha=</span><span class="dv">1</span>, <span class="at">lambda=</span>lambda_vector),</span>
<span id="cb2080-11"><a href="lassoregression.html#cb2080-11" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl=</span>ctrlspecs,</span>
<span id="cb2080-12"><a href="lassoregression.html#cb2080-12" aria-hidden="true" tabindex="-1"></a>                <span class="at">na.action=</span>na.omit)</span></code></pre></div>
<p>Our 10-fold cross-validation and model training process that we implemented above did the following. <em>First</em>, at each fold (i.e., resample), all possible lambda values from our <code>lambda_vector</code> object were evaluated based on the estimated models predictive accuracy/performance in the <em>k</em>th holdout validation sample for that fold, with model accuracy/performance signified by root mean-squared error (RMSE), <em>R</em><sup>2</sup> (Rsquared), and mean absolute error (MAE); however, by default, the training algorithm selected the lambda value in which RMSE, specifically, was lowest (i.e., minimized). As noted above, this evaluation criterion can be changed to <em>R</em><sup>2</sup> (Rsquared) by including the argument <code>weights="Rsquared"</code> in the <code>train</code> function. <em>Second</em>, after the first step was repeated for all 10 folds in the 10-fold cross-validation process, the average of the best lambda at each fold was computed to arrive at the optimal lambda. <em>Third</em>, a final lasso regression model was estimated based on the <em>complete</em> <code>train_df</code> data frame, and the optimal lambda value was applied to determine the final best model, including the regression coefficients; the final model accuracy/performance metrics (e.g., RMSE, Rsquared) represent an average of the metrics across the 10 folds based on the optimal lambda value applied to each fold.</p>
<p>Now its time to sift through the results. Lets begin by finding out what the optimal lambda value is based on the model training process we just carried out. To find out, we can specify the name of the model object we trained (<code>model1</code>) followed by the <code>$</code> operator and <code>bestTune</code>, which will retrieve the best alpha and lambda tuning parameter values. We already know alpha is equal to 1 because we set it as a constant to specify we wanted a lasso regression model, we but will anxiously await what the optimal lambda value is by running the following command.</p>
<div class="sourceCode" id="cb2081"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2081-1"><a href="lassoregression.html#cb2081-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Best tuning parameters (alpha, lambda)</span></span>
<span id="cb2081-2"><a href="lassoregression.html#cb2081-2" aria-hidden="true" tabindex="-1"></a>model1<span class="sc">$</span>bestTune</span></code></pre></div>
<pre><code>##     alpha    lambda
## 162     1 0.0168443</code></pre>
<p>As you can see in the output above, alpha is indeed 1, and the optimal lambda is .017 (after some rounding). Given that we really only wanted to know the optimal lambda value, we can request that directly by adding <code>$lambda</code> to the previous command.</p>
<div class="sourceCode" id="cb2083"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2083-1"><a href="lassoregression.html#cb2083-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Best lambda tuning parameter</span></span>
<span id="cb2083-2"><a href="lassoregression.html#cb2083-2" aria-hidden="true" tabindex="-1"></a>model1<span class="sc">$</span>bestTune<span class="sc">$</span>lambda</span></code></pre></div>
<pre><code>## [1] 0.0168443</code></pre>
<p>Next, lets look at the regression coefficients for the final model in which the optimal lambda value was applied. To do so, type the name of the <code>coef</code> function from base R, and as the first argument, specify the name of the model object we trained (<code>model1</code>) followed by the <code>$</code> operator and <code>finalModel</code>, where the latter calls up the final model estimated based on the complete <code>train_df</code> data frame as the final phase of the 10-fold cross-validation process. As the second argument, specify the name of the model object we trained (<code>model1</code>) followed by the <code>$</code> operator and <code>bestTune$lambda</code>, which when combined with the first argument, limits the retrieved regression coefficients to only those associated with the optimal lambda value.</p>
<div class="sourceCode" id="cb2085"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2085-1"><a href="lassoregression.html#cb2085-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso regression model coefficients</span></span>
<span id="cb2085-2"><a href="lassoregression.html#cb2085-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(model1<span class="sc">$</span>finalModel, model1<span class="sc">$</span>bestTune<span class="sc">$</span>lambda)</span></code></pre></div>
<pre><code>## 37 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                        1
## (Intercept)  0.001559301
## x1           0.105710879
## x2           0.132145274
## x3           0.076835793
## x4           0.137463746
## x5           .          
## x6           0.086437871
## x7           0.064530835
## x8           0.107235443
## x9           0.023979445
## x10          .          
## x11          .          
## x12          0.022841341
## x13         -0.005409866
## x14          0.070845008
## x15          .          
## x16          0.018059851
## x17          .          
## x18          0.038648205
## x19          0.036944920
## x20         -0.011799344
## x21          0.040398213
## x22          .          
## x23          .          
## x24          .          
## x25          .          
## x26          .          
## x27          .          
## x28          .          
## x29          0.027449222
## x30          .          
## x31          0.012105496
## x32          0.067979921
## x33         -0.003821760
## x34         -0.076544682
## x35         -0.049270620
## x36          0.075633216</code></pre>
<p>As you can see, the optimal lambda value shrunk a number of the regression coefficients to zero, where zero is represented by a period (<code>.</code>). In this way, you can see how lasso regression can be used for variable selection (i.e., feature selection), as only the most predictive predictor variables had non-zero regression coefficients.</p>
<p>The next step is not required, but I find it helpful to understand visually how the lambda value influences model prediction error (i.e., accuracy), as indicated by RMSE. For interpretation purposes, however, we perform a logarithmic transformation on the lambda values using the <code>log</code> function from base R. To create this data visualization, we will use the <code>plot</code> function from base R. As the first argument, introduce the <code>log</code> function with <code>model1$results$lambda</code> as the sole parenthetical argument, where the latter calls up our vector of 500 potential lambda values. As the second argument, type <code>model1$results$RMSE</code> to retrieve the vector of RMSE values (averaged across the 10 folds) based on applying each of our potential lambda values at each fold. As the third argument, well type <code>xlab=</code> followed by a meaningful label for the x-axis (in quotation marks). As the fourth argument, well type <code>ylab=</code> followed by a meaningful label for the y-axis (in quotation marks). As the final argument, I added <code>xlim=</code> followed by <code>c(-5, 0)</code> to constrain the x-axis limits to -5 and 0, respectively; you dont necessarily need to do this, and if you do, youll likely need to play around with those limits to find ones that focus in on the more meaningful areas of the plot.</p>
<div class="sourceCode" id="cb2087"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2087-1"><a href="lassoregression.html#cb2087-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot log(lambda) &amp; root mean-squared error (RMSE)</span></span>
<span id="cb2087-2"><a href="lassoregression.html#cb2087-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">log</span>(model1<span class="sc">$</span>results<span class="sc">$</span>lambda),</span>
<span id="cb2087-3"><a href="lassoregression.html#cb2087-3" aria-hidden="true" tabindex="-1"></a>     model1<span class="sc">$</span>results<span class="sc">$</span>RMSE,</span>
<span id="cb2087-4"><a href="lassoregression.html#cb2087-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;log(lambda)&quot;</span>,</span>
<span id="cb2087-5"><a href="lassoregression.html#cb2087-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Root Mean-Squared Error (RMSE)&quot;</span>,</span>
<span id="cb2087-6"><a href="lassoregression.html#cb2087-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">0</span>)</span>
<span id="cb2087-7"><a href="lassoregression.html#cb2087-7" aria-hidden="true" tabindex="-1"></a>     )</span></code></pre></div>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-1261-1.png" width="672" /></p>
<p>Remember, our goal is to minimize model prediction error and, specifically, RMSE. As you can see in the plot above, the lowest RMSE value (~ .84) seems to occur around a log(lambda) value of approximately -4 or so. To see what that exact value is, lets apply a logarithmic transformation to our optimal lambda using the <code>log</code> function.</p>
<div class="sourceCode" id="cb2088"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2088-1"><a href="lassoregression.html#cb2088-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Best tuned lambda</span></span>
<span id="cb2088-2"><a href="lassoregression.html#cb2088-2" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(model1<span class="sc">$</span>bestTune<span class="sc">$</span>lambda)</span></code></pre></div>
<pre><code>## [1] -4.083743</code></pre>
<p>As you can see, the log of our lambda is -4.084 (with rounding), which aligns with our visual estimate from the plot of about -4.</p>
<p>Interestingly, I havent been able to find an existing function or command associated with the <code>caret</code> package and the <code>glmnet</code> model function that makes just the average RMSE and Rsquared values across the <em>k</em> (i.e., 10) folds easily accessible, and specifically for the optimal lambda value. Thus, were going to do this the old-fashioned way (or at least more cumbersome way) by creating our own functions to carry out those operations. For space considerations, Im not going to explain each aspect of the functions, but I encourage you to take a peek at the operations within the braces (<code>{ }</code>) to see if you can follow the logic.</p>
<p>First, lets create a function called <code>RMSE_lasso</code>.</p>
<div class="sourceCode" id="cb2090"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2090-1"><a href="lassoregression.html#cb2090-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create function to identify RMSE for best lambda, </span></span>
<span id="cb2090-2"><a href="lassoregression.html#cb2090-2" aria-hidden="true" tabindex="-1"></a><span class="co"># where x = RMSE vector, y = lambda vector, &amp;  z = optimal lambda value</span></span>
<span id="cb2090-3"><a href="lassoregression.html#cb2090-3" aria-hidden="true" tabindex="-1"></a>RMSE_lasso <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y, z){</span>
<span id="cb2090-4"><a href="lassoregression.html#cb2090-4" aria-hidden="true" tabindex="-1"></a>  temp <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x, y)</span>
<span id="cb2090-5"><a href="lassoregression.html#cb2090-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(temp) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;RMSE&quot;</span>, <span class="st">&quot;lambda_val&quot;</span>)</span>
<span id="cb2090-6"><a href="lassoregression.html#cb2090-6" aria-hidden="true" tabindex="-1"></a>  rownum <span class="ot">&lt;-</span> <span class="fu">which</span>(temp<span class="sc">$</span>lambda_val<span class="sc">==</span>z)</span>
<span id="cb2090-7"><a href="lassoregression.html#cb2090-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(temp[rownum,]<span class="sc">$</span>RMSE)</span>
<span id="cb2090-8"><a href="lassoregression.html#cb2090-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Now, lets apply the <code>RMSE_lasso</code> to our data by plugging the RMSE and lambda vectors from our final model, along with the optimal lambda value.</p>
<div class="sourceCode" id="cb2091"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2091-1"><a href="lassoregression.html#cb2091-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply newly created Rsquared_lasso function</span></span>
<span id="cb2091-2"><a href="lassoregression.html#cb2091-2" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE_lasso</span>(<span class="at">x=</span>model1<span class="sc">$</span>results<span class="sc">$</span>RMSE,         <span class="co"># x = RMSE vector</span></span>
<span id="cb2091-3"><a href="lassoregression.html#cb2091-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">y=</span>model1<span class="sc">$</span>results<span class="sc">$</span>lambda,   <span class="co"># y = lambda vector</span></span>
<span id="cb2091-4"><a href="lassoregression.html#cb2091-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">z=</span>model1<span class="sc">$</span>bestTune<span class="sc">$</span>lambda)  <span class="co"># z = optimal lambda value</span></span></code></pre></div>
<pre><code>## [1] 0.8400556</code></pre>
<p>Our RMSE value based on the final model with the optimal lambda is .840 (with rounding).</p>
<p>Second, lets create a function called <code>Rsquared_lasso</code></p>
<div class="sourceCode" id="cb2093"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2093-1"><a href="lassoregression.html#cb2093-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create function to identify Rsquared for best lambda, </span></span>
<span id="cb2093-2"><a href="lassoregression.html#cb2093-2" aria-hidden="true" tabindex="-1"></a><span class="co"># where x = Rsquared vector, y = lambda vector, &amp;  z = optimal lambda value</span></span>
<span id="cb2093-3"><a href="lassoregression.html#cb2093-3" aria-hidden="true" tabindex="-1"></a>Rsquared_lasso <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y, z){</span>
<span id="cb2093-4"><a href="lassoregression.html#cb2093-4" aria-hidden="true" tabindex="-1"></a>  temp <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x, y)</span>
<span id="cb2093-5"><a href="lassoregression.html#cb2093-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(temp) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rsquared&quot;</span>, <span class="st">&quot;lambda_val&quot;</span>)</span>
<span id="cb2093-6"><a href="lassoregression.html#cb2093-6" aria-hidden="true" tabindex="-1"></a>  rownum <span class="ot">&lt;-</span> <span class="fu">which</span>(temp<span class="sc">$</span>lambda_val<span class="sc">==</span>z)</span>
<span id="cb2093-7"><a href="lassoregression.html#cb2093-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(temp[rownum,]<span class="sc">$</span>Rsquared)</span>
<span id="cb2093-8"><a href="lassoregression.html#cb2093-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Now, lets apply the <code>Rsquared_lasso</code> to our data by plugging the Rsquared and lambda vectors from our final model, along with the optimal lambda value.</p>
<div class="sourceCode" id="cb2094"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2094-1"><a href="lassoregression.html#cb2094-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply newly created Rsquared_lasso function</span></span>
<span id="cb2094-2"><a href="lassoregression.html#cb2094-2" aria-hidden="true" tabindex="-1"></a><span class="fu">Rsquared_lasso</span>(<span class="at">x=</span>model1<span class="sc">$</span>results<span class="sc">$</span>Rsquared, <span class="co"># x = Rsquared vector</span></span>
<span id="cb2094-3"><a href="lassoregression.html#cb2094-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">y=</span>model1<span class="sc">$</span>results<span class="sc">$</span>lambda,   <span class="co"># y = lambda vector</span></span>
<span id="cb2094-4"><a href="lassoregression.html#cb2094-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">z=</span>model1<span class="sc">$</span>bestTune<span class="sc">$</span>lambda)  <span class="co"># z = optimal lambda value</span></span></code></pre></div>
<pre><code>## [1] 0.4150716</code></pre>
<p>Our Rsquared value based on the final model with the optimal lambda is .415 (with rounding). Well revisit these <code>RMSE_lasso</code> and <code>Rsquared_lasso</code> functions a little bit later on in this tutorial.</p>
<p>Moving on, lets investigate the regression coefficients from our final model based on the optimal lambda value. Specifically, we will evaluate the importance of the various predictor variables in our model. Variables with higher importance values contribute more to estimation. To do so, well use the <code>varImp</code> function from the <code>caret</code> package, and as the sole parenthetical argument, we will type the name of our trained model (<code>model1</code>).</p>
<div class="sourceCode" id="cb2096"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2096-1"><a href="lassoregression.html#cb2096-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate the importance of different predictor variables</span></span>
<span id="cb2096-2"><a href="lassoregression.html#cb2096-2" aria-hidden="true" tabindex="-1"></a><span class="fu">varImp</span>(model1)</span></code></pre></div>
<pre><code>## glmnet variable importance
## 
##   only 20 most important variables shown (out of 36)
## 
##     Overall
## x4  100.000
## x2   96.131
## x8   78.010
## x1   76.901
## x6   62.880
## x3   55.895
## x34  55.684
## x36  55.020
## x14  51.537
## x32  49.453
## x7   46.944
## x35  35.843
## x21  29.388
## x18  28.115
## x19  26.876
## x29  19.968
## x9   17.444
## x12  16.616
## x16  13.138
## x31   8.806</code></pre>
<p>As you can see, variables <code>x4</code> and <code>x2</code> are two of the most important predictor variables in terms of estimating the outcome variable <code>y</code>. Lets create a horizontal bar chart to view these same results. Simply call up the <code>ggplot2</code> package using the <code>library</code> function from base R (and if you havent already, be sure to install the package first: <code>install.packages("ggplot2")</code>). Next, type the name of the <code>ggplot</code> function with <code>varImp</code> function we specified above as the sole parenthetical argument.</p>
<div class="sourceCode" id="cb2098"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2098-1"><a href="lassoregression.html#cb2098-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the importance of different predictor variables</span></span>
<span id="cb2098-2"><a href="lassoregression.html#cb2098-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb2098-3"><a href="lassoregression.html#cb2098-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">varImp</span>(model1))</span></code></pre></div>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-1268-1.png" width="672" /></p>
<p>Note that the y-axis is labeled Feature, which is just another way of saying predictor variable in this context.</p>
<p>Remember way back when in this tutorial when we partitioned our data into the <code>train_df</code> and <code>test_df</code>? Well, now we are going to apply our lasso regression model that we trained using <em>k</em>-fold cross-validation and the <code>train_df</code> data frame to our <code>test_df</code> data frame. First, using our final lasso regression model, we need to estimate predicted values for individuals scores on <code>y</code> based the predictor variable values in the <code>test_df</code> data. Lets call the object to which we will assign these predictions <code>predictions</code> by using the <code>&lt;-</code> operator. To the right of the <code>&lt;-</code> operator, type the name of the <code>predict</code> function from base R. As the first argument, type the name of the model object we built using the <code>train</code> function (<code>model1</code>). As the second argument, type <code>newdata=</code> followed by the name of the testing data frame (<code>test_df</code>).</p>
<div class="sourceCode" id="cb2099"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2099-1"><a href="lassoregression.html#cb2099-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict outcome using model from training data based on testing data</span></span>
<span id="cb2099-2"><a href="lassoregression.html#cb2099-2" aria-hidden="true" tabindex="-1"></a>predictions1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model1, <span class="at">newdata=</span>test_df)</span></code></pre></div>
<p>Next, lets calculate the RMSE and Rsquared values based on our predictions. At this point, you might be saying, Wait, didnt we just do that a few steps earlier? Well, yes, we did previously compute RMSE and Rsquared values based on our optimal lambda value, but we did so based on the <code>train_df</code> data frame, and these values represent their averages across the <em>k</em> (i.e., 10) folds for the given lambda value. The RMSE and Rsquared values we are about to compute differ because they will be based on how well our final model predicts the outcome when applied to the holdout <code>test_df</code> data frame.</p>
<p>We will use the <code>&lt;-</code> operator to name the data frame object containing the RMSE and Rsquared values, which we can reference later on; lets call this object <code>mod1perf</code>. To the right of the <code>&lt;-</code> operator, type the name of the <code>data.frame</code> function from base R, which will allow us to create a data frame object. As the first argument, lets create the first column of data and name this column <code>RMSE</code> followed by the <code>=</code> operator and the <code>RMSE</code> function from <code>caret</code> with our <code>predictions1</code> vector as the first argument and the vector containing our outcome (<code>y</code>) values from our <code>test_df</code> data frame as the second argument (<code>test_df$y</code>). As the second argument of the <code>data.frame</code> function, create the second column of data and name this column <code>Rsquared</code> followed by the <code>=</code> operator and the <code>R2</code> function from <code>caret</code> with our <code>predictions1</code> vector as the first argument and the vector containing our outcome (<code>y</code>) values from our <code>test_df</code> data frame as the second argument (<code>test_df$y</code>). As a final step, use the <code>print</code> function from base R to print the <code>mod1perf</code> data frame object to our console.</p>
<div class="sourceCode" id="cb2100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2100-1"><a href="lassoregression.html#cb2100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model performance/accuracy</span></span>
<span id="cb2100-2"><a href="lassoregression.html#cb2100-2" aria-hidden="true" tabindex="-1"></a>mod1perf <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">RMSE=</span><span class="fu">RMSE</span>(predictions1, test_df<span class="sc">$</span>y),</span>
<span id="cb2100-3"><a href="lassoregression.html#cb2100-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">Rsquared=</span><span class="fu">R2</span>(predictions1, test_df<span class="sc">$</span>y))</span>
<span id="cb2100-4"><a href="lassoregression.html#cb2100-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2100-5"><a href="lassoregression.html#cb2100-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model performance/accuracy results</span></span>
<span id="cb2100-6"><a href="lassoregression.html#cb2100-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mod1perf)</span></code></pre></div>
<pre><code>##        RMSE  Rsquared
## 1 0.8219381 0.4700103</code></pre>
<p>As you can see, using predictive analytics, we found that our lasso regression model yielded an RMSE of .822 and an Rsquared of .470 (with rounding) when applied to the holdout <code>test_df</code> data frame. Note that our RMSE value is lower and our Rsquared value is higher when we apply the model to new data (<code>test_df</code>), as compared to the same values based on the old data (<code>train_df</code>); this illustrates one of the advantages of using <em>k</em>-fold cross-validation and lasso regression, as they help to reduce shrinkage in terms of model fit/performance when a model is applied to new data. Below I provide some generic benchmarks for interpreting the practical significance of the Rsquared (<em>R</em><sup>2</sup>) values.</p>
<table>
<thead>
<tr class="header">
<th><em>R</em><sup>2</sup></th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>.01</td>
<td>Small</td>
</tr>
<tr class="even">
<td>.09</td>
<td>Medium</td>
</tr>
<tr class="odd">
<td>.25</td>
<td>Large</td>
</tr>
</tbody>
</table>
<p>Finally, we can also estimate 95% prediction intervals.</p>
<div class="sourceCode" id="cb2102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2102-1"><a href="lassoregression.html#cb2102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate 95% prediction intervals</span></span>
<span id="cb2102-2"><a href="lassoregression.html#cb2102-2" aria-hidden="true" tabindex="-1"></a>pred.int <span class="ot">&lt;-</span> <span class="fu">predict</span>(model1, <span class="at">newdata=</span>test_df, <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb2102-3"><a href="lassoregression.html#cb2102-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2102-4"><a href="lassoregression.html#cb2102-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Join fitted (predicted) values and upper and lower prediction interval values to data frame</span></span>
<span id="cb2102-5"><a href="lassoregression.html#cb2102-5" aria-hidden="true" tabindex="-1"></a>test_df <span class="ot">&lt;-</span> <span class="fu">cbind</span>(test_df, pred.int)</span>
<span id="cb2102-6"><a href="lassoregression.html#cb2102-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2102-7"><a href="lassoregression.html#cb2102-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print first 6 rows</span></span>
<span id="cb2102-8"><a href="lassoregression.html#cb2102-8" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(test_df)</span></code></pre></div>
<pre><code>##         y     x1     x2     x3     x4     x5     x6     x7     x8     x9    x10    x11    x12    x13
## 6  -0.458 -0.619 -1.822 -1.348 -0.036 -3.787 -2.025 -0.072 -1.263 -0.999 -1.121 -2.608 -1.849 -2.163
## 12 -0.150  0.841  0.449  0.574  0.762  0.741 -0.511  0.062  1.318  1.177 -0.842 -0.953 -0.824  0.603
## 19 -0.182  0.039 -0.283 -0.512 -0.872 -0.650  0.485 -1.231 -1.971  0.936 -0.749 -1.812 -0.138 -1.548
## 25  2.373  1.123  1.160  0.310  1.276  0.422  1.447  0.328  0.777  0.713  0.409  0.823  1.081  2.032
## 33  2.304  0.535  0.626 -0.031 -0.231  1.821 -0.836  0.147  1.840  1.076 -0.835  0.040  0.143 -0.403
## 37  0.679  0.843  0.730  0.469  0.840  0.085  0.670  0.930  0.894  1.584  0.605  0.331  0.578 -0.761
##       x14    x15    x16    x17    x18    x19    x20    x21    x22    x23    x24    x25    x26    x27
## 6   0.311 -5.685 -0.409 -0.999 -3.667 -0.419 -0.516 -1.090 -0.493 -0.106 -2.004  0.371  0.561 -0.411
## 12 -0.106  0.264  0.605 -2.714  0.646 -0.236 -1.133 -0.216 -0.014 -0.242 -0.227  0.860 -0.279  0.088
## 19  0.646 -0.769  0.630  5.730  4.166  0.202  0.812 -1.785 -1.057 -0.014 -0.128 -2.299  0.027 -0.778
## 25  3.576 -0.527  0.566  2.347  5.440  0.259 -1.100  0.179 -0.497 -1.819 -0.033 -0.031  0.596  0.835
## 33 -2.242  0.355  0.407  3.195  1.348 -0.042 -0.475  0.488 -0.117  2.058 -0.186 -0.450  0.758 -0.999
## 37  2.498  3.071  0.546  6.986 -1.552  0.183  1.617  1.013  1.045 -1.877  0.354  1.543 -0.803  0.082
##       x28    x29    x30    x31    x32    x33    x34    x35    x36     pred.int
## 6  -2.154  0.332 -0.683  0.592 -1.762 -1.748  2.331 -1.404 -2.973 -1.147386264
## 12  1.367 -2.066 -0.651 -0.750  0.483 -0.142  2.579  0.310 -2.223 -0.003962978
## 19  0.615 -2.827 -1.479  0.832 -0.736 -0.856 -0.351 -2.330 -1.208 -0.325320211
## 25 -0.113  0.394 -1.702  0.701  1.204  0.844 -0.205  0.257  2.426  1.148565410
## 33  1.564 -0.949  1.817  1.786  1.041 -0.176 -0.525  2.055  0.232  0.153837839
## 37 -0.748  1.446 -0.856 -0.214  0.572  2.362  1.199  1.440  1.778  0.690189801</code></pre>
</div>
<div id="compare_ols_lasso" class="section level3" number="53.2.8">
<h3><span class="header-section-number">53.2.8</span> Optional: Compare to Lasso Model to OLS Multiple Linear Regression Model</h3>
<p>This next section is optional, so proceed if you wish. In the event you are interested, we will learn how to train a conventional ordinary least squares (OLS) multiple linear regression (MLR) model based on the same variables that we used for the LASSO regression. Further, just like we did with LASSO regression, we will train the OLS MLR model using <em>k</em>-fold cross-validation. If you need a refresher on OLS MLR, please refer to the <a href="incrementalvalidity.html#incrementalvalidity">chapter on estimating incremental validity using multiple linear regression</a>. Note, however, that when using <em>k</em>-fold cross-validation for an OLS MLR model (or other non-machine learning model), we are really just interested in getting a glimpse at how well the model will likely perform when given new data at a later time.</p>
<p>We will use the same <em>k</em>-fold cross-validation specifications object that we created for our LASSO regression model training (<code>ctrlspecs</code>), so if youre starting a fresh section with this section, then you will need to go to the previous section in this section in which we created the <code>ctrlspecs</code> object and run it.</p>
<p>Just as we did before, be sure to set a seed using the <code>set.seed</code> function prior to training your model. Lets call this OLS MLR training model object <code>model2</code> using the <code>&lt;-</code> operator. To the right of the <code>&lt;-</code>, type the name of the <code>train</code> function from the <code>caret</code> package. With the exception of the <code>method="lm"</code> argument, the rest of the arguments should look familiar. The <code>method="lm"</code> argument simply tells the function that we want to use the <code>lm</code> (linear model) function from base R to estimate our OLS MLR model. After specifying the <code>train</code> function and creating the <code>model2</code> object, use the <code>print</code> function to print the results of the model to your console.</p>
<div class="sourceCode" id="cb2104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2104-1"><a href="lassoregression.html#cb2104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducible random selection and assignment operations</span></span>
<span id="cb2104-2"><a href="lassoregression.html#cb2104-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1985</span>)</span>
<span id="cb2104-3"><a href="lassoregression.html#cb2104-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2104-4"><a href="lassoregression.html#cb2104-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify OLS MLR model to be estimated using training data</span></span>
<span id="cb2104-5"><a href="lassoregression.html#cb2104-5" aria-hidden="true" tabindex="-1"></a><span class="co"># and k-fold cross-validation process</span></span>
<span id="cb2104-6"><a href="lassoregression.html#cb2104-6" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">train</span>(y <span class="sc">~</span> ., </span>
<span id="cb2104-7"><a href="lassoregression.html#cb2104-7" aria-hidden="true" tabindex="-1"></a>                <span class="at">data=</span>train_df,</span>
<span id="cb2104-8"><a href="lassoregression.html#cb2104-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">preProcess=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>),</span>
<span id="cb2104-9"><a href="lassoregression.html#cb2104-9" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">&quot;lm&quot;</span>, </span>
<span id="cb2104-10"><a href="lassoregression.html#cb2104-10" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl=</span>ctrlspecs,</span>
<span id="cb2104-11"><a href="lassoregression.html#cb2104-11" aria-hidden="true" tabindex="-1"></a>                <span class="at">na.action=</span>na.omit)</span>
<span id="cb2104-12"><a href="lassoregression.html#cb2104-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2104-13"><a href="lassoregression.html#cb2104-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Model fit</span></span>
<span id="cb2104-14"><a href="lassoregression.html#cb2104-14" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(model2)</span></code></pre></div>
<pre><code>## Linear Regression 
## 
## 801 samples
##  36 predictor
## 
## Pre-processing: centered (36), scaled (36) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 721, 721, 721, 721, 720, 721, ... 
## Resampling results:
## 
##   RMSE       Rsquared   MAE      
##   0.8467902  0.4069315  0.6730339
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<p>As you can see in the output, the average RMSE across the 10 folds is .847, and the average Rsquared is .407.</p>
<p>Lets take a peek at the regression coefficients for the OLS MLR model estimated based on the entire <code>train_df</code> data frame. To do so, type the name of the <code>summary</code> function from base R with the name of the model object (<code>model2</code>) as the sole parenthetical argument.</p>
<div class="sourceCode" id="cb2106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2106-1"><a href="lassoregression.html#cb2106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS MLR model coefficients with statistical significance tests</span></span>
<span id="cb2106-2"><a href="lassoregression.html#cb2106-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = .outcome ~ ., data = dat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.31440 -0.54251  0.05817  0.52693  2.95915 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  0.0015593  0.0292866   0.053  0.95755   
## x1           0.1064869  0.0393948   2.703  0.00702 **
## x2           0.1288509  0.0415154   3.104  0.00198 **
## x3           0.0844271  0.0405929   2.080  0.03787 * 
## x4           0.1374366  0.0444428   3.092  0.00206 **
## x5           0.0037226  0.0403916   0.092  0.92659   
## x6           0.0900118  0.0422154   2.132  0.03331 * 
## x7           0.0797314  0.0417962   1.908  0.05681 . 
## x8           0.1052692  0.0391978   2.686  0.00740 **
## x9           0.0231167  0.0409762   0.564  0.57282   
## x10         -0.0245487  0.0410393  -0.598  0.54990   
## x11          0.0115515  0.0406161   0.284  0.77618   
## x12          0.0429262  0.0421068   1.019  0.30831   
## x13         -0.0540795  0.0401108  -1.348  0.17798   
## x14          0.0920183  0.0368723   2.496  0.01278 * 
## x15         -0.0131627  0.0394906  -0.333  0.73899   
## x16          0.0400716  0.0386785   1.036  0.30052   
## x17         -0.0157952  0.0380508  -0.415  0.67818   
## x18          0.0615636  0.0387173   1.590  0.11223   
## x19          0.0609104  0.0383000   1.590  0.11217   
## x20         -0.0390587  0.0392237  -0.996  0.31966   
## x21          0.0637443  0.0401520   1.588  0.11280   
## x22          0.0123254  0.0406316   0.303  0.76171   
## x23          0.0105869  0.0335785   0.315  0.75263   
## x24         -0.0135661  0.0406415  -0.334  0.73862   
## x25          0.0190199  0.0391689   0.486  0.62740   
## x26          0.0070111  0.0358145   0.196  0.84485   
## x27         -0.0001692  0.0408429  -0.004  0.99670   
## x28         -0.0403859  0.0392460  -1.029  0.30378   
## x29          0.0509068  0.0387079   1.315  0.18885   
## x30          0.0014375  0.0380287   0.038  0.96986   
## x31          0.0321008  0.0352222   0.911  0.36238   
## x32          0.0954990  0.0414220   2.306  0.02140 * 
## x33         -0.0488635  0.0407278  -1.200  0.23061   
## x34         -0.0911234  0.0355243  -2.565  0.01050 * 
## x35         -0.0815071  0.0400127  -2.037  0.04199 * 
## x36          0.0975800  0.0398941   2.446  0.01467 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8289 on 764 degrees of freedom
## Multiple R-squared:  0.4548, Adjusted R-squared:  0.4291 
## F-statistic:  17.7 on 36 and 764 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<p>The <code>summary</code> function provides us with the regression coefficients along with their statistical significance tests. Note that none of the regression coefficients are zeroed out, which contrasts with our final LASSO regression model. If you just want to call up the regression coefficients without their statistical significance tests, then just specify your model object (<code>model2</code>) followed by <code>$finalModel$coefficients</code>.</p>
<div class="sourceCode" id="cb2108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2108-1"><a href="lassoregression.html#cb2108-1" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS MLR model coefficients</span></span>
<span id="cb2108-2"><a href="lassoregression.html#cb2108-2" aria-hidden="true" tabindex="-1"></a>model2<span class="sc">$</span>finalModel<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##   (Intercept)            x1            x2            x3            x4            x5            x6 
##  0.0015593009  0.1064868762  0.1288508857  0.0844271182  0.1374366297  0.0037225690  0.0900118226 
##            x7            x8            x9           x10           x11           x12           x13 
##  0.0797314105  0.1052691528  0.0231166560 -0.0245487466  0.0115514738  0.0429261616 -0.0540795343 
##           x14           x15           x16           x17           x18           x19           x20 
##  0.0920183162 -0.0131626874  0.0400715853 -0.0157952042  0.0615636356  0.0609103741 -0.0390587426 
##           x21           x22           x23           x24           x25           x26           x27 
##  0.0637442959  0.0123254180  0.0105869070 -0.0135661097  0.0190199415  0.0070111163 -0.0001692177 
##           x28           x29           x30           x31           x32           x33           x34 
## -0.0403859078  0.0509067573  0.0014374660  0.0321007692  0.0954989890 -0.0488634949 -0.0911234150 
##           x35           x36 
## -0.0815070991  0.0975800099</code></pre>
<p>Now its time to compare our lasso regression model (<code>model1</code>) with our OLS MLR model (<code>model2</code>), and well start by comparing how well the models performed on the training data during the 10-fold cross-validation process. Ill show you two ways in which you can compile this information.</p>
<p>For the first approach, we will use the <code>list</code> function from base R. Enter the name of the first model (<code>model1</code>) as the first argument and the name of the second model (<code>model2</code>) as the second argument. Assign this list object to an object well call <code>model_list</code> using the <code>&lt;-</code> operator. Next, we will type the name of the <code>resamples</code> object from the <code>caret</code> package with our <code>model_list</code> object as the sole parenthetical argument, and we will assign the results of this function to an object well call <code>resamp</code>; the <code>resamples</code> function collates the model performance metrics (i.e., mean absolute error [MAE], RMSE, Rsquared) across the folds of the <em>k</em>-fold cross-validations for us. Finally, as the last step, enter the <code>resamp</code> object as the sole parenthetical argument in the <code>summary</code> function.</p>
<div class="sourceCode" id="cb2110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2110-1"><a href="lassoregression.html#cb2110-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare model performance of k-fold cross-validation on train_df</span></span>
<span id="cb2110-2"><a href="lassoregression.html#cb2110-2" aria-hidden="true" tabindex="-1"></a>model_list <span class="ot">&lt;-</span> <span class="fu">list</span>(model1, model2)</span>
<span id="cb2110-3"><a href="lassoregression.html#cb2110-3" aria-hidden="true" tabindex="-1"></a>resamp <span class="ot">&lt;-</span> <span class="fu">resamples</span>(model_list)</span>
<span id="cb2110-4"><a href="lassoregression.html#cb2110-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(resamp)</span></code></pre></div>
<pre><code>## 
## Call:
## summary.resamples(object = resamp)
## 
## Models: Model1, Model2 
## Number of resamples: 10 
## 
## MAE 
##             Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## Model1 0.6001450 0.6485866 0.6542165 0.6676563 0.6872213 0.7584773    0
## Model2 0.6087479 0.6460566 0.6594453 0.6730339 0.6904705 0.7568991    0
## 
## RMSE 
##             Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## Model1 0.7564365 0.8136099 0.8355552 0.8400556 0.8681174 0.9250472    0
## Model2 0.7665855 0.8211470 0.8463947 0.8467902 0.8670284 0.9312064    0
## 
## Rsquared 
##             Min.   1st Qu.    Median      Mean  3rd Qu.      Max. NA&#39;s
## Model1 0.2692479 0.3360087 0.4404051 0.4150716 0.487333 0.5324680    0
## Model2 0.2510815 0.3348805 0.4255335 0.4069315 0.473309 0.5384864    0</code></pre>
<p>As you can see, the model performance metrics are grouped into MAE, RMSE, and Rsquared for <code>Model1</code> and <code>Model2</code>. For <code>Model1</code>, the Mean column provides the average model performance metric value across the 10 folds (i.e., resamples) for the optimal lambda tuning parameter value. For <code>Model2</code>, the Mean column provides the average model performance metric value across the 10 folds. As you can see, <code>Model1</code> (which is the lasso regression model) has a slightly lower RMSE value and a slightly higher Rsquared value, which indicates better model performance with the training data (<code>train_df</code>).</p>
<p>If youd like to create a single trimmed down table of the different RMSE and Rsquared values for <code>model1</code> and <code>model2</code>, you can create a matrix object using the <code>matrix</code> function from base R. Well call this matrix object <code>comp</code> using the <code>&lt;-</code> operator. As the first argument in the <code>matrix</code> function, type the <code>c</code> (combine) function, with the values for the lasso regression RMSE and Rsquared followed by the same metric values for the OLS MLR, for a total of four arguments. Note that for the LASSO regression RMSE and Rsquared values, I have entered the <code>RMSE_lasso</code> and <code>Rsquared_lasso</code> functions we created previously. As the second argument in the <code>matrix</code> object, indicate there are two columns (i.e., one for RMSE values and one for Rsquared values). As the final argument, type <code>byrow=TRUE</code> argument to indicate that the matrix will be filled by rows. As a next step, name the columns and rows of the matrix object using the <code>colnames</code> and <code>rownames</code> functions from base R. After that, use the <code>as.table</code> function to convert the matrix to a table object. Finally, use the <code>round</code> function to display on three places after the decimal in the table.</p>
<div class="sourceCode" id="cb2112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2112-1"><a href="lassoregression.html#cb2112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create matrix to compare model performance based on train_df</span></span>
<span id="cb2112-2"><a href="lassoregression.html#cb2112-2" aria-hidden="true" tabindex="-1"></a>comp <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(</span>
<span id="cb2112-3"><a href="lassoregression.html#cb2112-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">RMSE_lasso</span>(<span class="at">x=</span>model1<span class="sc">$</span>results<span class="sc">$</span>RMSE,</span>
<span id="cb2112-4"><a href="lassoregression.html#cb2112-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">y=</span>model1<span class="sc">$</span>results<span class="sc">$</span>lambda,</span>
<span id="cb2112-5"><a href="lassoregression.html#cb2112-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">z=</span>model1<span class="sc">$</span>bestTune<span class="sc">$</span>lambda),</span>
<span id="cb2112-6"><a href="lassoregression.html#cb2112-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Rsquared_lasso</span>(<span class="at">x=</span>model1<span class="sc">$</span>results<span class="sc">$</span>Rsquared,</span>
<span id="cb2112-7"><a href="lassoregression.html#cb2112-7" aria-hidden="true" tabindex="-1"></a>                 <span class="at">y=</span>model1<span class="sc">$</span>results<span class="sc">$</span>lambda,</span>
<span id="cb2112-8"><a href="lassoregression.html#cb2112-8" aria-hidden="true" tabindex="-1"></a>                 <span class="at">z=</span>model1<span class="sc">$</span>bestTune<span class="sc">$</span>lambda), </span>
<span id="cb2112-9"><a href="lassoregression.html#cb2112-9" aria-hidden="true" tabindex="-1"></a>  model2<span class="sc">$</span>results<span class="sc">$</span>RMSE, </span>
<span id="cb2112-10"><a href="lassoregression.html#cb2112-10" aria-hidden="true" tabindex="-1"></a>  model2<span class="sc">$</span>results<span class="sc">$</span>Rsquared),</span>
<span id="cb2112-11"><a href="lassoregression.html#cb2112-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">ncol=</span><span class="dv">2</span>,</span>
<span id="cb2112-12"><a href="lassoregression.html#cb2112-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">byrow=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 0.8400556
## [1] 0.4150716</code></pre>
<div class="sourceCode" id="cb2114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2114-1"><a href="lassoregression.html#cb2114-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Name the columns and rows of comp matrix object</span></span>
<span id="cb2114-2"><a href="lassoregression.html#cb2114-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(comp) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;RMSE&quot;</span>,<span class="st">&quot;R-square&quot;</span>)</span>
<span id="cb2114-3"><a href="lassoregression.html#cb2114-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(comp) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;LASSO Regression&quot;</span>,<span class="st">&quot;OLS Linear Regression&quot;</span>)</span>
<span id="cb2114-4"><a href="lassoregression.html#cb2114-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2114-5"><a href="lassoregression.html#cb2114-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert matrix to a table</span></span>
<span id="cb2114-6"><a href="lassoregression.html#cb2114-6" aria-hidden="true" tabindex="-1"></a>comp <span class="ot">&lt;-</span> <span class="fu">as.table</span>(comp)</span>
<span id="cb2114-7"><a href="lassoregression.html#cb2114-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2114-8"><a href="lassoregression.html#cb2114-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Round table values to three places after decimal</span></span>
<span id="cb2114-9"><a href="lassoregression.html#cb2114-9" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(comp, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##                        RMSE R-square
## LASSO Regression      0.840    0.415
## OLS Linear Regression 0.847    0.407</code></pre>
<p>If you would like to know whether the estimated RMSE and Rsquared values from the 10 folds for the <code>model1</code> 10-fold cross-validation differ significantly from the estimated RMSE and Rsquared values from the 10 folds for the <code>model2</code> 10-fold cross-validation, we can use the <code>compare_models</code> function from the <code>caret</code> package. Simply enter the model object names as the first two arguments and <code>metric="RMSE"</code>or <code>metric="Rsquared"</code> as the third argument. This function applies a paired-samples (i.e., one-sample) <em>t</em>-test to evaluate with the mean of the differences between the two models performance metric values (across the 10 folds) differs significantly from zero.</p>
<div class="sourceCode" id="cb2116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2116-1"><a href="lassoregression.html#cb2116-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare models with paired-samples (one-sample) t-test</span></span>
<span id="cb2116-2"><a href="lassoregression.html#cb2116-2" aria-hidden="true" tabindex="-1"></a><span class="fu">compare_models</span>(model1, model2, <span class="at">metric=</span><span class="st">&quot;RMSE&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = -2.5958, df = 9, p-value = 0.02893
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -0.0126036525 -0.0008657173
## sample estimates:
##    mean of x 
## -0.006734685</code></pre>
<div class="sourceCode" id="cb2118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2118-1"><a href="lassoregression.html#cb2118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">compare_models</span>(model1, model2, <span class="at">metric=</span><span class="st">&quot;Rsquared&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 2.7233, df = 9, p-value = 0.02348
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  0.001378438 0.014901850
## sample estimates:
##   mean of x 
## 0.008140144</code></pre>
<p>As you can see, both <em>t</em>-tests indicate that <code>model1</code> outperformed <code>model2</code> in the training data <code>train_df</code> with respect to RMSE and Rsquared values.</p>
<p>As a final step, lets repeat what we did for our lasso regression model (<code>model1</code>) by seeing how well our OLS MLR model (<code>model2</code>) predicts the outcome <code>y</code> when we feed fresh data from the <code>test_df</code> into our model. As before, well create a data frame object (<code>mod2perf</code>) containing the RMSE and Rsquared values.</p>
<div class="sourceCode" id="cb2120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2120-1"><a href="lassoregression.html#cb2120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict outcome using model from training data based on testing data</span></span>
<span id="cb2120-2"><a href="lassoregression.html#cb2120-2" aria-hidden="true" tabindex="-1"></a>predictions2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model2, <span class="at">newdata=</span>test_df)</span>
<span id="cb2120-3"><a href="lassoregression.html#cb2120-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2120-4"><a href="lassoregression.html#cb2120-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Model performance</span></span>
<span id="cb2120-5"><a href="lassoregression.html#cb2120-5" aria-hidden="true" tabindex="-1"></a>mod2perf <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">RMSE=</span><span class="fu">RMSE</span>(predictions2, test_df<span class="sc">$</span>y),</span>
<span id="cb2120-6"><a href="lassoregression.html#cb2120-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">Rsquared=</span><span class="fu">R2</span>(predictions2, test_df<span class="sc">$</span>y))</span>
<span id="cb2120-7"><a href="lassoregression.html#cb2120-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2120-8"><a href="lassoregression.html#cb2120-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model performance results</span></span>
<span id="cb2120-9"><a href="lassoregression.html#cb2120-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mod2perf)</span></code></pre></div>
<pre><code>##        RMSE  Rsquared
## 1 0.8360987 0.4512161</code></pre>
<p>Using this predictive analytics approach, we found that our OLS MLR regression model yielded an RMSE of .836 and an Rsquared of .451 (with rounding) when applied to the holdout <code>test_df</code> data frame.</p>
<p>Lets see how well the OLS MLR regression model compares to our lasso regression model in terms of predictive performance/accuracy. To do so, well apply the <code>matrix</code>, <code>colnames</code>, <code>rownames</code>, <code>as.table</code>, and <code>round</code> functions, which are all from base R. These functions were explained previously in this tutorial, so if you have questions, venture back to their prior applications.</p>
<div class="sourceCode" id="cb2122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2122-1"><a href="lassoregression.html#cb2122-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare model1 and model2 predictive performance based on test_df</span></span>
<span id="cb2122-2"><a href="lassoregression.html#cb2122-2" aria-hidden="true" tabindex="-1"></a>comp2 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(mod1perf<span class="sc">$</span>RMSE, mod1perf<span class="sc">$</span>Rsquared,</span>
<span id="cb2122-3"><a href="lassoregression.html#cb2122-3" aria-hidden="true" tabindex="-1"></a>                  mod2perf<span class="sc">$</span>RMSE, mod2perf<span class="sc">$</span>Rsquared),</span>
<span id="cb2122-4"><a href="lassoregression.html#cb2122-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">ncol=</span><span class="dv">2</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb2122-5"><a href="lassoregression.html#cb2122-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2122-6"><a href="lassoregression.html#cb2122-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Name the columns and rows of comp matrix object</span></span>
<span id="cb2122-7"><a href="lassoregression.html#cb2122-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(comp2) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;RMSE&quot;</span>,<span class="st">&quot;R-square&quot;</span>)</span>
<span id="cb2122-8"><a href="lassoregression.html#cb2122-8" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(comp2) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;LASSO Regression&quot;</span>,<span class="st">&quot;OLS Multiple Linear Regression&quot;</span>)</span>
<span id="cb2122-9"><a href="lassoregression.html#cb2122-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2122-10"><a href="lassoregression.html#cb2122-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert matrix object to a table</span></span>
<span id="cb2122-11"><a href="lassoregression.html#cb2122-11" aria-hidden="true" tabindex="-1"></a>comp2 <span class="ot">&lt;-</span> <span class="fu">as.table</span>(comp2)</span>
<span id="cb2122-12"><a href="lassoregression.html#cb2122-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2122-13"><a href="lassoregression.html#cb2122-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Round table values to three places after decimal</span></span>
<span id="cb2122-14"><a href="lassoregression.html#cb2122-14" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(comp2, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##                                 RMSE R-square
## LASSO Regression               0.822    0.470
## OLS Multiple Linear Regression 0.836    0.451</code></pre>
<p>As displayed in the table, in terms of predictive performance/accuracy, the lasso regression model outperforms the OLS MLR regression model. That is, the lasso regression model learned a more predictive model.</p>
</div>
<div id="summary_lasso" class="section level3" number="53.2.9">
<h3><span class="header-section-number">53.2.9</span> Summary</h3>
<p>In this chapter, we learned how to train a linear lasso regression model using <em>k</em>-fold cross-validation and how to evaluate the model using holdout test data (i.e., predictive analytics). Further, we compared the predictive performance/accuracy of a lasso regression model to an ordinary least squares (OLS) multiple linear regression (MLR) model.</p>

</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="polynomialregression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="create-portfolio.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
