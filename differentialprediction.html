<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 42 Testing for Differential Prediction Using Moderated Multiple Linear Regression | R for HR: An Introduction to Human Resource Analytics Using R</title>
  <meta name="description" content="Human resource (HR) analytics is a growing area of HR manage, and the purpose of this book is to show how the R programming language can be used as tool to manage, analyze, and visualize HR data in order to derive insights and to inform decision making. [NOTE: This is Version 0.1.5 of this book, which means that the book is not yet in its final form, that it contains typographical errors, and that it may be expanded in the future.]" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 42 Testing for Differential Prediction Using Moderated Multiple Linear Regression | R for HR: An Introduction to Human Resource Analytics Using R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Human resource (HR) analytics is a growing area of HR manage, and the purpose of this book is to show how the R programming language can be used as tool to manage, analyze, and visualize HR data in order to derive insights and to inform decision making. [NOTE: This is Version 0.1.5 of this book, which means that the book is not yet in its final form, that it contains typographical errors, and that it may be expanded in the future.]" />
  <meta name="github-repo" content="davidcaughlin/R-for-HR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 42 Testing for Differential Prediction Using Moderated Multiple Linear Regression | R for HR: An Introduction to Human Resource Analytics Using R" />
  
  <meta name="twitter:description" content="Human resource (HR) analytics is a growing area of HR manage, and the purpose of this book is to show how the R programming language can be used as tool to manage, analyze, and visualize HR data in order to derive insights and to inform decision making. [NOTE: This is Version 0.1.5 of this book, which means that the book is not yet in its final form, that it contains typographical errors, and that it may be expanded in the future.]" />
  

<meta name="author" content="David E. Caughlin" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiplecutoff.html"/>
<link rel="next" href="crossvalidation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R for HR</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#hragrowth"><i class="fa fa-check"></i><b>0.1</b> Growth of HR Analytics</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#hranalytics_skillsgap"><i class="fa fa-check"></i><b>0.2</b> Skills Gap</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#hraplc"><i class="fa fa-check"></i><b>0.3</b> Project Life Cycle Perspective</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#hranalytics_hris_overview"><i class="fa fa-check"></i><b>0.4</b> Overview of HRIS &amp; HR Analytics</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#philosophy"><i class="fa fa-check"></i><b>0.5</b> My Philosophy for This Book</a>
<ul>
<li class="chapter" data-level="0.5.1" data-path="index.html"><a href="index.html#rationalerpref"><i class="fa fa-check"></i><b>0.5.1</b> Rationale for Using R</a></li>
<li class="chapter" data-level="0.5.2" data-path="index.html"><a href="index.html#audiencepref"><i class="fa fa-check"></i><b>0.5.2</b> Audience</a></li>
</ul></li>
<li class="chapter" data-level="0.6" data-path="index.html"><a href="index.html#structurepref"><i class="fa fa-check"></i><b>0.6</b> Structure</a></li>
<li class="chapter" data-level="0.7" data-path="index.html"><a href="index.html#aboutauthor"><i class="fa fa-check"></i><b>0.7</b> About the Author</a></li>
<li class="chapter" data-level="0.8" data-path="index.html"><a href="index.html#contactauthor"><i class="fa fa-check"></i><b>0.8</b> Contacting the Author</a></li>
<li class="chapter" data-level="0.9" data-path="index.html"><a href="index.html#acknowpref"><i class="fa fa-check"></i><b>0.9</b> Acknowledgements</a></li>
</ul></li>
<li class="part"><span><b>I HR Analytics Project Life Cycle</b></span></li>
<li class="chapter" data-level="1" data-path="overviewhraplc.html"><a href="overviewhraplc.html"><i class="fa fa-check"></i><b>1</b> Overview of HR Analytics Project Life Cycle</a></li>
<li class="chapter" data-level="2" data-path="questionformulation.html"><a href="questionformulation.html"><i class="fa fa-check"></i><b>2</b> Question Formulation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="questionformulation.html"><a href="questionformulation.html#adoptstrategicmindset"><i class="fa fa-check"></i><b>2.1</b> Adopting a Strategic Mindset</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="questionformulation.html"><a href="questionformulation.html#strategy"><i class="fa fa-check"></i><b>2.1.1</b> Strategy</a></li>
<li class="chapter" data-level="2.1.2" data-path="questionformulation.html"><a href="questionformulation.html#strategyformulation"><i class="fa fa-check"></i><b>2.1.2</b> Strategy Formulation</a></li>
<li class="chapter" data-level="2.1.3" data-path="questionformulation.html"><a href="questionformulation.html#strategyimplementation"><i class="fa fa-check"></i><b>2.1.3</b> Strategy Implementation</a></li>
<li class="chapter" data-level="2.1.4" data-path="questionformulation.html"><a href="questionformulation.html#strategichrm"><i class="fa fa-check"></i><b>2.1.4</b> Strategic Human Resource Management</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="questionformulation.html"><a href="questionformulation.html#defining-problems-formulating-questions"><i class="fa fa-check"></i><b>2.2</b> Defining Problems &amp; Formulating Questions</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="questionformulation.html"><a href="questionformulation.html#definingaproblem"><i class="fa fa-check"></i><b>2.2.1</b> Defining a Problem</a></li>
<li class="chapter" data-level="2.2.2" data-path="questionformulation.html"><a href="questionformulation.html#formulatingaquestion"><i class="fa fa-check"></i><b>2.2.2</b> Formulating a Question</a></li>
<li class="chapter" data-level="2.2.3" data-path="questionformulation.html"><a href="questionformulation.html#divergentconvergentthinking"><i class="fa fa-check"></i><b>2.2.3</b> Thinking Divergently &amp; Convergently</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="questionformulation.html"><a href="questionformulation.html#summary"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="dataacquisition.html"><a href="dataacquisition.html"><i class="fa fa-check"></i><b>3</b> Data Acquisition</a>
<ul>
<li class="chapter" data-level="3.1" data-path="dataacquisition.html"><a href="dataacquisition.html#employeesurveys_dataacquisition"><i class="fa fa-check"></i><b>3.1</b> Employee Surveys</a></li>
<li class="chapter" data-level="3.2" data-path="dataacquisition.html"><a href="dataacquisition.html#ratingforms_dataacquisition"><i class="fa fa-check"></i><b>3.2</b> Rating Forms</a></li>
<li class="chapter" data-level="3.3" data-path="dataacquisition.html"><a href="dataacquisition.html#surveillance_dataacquisition"><i class="fa fa-check"></i><b>3.3</b> Surveillance &amp; Monitoring</a></li>
<li class="chapter" data-level="3.4" data-path="dataacquisition.html"><a href="dataacquisition.html#dbqueries_dataacquisition"><i class="fa fa-check"></i><b>3.4</b> Database Queries</a></li>
<li class="chapter" data-level="3.5" data-path="dataacquisition.html"><a href="dataacquisition.html#scraping_dataacquisition"><i class="fa fa-check"></i><b>3.5</b> Scraping</a></li>
<li class="chapter" data-level="3.6" data-path="dataacquisition.html"><a href="dataacquisition.html#summary_dataacquisition"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="datamanagement.html"><a href="datamanagement.html"><i class="fa fa-check"></i><b>4</b> Data Management</a>
<ul>
<li class="chapter" data-level="4.1" data-path="datamanagement.html"><a href="datamanagement.html#datamanage_clean"><i class="fa fa-check"></i><b>4.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="4.2" data-path="datamanagement.html"><a href="datamanagement.html#datamanage_manipulate"><i class="fa fa-check"></i><b>4.2</b> Data Manipulation &amp; Structuring</a></li>
<li class="chapter" data-level="4.3" data-path="datamanagement.html"><a href="datamanagement.html#datamanage_tools"><i class="fa fa-check"></i><b>4.3</b> Common Data-Management Tools</a></li>
<li class="chapter" data-level="4.4" data-path="datamanagement.html"><a href="datamanagement.html#summary-1"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dataanalysis.html"><a href="dataanalysis.html"><i class="fa fa-check"></i><b>5</b> Data Analysis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="dataanalysis.html"><a href="dataanalysis.html#dataanalysis_toolstechniques"><i class="fa fa-check"></i><b>5.1</b> Tools &amp; Techniques</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="dataanalysis.html"><a href="dataanalysis.html#mathematics"><i class="fa fa-check"></i><b>5.1.1</b> Mathematics</a></li>
<li class="chapter" data-level="5.1.2" data-path="dataanalysis.html"><a href="dataanalysis.html#statistics"><i class="fa fa-check"></i><b>5.1.2</b> Statistics</a></li>
<li class="chapter" data-level="5.1.3" data-path="dataanalysis.html"><a href="dataanalysis.html#machinelearning"><i class="fa fa-check"></i><b>5.1.3</b> Machine Learning</a></li>
<li class="chapter" data-level="5.1.4" data-path="dataanalysis.html"><a href="dataanalysis.html#computationalmodelsimulation"><i class="fa fa-check"></i><b>5.1.4</b> Computational Modeling &amp; Simulations</a></li>
<li class="chapter" data-level="5.1.5" data-path="dataanalysis.html"><a href="dataanalysis.html#textqualitativeanalyses"><i class="fa fa-check"></i><b>5.1.5</b> Text Analyses &amp; Qualitative Analyses</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="dataanalysis.html"><a href="dataanalysis.html#continuum_dataanalytics"><i class="fa fa-check"></i><b>5.2</b> Continuum of Data Analytics</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="dataanalysis.html"><a href="dataanalysis.html#descriptive_analytics"><i class="fa fa-check"></i><b>5.2.1</b> Descriptive Analytics</a></li>
<li class="chapter" data-level="5.2.2" data-path="dataanalysis.html"><a href="dataanalysis.html#predictish_analytics"><i class="fa fa-check"></i><b>5.2.2</b> Predict-ish Analytics</a></li>
<li class="chapter" data-level="5.2.3" data-path="dataanalysis.html"><a href="dataanalysis.html#predictive_analytics"><i class="fa fa-check"></i><b>5.2.3</b> Predictive Analytics</a></li>
<li class="chapter" data-level="5.2.4" data-path="dataanalysis.html"><a href="dataanalysis.html#prescriptive_analytics"><i class="fa fa-check"></i><b>5.2.4</b> Prescriptive Analytics</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="dataanalysis.html"><a href="dataanalysis.html#summary-2"><i class="fa fa-check"></i><b>5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html"><i class="fa fa-check"></i><b>6</b> Data Interpretation &amp; Storytelling</a>
<ul>
<li class="chapter" data-level="6.1" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#datainterpretation"><i class="fa fa-check"></i><b>6.1</b> Data Interpretation</a></li>
<li class="chapter" data-level="6.2" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#storytelling"><i class="fa fa-check"></i><b>6.2</b> Storytelling</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#structure_storytelling"><i class="fa fa-check"></i><b>6.2.1</b> Structure</a></li>
<li class="chapter" data-level="6.2.2" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#clarityparsimony_storytelling"><i class="fa fa-check"></i><b>6.2.2</b> Clarity &amp; Parsimony</a></li>
<li class="chapter" data-level="6.2.3" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#influencepersuasion_storytelling"><i class="fa fa-check"></i><b>6.2.3</b> Influence &amp; Persuasion</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#datavizualization_storytelling"><i class="fa fa-check"></i><b>6.3</b> Data Visualization</a></li>
<li class="chapter" data-level="6.4" data-path="datainterpretationstorytelling.html"><a href="datainterpretationstorytelling.html#summary_datainterpretationstorytelling"><i class="fa fa-check"></i><b>6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="deploymentimplementation.html"><a href="deploymentimplementation.html"><i class="fa fa-check"></i><b>7</b> Deployment &amp; Implementation</a></li>
<li class="part"><span><b>II Introduction to R</b></span></li>
<li class="chapter" data-level="8" data-path="overviewR.html"><a href="overviewR.html"><i class="fa fa-check"></i><b>8</b> Overview of R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="8.1" data-path="overviewR.html"><a href="overviewR.html#R_overview"><i class="fa fa-check"></i><b>8.1</b> R Programming Language</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="overviewR.html"><a href="overviewR.html#R_what"><i class="fa fa-check"></i><b>8.1.1</b> What Is R?</a></li>
<li class="chapter" data-level="8.1.2" data-path="overviewR.html"><a href="overviewR.html#R_why"><i class="fa fa-check"></i><b>8.1.2</b> Why Use R?</a></li>
<li class="chapter" data-level="8.1.3" data-path="overviewR.html"><a href="overviewR.html#R_who"><i class="fa fa-check"></i><b>8.1.3</b> Who Uses R?</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="overviewR.html"><a href="overviewR.html#RStudio_overview"><i class="fa fa-check"></i><b>8.2</b> RStudio</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="overviewR.html"><a href="overviewR.html#RStudio_what"><i class="fa fa-check"></i><b>8.2.1</b> What is RStudio?</a></li>
<li class="chapter" data-level="8.2.2" data-path="overviewR.html"><a href="overviewR.html#RStudio_why"><i class="fa fa-check"></i><b>8.2.2</b> Why RStudio?</a></li>
<li class="chapter" data-level="8.2.3" data-path="overviewR.html"><a href="overviewR.html#RStudio_who"><i class="fa fa-check"></i><b>8.2.3</b> Who Uses RStudio?</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="overviewR.html"><a href="overviewR.html#packages_overview"><i class="fa fa-check"></i><b>8.3</b> Packages</a></li>
<li class="chapter" data-level="8.4" data-path="overviewR.html"><a href="overviewR.html#summary-3"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="install.html"><a href="install.html"><i class="fa fa-check"></i><b>9</b> Installing R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="9.1" data-path="install.html"><a href="install.html#videotutorial_install"><i class="fa fa-check"></i><b>9.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="9.2" data-path="install.html"><a href="install.html#installR"><i class="fa fa-check"></i><b>9.2</b> Downloading &amp; Installing R</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="install.html"><a href="install.html#installR_windows"><i class="fa fa-check"></i><b>9.2.1</b> For Windows Operation Systems</a></li>
<li class="chapter" data-level="9.2.2" data-path="install.html"><a href="install.html#installR_macos"><i class="fa fa-check"></i><b>9.2.2</b> For Mac Operating Systems</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="install.html"><a href="install.html#installRStudio"><i class="fa fa-check"></i><b>9.3</b> Downloading &amp; Installing RStudio</a></li>
<li class="chapter" data-level="9.4" data-path="install.html"><a href="install.html#summary_install"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="gettingstarted.html"><a href="gettingstarted.html"><i class="fa fa-check"></i><b>10</b> Getting Started with R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="10.1" data-path="gettingstarted.html"><a href="gettingstarted.html#orientation_gettingstarted"><i class="fa fa-check"></i><b>10.1</b> Orientation to RStudio</a></li>
<li class="chapter" data-level="10.2" data-path="gettingstarted.html"><a href="gettingstarted.html#createRscript"><i class="fa fa-check"></i><b>10.2</b> Creating &amp; Saving an R Script</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="gettingstarted.html"><a href="gettingstarted.html#createnewRscript_gettingstarted"><i class="fa fa-check"></i><b>10.2.1</b> Creating a New R Script</a></li>
<li class="chapter" data-level="10.2.2" data-path="gettingstarted.html"><a href="gettingstarted.html#usenewRscript_gettingstarted"><i class="fa fa-check"></i><b>10.2.2</b> Using an R Script</a></li>
<li class="chapter" data-level="10.2.3" data-path="gettingstarted.html"><a href="gettingstarted.html#saveRscript_gettingstarted"><i class="fa fa-check"></i><b>10.2.3</b> Saving an R Script</a></li>
<li class="chapter" data-level="10.2.4" data-path="gettingstarted.html"><a href="gettingstarted.html#openRscript_gettingstarted"><i class="fa fa-check"></i><b>10.2.4</b> Opening a Saved R Script</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="gettingstarted.html"><a href="gettingstarted.html#RStudioproject_gettingstarted"><i class="fa fa-check"></i><b>10.3</b> Creating an RStudio Project</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="gettingstarted.html"><a href="gettingstarted.html#createRStudioproject_gettingstarted"><i class="fa fa-check"></i><b>10.3.1</b> Creating a New RStudio Project</a></li>
<li class="chapter" data-level="10.3.2" data-path="gettingstarted.html"><a href="gettingstarted.html#openRStudioproject_gettingstarted"><i class="fa fa-check"></i><b>10.3.2</b> Opening an Existing RStudio Project</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="gettingstarted.html"><a href="gettingstarted.html#writtentutorials_gettingstarted"><i class="fa fa-check"></i><b>10.4</b> Orientation to Written Tutorials</a></li>
<li class="chapter" data-level="10.5" data-path="gettingstarted.html"><a href="gettingstarted.html#summary_gettingstarted"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="gentleintro.html"><a href="gentleintro.html"><i class="fa fa-check"></i><b>11</b> Basic Features and Operations of the R Language</a>
<ul>
<li class="chapter" data-level="11.1" data-path="gentleintro.html"><a href="gentleintro.html#videotutorial_gentleintro"><i class="fa fa-check"></i><b>11.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="11.2" data-path="gentleintro.html"><a href="gentleintro.html#functions_gentleintro"><i class="fa fa-check"></i><b>11.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="11.3" data-path="gentleintro.html"><a href="gentleintro.html#r_as_calculator"><i class="fa fa-check"></i><b>11.3</b> R as a Calculator</a></li>
<li class="chapter" data-level="11.4" data-path="gentleintro.html"><a href="gentleintro.html#functions"><i class="fa fa-check"></i><b>11.4</b> Functions</a></li>
<li class="chapter" data-level="11.5" data-path="gentleintro.html"><a href="gentleintro.html#packages"><i class="fa fa-check"></i><b>11.5</b> Packages</a></li>
<li class="chapter" data-level="11.6" data-path="gentleintro.html"><a href="gentleintro.html#variableassignment"><i class="fa fa-check"></i><b>11.6</b> Variable Assignment</a></li>
<li class="chapter" data-level="11.7" data-path="gentleintro.html"><a href="gentleintro.html#typesofdata"><i class="fa fa-check"></i><b>11.7</b> Types of Data</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="gentleintro.html"><a href="gentleintro.html#numeric-data"><i class="fa fa-check"></i><b>11.7.1</b> <code>numeric</code> Data</a></li>
<li class="chapter" data-level="11.7.2" data-path="gentleintro.html"><a href="gentleintro.html#character-data"><i class="fa fa-check"></i><b>11.7.2</b> <code>character</code> Data</a></li>
<li class="chapter" data-level="11.7.3" data-path="gentleintro.html"><a href="gentleintro.html#date-data"><i class="fa fa-check"></i><b>11.7.3</b> <code>Date</code> Data</a></li>
<li class="chapter" data-level="11.7.4" data-path="gentleintro.html"><a href="gentleintro.html#logical-data"><i class="fa fa-check"></i><b>11.7.4</b> <code>logical</code> Data</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="gentleintro.html"><a href="gentleintro.html#vectors"><i class="fa fa-check"></i><b>11.8</b> Vectors</a></li>
<li class="chapter" data-level="11.9" data-path="gentleintro.html"><a href="gentleintro.html#lists"><i class="fa fa-check"></i><b>11.9</b> Lists</a></li>
<li class="chapter" data-level="11.10" data-path="gentleintro.html"><a href="gentleintro.html#dataframes"><i class="fa fa-check"></i><b>11.10</b> Data Frames</a></li>
<li class="chapter" data-level="11.11" data-path="gentleintro.html"><a href="gentleintro.html#annotate"><i class="fa fa-check"></i><b>11.11</b> Annotations</a></li>
<li class="chapter" data-level="11.12" data-path="gentleintro.html"><a href="gentleintro.html#summary_gentleintro"><i class="fa fa-check"></i><b>11.12</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="setwd.html"><a href="setwd.html"><i class="fa fa-check"></i><b>12</b> Setting a Working Directory</a>
<ul>
<li class="chapter" data-level="12.1" data-path="setwd.html"><a href="setwd.html#videotutorial_setwd"><i class="fa fa-check"></i><b>12.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="12.2" data-path="setwd.html"><a href="setwd.html#functions_setwd"><i class="fa fa-check"></i><b>12.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="12.3" data-path="setwd.html"><a href="setwd.html#getwd_setwd"><i class="fa fa-check"></i><b>12.3</b> Identify the Current Working Directory</a></li>
<li class="chapter" data-level="12.4" data-path="setwd.html"><a href="setwd.html#setwd_setwd"><i class="fa fa-check"></i><b>12.4</b> Set a New Working Directory</a></li>
<li class="chapter" data-level="12.5" data-path="setwd.html"><a href="setwd.html#summary_setwd"><i class="fa fa-check"></i><b>12.5</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>III Data Acquisition &amp; Management</b></span></li>
<li class="chapter" data-level="13" data-path="read.html"><a href="read.html"><i class="fa fa-check"></i><b>13</b> Reading Data into R</a>
<ul>
<li class="chapter" data-level="13.1" data-path="read.html"><a href="read.html#conceptualoverview_read"><i class="fa fa-check"></i><b>13.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="13.2" data-path="read.html"><a href="read.html#tutorial_read"><i class="fa fa-check"></i><b>13.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="read.html"><a href="read.html#videotutorial_read"><i class="fa fa-check"></i><b>13.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="13.2.2" data-path="read.html"><a href="read.html#functions_read"><i class="fa fa-check"></i><b>13.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="13.2.3" data-path="read.html"><a href="read.html#initialsteps_read"><i class="fa fa-check"></i><b>13.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="13.2.4" data-path="read.html"><a href="read.html#readcsv"><i class="fa fa-check"></i><b>13.2.4</b> Read a .csv File</a></li>
<li class="chapter" data-level="13.2.5" data-path="read.html"><a href="read.html#readxlsx"><i class="fa fa-check"></i><b>13.2.5</b> Read a .xlsx File</a></li>
<li class="chapter" data-level="13.2.6" data-path="read.html"><a href="read.html#read_summary"><i class="fa fa-check"></i><b>13.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="read.html"><a href="read.html#read_supplement"><i class="fa fa-check"></i><b>13.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="read.html"><a href="read.html#read_supplement_functions"><i class="fa fa-check"></i><b>13.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="13.3.2" data-path="read.html"><a href="read.html#read_initsteps_supplement"><i class="fa fa-check"></i><b>13.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="13.3.3" data-path="read.html"><a href="read.html#read_additionalfunctions"><i class="fa fa-check"></i><b>13.3.3</b> Additional Functions for Reading a .csv File</a></li>
<li class="chapter" data-level="13.3.4" data-path="read.html"><a href="read.html#read_skiprows"><i class="fa fa-check"></i><b>13.3.4</b> Skip Rows of Data During Read</a></li>
<li class="chapter" data-level="13.3.5" data-path="read.html"><a href="read.html#listdatafiles"><i class="fa fa-check"></i><b>13.3.5</b> List Data File Names in Working Directory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="addnames.html"><a href="addnames.html"><i class="fa fa-check"></i><b>14</b> Removing, Adding, &amp; Changing Variable Names</a>
<ul>
<li class="chapter" data-level="14.1" data-path="addnames.html"><a href="addnames.html#conceptualoverview_addnames"><i class="fa fa-check"></i><b>14.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="14.2" data-path="addnames.html"><a href="addnames.html#tutorial_addnames"><i class="fa fa-check"></i><b>14.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="addnames.html"><a href="addnames.html#videotutorial_addnames"><i class="fa fa-check"></i><b>14.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="14.2.2" data-path="addnames.html"><a href="addnames.html#function_addnames"><i class="fa fa-check"></i><b>14.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="14.2.3" data-path="addnames.html"><a href="addnames.html#initsteps_addnames"><i class="fa fa-check"></i><b>14.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="14.2.4" data-path="addnames.html"><a href="addnames.html#remove_variablenames"><i class="fa fa-check"></i><b>14.2.4</b> Remove Variable Names from a Data Frame Object</a></li>
<li class="chapter" data-level="14.2.5" data-path="addnames.html"><a href="addnames.html#add_variablenames"><i class="fa fa-check"></i><b>14.2.5</b> Add Variable Names to a Data Frame Object</a></li>
<li class="chapter" data-level="14.2.6" data-path="addnames.html"><a href="addnames.html#change_variablenames"><i class="fa fa-check"></i><b>14.2.6</b> Change Specific Variable Names in a Data Frame Object</a></li>
<li class="chapter" data-level="14.2.7" data-path="addnames.html"><a href="addnames.html#summary_addnames"><i class="fa fa-check"></i><b>14.2.7</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="write.html"><a href="write.html"><i class="fa fa-check"></i><b>15</b> Writing Data from R</a>
<ul>
<li class="chapter" data-level="15.1" data-path="write.html"><a href="write.html#conceptualoverview_write"><i class="fa fa-check"></i><b>15.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="15.2" data-path="write.html"><a href="write.html#tutorial_write"><i class="fa fa-check"></i><b>15.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="write.html"><a href="write.html#videotutorial_write"><i class="fa fa-check"></i><b>15.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="15.2.2" data-path="write.html"><a href="write.html#functions_write"><i class="fa fa-check"></i><b>15.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="15.2.3" data-path="write.html"><a href="write.html#initialsteps_write"><i class="fa fa-check"></i><b>15.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="15.2.4" data-path="write.html"><a href="write.html#write_dataframe"><i class="fa fa-check"></i><b>15.2.4</b> Write Data Frame to Working Directory</a></li>
<li class="chapter" data-level="15.2.5" data-path="write.html"><a href="write.html#write_table"><i class="fa fa-check"></i><b>15.2.5</b> Write Table to Working Directory</a></li>
<li class="chapter" data-level="15.2.6" data-path="write.html"><a href="write.html#summary_write"><i class="fa fa-check"></i><b>15.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="arrange.html"><a href="arrange.html"><i class="fa fa-check"></i><b>16</b> Arranging (Sorting) Data</a>
<ul>
<li class="chapter" data-level="16.1" data-path="arrange.html"><a href="arrange.html#conceptualoverview_arrange"><i class="fa fa-check"></i><b>16.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="16.2" data-path="arrange.html"><a href="arrange.html#tutorial_arrange"><i class="fa fa-check"></i><b>16.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="arrange.html"><a href="arrange.html#videotutorial_arrange"><i class="fa fa-check"></i><b>16.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="16.2.2" data-path="arrange.html"><a href="arrange.html#functions_arrange"><i class="fa fa-check"></i><b>16.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="16.2.3" data-path="arrange.html"><a href="arrange.html#initsteps_arrange"><i class="fa fa-check"></i><b>16.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="16.2.4" data-path="arrange.html"><a href="arrange.html#arrangebyvalues"><i class="fa fa-check"></i><b>16.2.4</b> Arrange (Sort) Data</a></li>
<li class="chapter" data-level="16.2.5" data-path="arrange.html"><a href="arrange.html#summary_arrange"><i class="fa fa-check"></i><b>16.2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="arrange.html"><a href="arrange.html#arrange_supplement"><i class="fa fa-check"></i><b>16.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="arrange.html"><a href="arrange.html#arrange_supplement_functions"><i class="fa fa-check"></i><b>16.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="16.3.2" data-path="arrange.html"><a href="arrange.html#arrange_initsteps_supplement"><i class="fa fa-check"></i><b>16.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="16.3.3" data-path="arrange.html"><a href="arrange.html#arrange_orderfunction"><i class="fa fa-check"></i><b>16.3.3</b> <code>order</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="join.html"><a href="join.html"><i class="fa fa-check"></i><b>17</b> Joining (Merging) Data</a>
<ul>
<li class="chapter" data-level="17.1" data-path="join.html"><a href="join.html#conceptualoverview_join"><i class="fa fa-check"></i><b>17.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="join.html"><a href="join.html#review_horizontaljoin"><i class="fa fa-check"></i><b>17.1.1</b> Review of Horizontal Joins (Merges)</a></li>
<li class="chapter" data-level="17.1.2" data-path="join.html"><a href="join.html#review_verticaljoin"><i class="fa fa-check"></i><b>17.1.2</b> Review of Vertical Joins (Merges)</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="join.html"><a href="join.html#tutorial_join"><i class="fa fa-check"></i><b>17.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="join.html"><a href="join.html#videotutorial_join"><i class="fa fa-check"></i><b>17.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="17.2.2" data-path="join.html"><a href="join.html#functions-packages-introduced"><i class="fa fa-check"></i><b>17.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="17.2.3" data-path="join.html"><a href="join.html#initsteps_join"><i class="fa fa-check"></i><b>17.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="17.2.4" data-path="join.html"><a href="join.html#horizontaljoin"><i class="fa fa-check"></i><b>17.2.4</b> Horizontal Join (Merge)</a></li>
<li class="chapter" data-level="17.2.5" data-path="join.html"><a href="join.html#verticaljoin"><i class="fa fa-check"></i><b>17.2.5</b> Vertical Join (Merge)</a></li>
<li class="chapter" data-level="17.2.6" data-path="join.html"><a href="join.html#summary_join"><i class="fa fa-check"></i><b>17.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="join.html"><a href="join.html#join_supplement"><i class="fa fa-check"></i><b>17.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="join.html"><a href="join.html#supp_join_video"><i class="fa fa-check"></i><b>17.3.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="17.3.2" data-path="join.html"><a href="join.html#join_supplement_functions"><i class="fa fa-check"></i><b>17.3.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="17.3.3" data-path="join.html"><a href="join.html#join_initsteps_supplement"><i class="fa fa-check"></i><b>17.3.3</b> Initial Steps</a></li>
<li class="chapter" data-level="17.3.4" data-path="join.html"><a href="join.html#join_mergefunction"><i class="fa fa-check"></i><b>17.3.4</b> <code>merge</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="filter.html"><a href="filter.html"><i class="fa fa-check"></i><b>18</b> Filtering (Subsetting) Data</a>
<ul>
<li class="chapter" data-level="18.1" data-path="filter.html"><a href="filter.html#conceptualoverview_filter"><i class="fa fa-check"></i><b>18.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="filter.html"><a href="filter.html#review_logicaloperators"><i class="fa fa-check"></i><b>18.1.1</b> Review of Logical Operators</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="filter.html"><a href="filter.html#tutorial_filter"><i class="fa fa-check"></i><b>18.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="filter.html"><a href="filter.html#videotutorial_filter"><i class="fa fa-check"></i><b>18.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="18.2.2" data-path="filter.html"><a href="filter.html#function_filter"><i class="fa fa-check"></i><b>18.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="18.2.3" data-path="filter.html"><a href="filter.html#initsteps_filter"><i class="fa fa-check"></i><b>18.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="18.2.4" data-path="filter.html"><a href="filter.html#filter_cases"><i class="fa fa-check"></i><b>18.2.4</b> Filter Cases from Data Frame</a></li>
<li class="chapter" data-level="18.2.5" data-path="filter.html"><a href="filter.html#remove-single-variable-from-data-frame"><i class="fa fa-check"></i><b>18.2.5</b> Remove Single Variable from Data Frame</a></li>
<li class="chapter" data-level="18.2.6" data-path="filter.html"><a href="filter.html#select_multiplevariables"><i class="fa fa-check"></i><b>18.2.6</b> Select Multiple Variables from Data Frame</a></li>
<li class="chapter" data-level="18.2.7" data-path="filter.html"><a href="filter.html#remove_multiplevariables"><i class="fa fa-check"></i><b>18.2.7</b> Remove Multiple Variables from Data Frame</a></li>
<li class="chapter" data-level="18.2.8" data-path="filter.html"><a href="filter.html#summary_filter"><i class="fa fa-check"></i><b>18.2.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="filter.html"><a href="filter.html#filter_supplement"><i class="fa fa-check"></i><b>18.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="filter.html"><a href="filter.html#supp_filter_video"><i class="fa fa-check"></i><b>18.3.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="18.3.2" data-path="filter.html"><a href="filter.html#filter_supplement_functions"><i class="fa fa-check"></i><b>18.3.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="18.3.3" data-path="filter.html"><a href="filter.html#filter_initsteps_supplement"><i class="fa fa-check"></i><b>18.3.3</b> Initial Steps</a></li>
<li class="chapter" data-level="18.3.4" data-path="filter.html"><a href="filter.html#filter_subset_supplement"><i class="fa fa-check"></i><b>18.3.4</b> <code>subset</code> Function from Base R</a></li>
<li class="chapter" data-level="18.3.5" data-path="filter.html"><a href="filter.html#str_detect_supp"><i class="fa fa-check"></i><b>18.3.5</b> Filter by Pattern Contained within String</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="clean.html"><a href="clean.html"><i class="fa fa-check"></i><b>19</b> Cleaning Data</a>
<ul>
<li class="chapter" data-level="19.1" data-path="clean.html"><a href="clean.html#conceptualoverview_clean"><i class="fa fa-check"></i><b>19.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="19.2" data-path="clean.html"><a href="clean.html#tutorial_clean"><i class="fa fa-check"></i><b>19.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="clean.html"><a href="clean.html#videotutorial_clean"><i class="fa fa-check"></i><b>19.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="19.2.2" data-path="clean.html"><a href="clean.html#functions_clean"><i class="fa fa-check"></i><b>19.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="19.2.3" data-path="clean.html"><a href="clean.html#initsteps_clean"><i class="fa fa-check"></i><b>19.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="19.2.4" data-path="clean.html"><a href="clean.html#reviewdata_clean"><i class="fa fa-check"></i><b>19.2.4</b> Review Data</a></li>
<li class="chapter" data-level="19.2.5" data-path="clean.html"><a href="clean.html#cleandata_clean"><i class="fa fa-check"></i><b>19.2.5</b> Clean Data</a></li>
<li class="chapter" data-level="19.2.6" data-path="clean.html"><a href="clean.html#renamevariables_clean"><i class="fa fa-check"></i><b>19.2.6</b> Rename Variables</a></li>
<li class="chapter" data-level="19.2.7" data-path="clean.html"><a href="clean.html#otherapproaches_clean"><i class="fa fa-check"></i><b>19.2.7</b> Other Approaches to Cleaning Data</a></li>
<li class="chapter" data-level="19.2.8" data-path="clean.html"><a href="clean.html#summary_clean"><i class="fa fa-check"></i><b>19.2.8</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="manipulate.html"><a href="manipulate.html"><i class="fa fa-check"></i><b>20</b> Manipulating &amp; Restructuring Data</a>
<ul>
<li class="chapter" data-level="20.1" data-path="manipulate.html"><a href="manipulate.html#conceptualoverview_manipulate"><i class="fa fa-check"></i><b>20.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="20.2" data-path="manipulate.html"><a href="manipulate.html#tutorial_manipulate"><i class="fa fa-check"></i><b>20.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="manipulate.html"><a href="manipulate.html#videotutorial_manipulate"><i class="fa fa-check"></i><b>20.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="20.2.2" data-path="manipulate.html"><a href="manipulate.html#functions_manipulate"><i class="fa fa-check"></i><b>20.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="20.2.3" data-path="manipulate.html"><a href="manipulate.html#initsteps_manipulate"><i class="fa fa-check"></i><b>20.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="20.2.4" data-path="manipulate.html"><a href="manipulate.html#manipulate_widetolong"><i class="fa fa-check"></i><b>20.2.4</b> Wide-to-Long Format Data Manipulation</a></li>
<li class="chapter" data-level="20.2.5" data-path="manipulate.html"><a href="manipulate.html#manipulate_longtowide"><i class="fa fa-check"></i><b>20.2.5</b> Long-to-Wide Format Data Manipulation</a></li>
<li class="chapter" data-level="20.2.6" data-path="manipulate.html"><a href="manipulate.html#summary_manipulate"><i class="fa fa-check"></i><b>20.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="center.html"><a href="center.html"><i class="fa fa-check"></i><b>21</b> Centering &amp; Standardizing Variables</a>
<ul>
<li class="chapter" data-level="21.1" data-path="center.html"><a href="center.html#conceptualoverview_center"><i class="fa fa-check"></i><b>21.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="center.html"><a href="center.html#review_center"><i class="fa fa-check"></i><b>21.1.1</b> Review of Centering Variables</a></li>
<li class="chapter" data-level="21.1.2" data-path="center.html"><a href="center.html#review_standardize"><i class="fa fa-check"></i><b>21.1.2</b> Review of Standardizing Variables</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="center.html"><a href="center.html#tutorial_center"><i class="fa fa-check"></i><b>21.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="center.html"><a href="center.html#videotutorial_center"><i class="fa fa-check"></i><b>21.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="21.2.2" data-path="center.html"><a href="center.html#functions_center"><i class="fa fa-check"></i><b>21.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="21.2.3" data-path="center.html"><a href="center.html#initsteps_center"><i class="fa fa-check"></i><b>21.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="21.2.4" data-path="center.html"><a href="center.html#grandmean_center"><i class="fa fa-check"></i><b>21.2.4</b> Grand-Mean Center Variables</a></li>
<li class="chapter" data-level="21.2.5" data-path="center.html"><a href="center.html#groupmean_center"><i class="fa fa-check"></i><b>21.2.5</b> Group-Mean Center Variables</a></li>
<li class="chapter" data-level="21.2.6" data-path="center.html"><a href="center.html#standardize_center"><i class="fa fa-check"></i><b>21.2.6</b> Standardize Variables</a></li>
<li class="chapter" data-level="21.2.7" data-path="center.html"><a href="center.html#summary_center"><i class="fa fa-check"></i><b>21.2.7</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="removeobjects.html"><a href="removeobjects.html"><i class="fa fa-check"></i><b>22</b> Removing Objects from the R Environment</a>
<ul>
<li class="chapter" data-level="22.1" data-path="removeobjects.html"><a href="removeobjects.html#conceptualoverview_removeobjects"><i class="fa fa-check"></i><b>22.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="22.2" data-path="removeobjects.html"><a href="removeobjects.html#tutorial_removeobjects"><i class="fa fa-check"></i><b>22.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="removeobjects.html"><a href="removeobjects.html#videotutorial_removeobjects"><i class="fa fa-check"></i><b>22.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="22.2.2" data-path="removeobjects.html"><a href="removeobjects.html#function_removeobjects"><i class="fa fa-check"></i><b>22.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="22.2.3" data-path="removeobjects.html"><a href="removeobjects.html#initsteps_removeobjects"><i class="fa fa-check"></i><b>22.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="22.2.4" data-path="removeobjects.html"><a href="removeobjects.html#listobjects_removeobjects"><i class="fa fa-check"></i><b>22.2.4</b> List Objects in R Environment</a></li>
<li class="chapter" data-level="22.2.5" data-path="removeobjects.html"><a href="removeobjects.html#removeobjects_removeobjects"><i class="fa fa-check"></i><b>22.2.5</b> Remove Objects from R Environment</a></li>
<li class="chapter" data-level="22.2.6" data-path="removeobjects.html"><a href="removeobjects.html#summary_removeobjects"><i class="fa fa-check"></i><b>22.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Employee Demographics</b></span></li>
<li class="chapter" data-level="23" data-path="employeedemographics.html"><a href="employeedemographics.html"><i class="fa fa-check"></i><b>23</b> Introduction to Employee Demographics</a>
<ul>
<li class="chapter" data-level="23.1" data-path="employeedemographics.html"><a href="employeedemographics.html#chapters_employeedemographics"><i class="fa fa-check"></i><b>23.1</b> Chapters Included</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>24</b> Describing Employee Demographics Using Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="24.1" data-path="descriptives.html"><a href="descriptives.html#conceptualoverview_descriptives"><i class="fa fa-check"></i><b>24.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="24.1.1" data-path="descriptives.html"><a href="descriptives.html#measurementscales"><i class="fa fa-check"></i><b>24.1.1</b> Review of Measurement Scales</a></li>
<li class="chapter" data-level="24.1.2" data-path="descriptives.html"><a href="descriptives.html#constructs_measures_measurementscales"><i class="fa fa-check"></i><b>24.1.2</b> Constructs, Measures, &amp; Measurement Scales</a></li>
<li class="chapter" data-level="24.1.3" data-path="descriptives.html"><a href="descriptives.html#typesof_descriptivestatistics"><i class="fa fa-check"></i><b>24.1.3</b> Types of Descriptive Statistics</a></li>
<li class="chapter" data-level="24.1.4" data-path="descriptives.html"><a href="descriptives.html#samplewriteup_descriptives"><i class="fa fa-check"></i><b>24.1.4</b> Sample Write-Up</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="descriptives.html"><a href="descriptives.html#tutorial_descriptives"><i class="fa fa-check"></i><b>24.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="descriptives.html"><a href="descriptives.html#videotutorial_descriptives"><i class="fa fa-check"></i><b>24.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="24.2.2" data-path="descriptives.html"><a href="descriptives.html#functions_descriptives"><i class="fa fa-check"></i><b>24.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="24.2.3" data-path="descriptives.html"><a href="descriptives.html#initsteps_descriptives"><i class="fa fa-check"></i><b>24.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="24.2.4" data-path="descriptives.html"><a href="descriptives.html#determine_measurementscale"><i class="fa fa-check"></i><b>24.2.4</b> Determine the Measurement Scale</a></li>
<li class="chapter" data-level="24.2.5" data-path="descriptives.html"><a href="descriptives.html#describe_nominal_ordinal"><i class="fa fa-check"></i><b>24.2.5</b> Describe Nominal &amp; Ordinal (Categorical) Variables</a></li>
<li class="chapter" data-level="24.2.6" data-path="descriptives.html"><a href="descriptives.html#describe_interval_ratio"><i class="fa fa-check"></i><b>24.2.6</b> Describe Interval &amp; Ratio (Continuous) Variables</a></li>
<li class="chapter" data-level="24.2.7" data-path="descriptives.html"><a href="descriptives.html#summary_descriptives"><i class="fa fa-check"></i><b>24.2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="descriptives.html"><a href="descriptives.html#descriptives_supplement"><i class="fa fa-check"></i><b>24.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="descriptives.html"><a href="descriptives.html#descriptives_supplement_functions"><i class="fa fa-check"></i><b>24.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="24.3.2" data-path="descriptives.html"><a href="descriptives.html#descriptives_initsteps_supplement"><i class="fa fa-check"></i><b>24.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="24.3.3" data-path="descriptives.html"><a href="descriptives.html#descriptives_coefficientofvariation_supplement"><i class="fa fa-check"></i><b>24.3.3</b> Compute Coefficient of Variation (CV)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="crosstabs.html"><a href="crosstabs.html"><i class="fa fa-check"></i><b>25</b> Summarizing Two or More Categorical Variables Using Cross-Tabulations</a>
<ul>
<li class="chapter" data-level="25.1" data-path="crosstabs.html"><a href="crosstabs.html#conceptualoverview_crosstabs"><i class="fa fa-check"></i><b>25.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="25.1.1" data-path="crosstabs.html"><a href="crosstabs.html#review_crosstabs"><i class="fa fa-check"></i><b>25.1.1</b> Review of Cross-Tabulation</a></li>
<li class="chapter" data-level="25.1.2" data-path="crosstabs.html"><a href="crosstabs.html#samplewriteup_crosstabs"><i class="fa fa-check"></i><b>25.1.2</b> Sample Write-Up</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="crosstabs.html"><a href="crosstabs.html#tutorial_crosstabs"><i class="fa fa-check"></i><b>25.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="crosstabs.html"><a href="crosstabs.html#videotutorial_crosstabs"><i class="fa fa-check"></i><b>25.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="25.2.2" data-path="crosstabs.html"><a href="crosstabs.html#functions_crosstabs"><i class="fa fa-check"></i><b>25.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="25.2.3" data-path="crosstabs.html"><a href="crosstabs.html#initsteps_tables"><i class="fa fa-check"></i><b>25.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="25.2.4" data-path="crosstabs.html"><a href="crosstabs.html#twoway_crosstabs"><i class="fa fa-check"></i><b>25.2.4</b> Two-Way Cross-Tabulation</a></li>
<li class="chapter" data-level="25.2.5" data-path="crosstabs.html"><a href="crosstabs.html#threeway_crosstabs"><i class="fa fa-check"></i><b>25.2.5</b> Three-Way Cross-Tabulation</a></li>
<li class="chapter" data-level="25.2.6" data-path="crosstabs.html"><a href="crosstabs.html#summary_crosstabs"><i class="fa fa-check"></i><b>25.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="pivottables.html"><a href="pivottables.html"><i class="fa fa-check"></i><b>26</b> Applying Pivot Tables to Explore Employee Demographic Data</a>
<ul>
<li class="chapter" data-level="26.1" data-path="pivottables.html"><a href="pivottables.html#conceptualoverview_pivottables"><i class="fa fa-check"></i><b>26.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="26.2" data-path="pivottables.html"><a href="pivottables.html#tutorial_pivottables"><i class="fa fa-check"></i><b>26.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="pivottables.html"><a href="pivottables.html#videotutorial_pivottables"><i class="fa fa-check"></i><b>26.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="26.2.2" data-path="pivottables.html"><a href="pivottables.html#functions_pivottables"><i class="fa fa-check"></i><b>26.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="26.2.3" data-path="pivottables.html"><a href="pivottables.html#initsteps_pivottables"><i class="fa fa-check"></i><b>26.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="26.2.4" data-path="pivottables.html"><a href="pivottables.html#create_pivottables"><i class="fa fa-check"></i><b>26.2.4</b> Create a Pivot Table</a></li>
<li class="chapter" data-level="26.2.5" data-path="pivottables.html"><a href="pivottables.html#summary_pivottables"><i class="fa fa-check"></i><b>26.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Employee Surveys</b></span></li>
<li class="chapter" data-level="27" data-path="employeesurveys.html"><a href="employeesurveys.html"><i class="fa fa-check"></i><b>27</b> Introduction to Employee Surveys</a>
<ul>
<li class="chapter" data-level="27.1" data-path="employeesurveys.html"><a href="employeesurveys.html#chapters_employeesurveys"><i class="fa fa-check"></i><b>27.1</b> Chapters Included</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="aggregatesegment.html"><a href="aggregatesegment.html"><i class="fa fa-check"></i><b>28</b> Aggregating &amp; Segmenting Employee Survey Data</a>
<ul>
<li class="chapter" data-level="28.1" data-path="aggregatesegment.html"><a href="aggregatesegment.html#conceptualoverview_aggregatesegment"><i class="fa fa-check"></i><b>28.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="28.2" data-path="aggregatesegment.html"><a href="aggregatesegment.html#tutorial_aggregatesegment"><i class="fa fa-check"></i><b>28.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="28.2.1" data-path="aggregatesegment.html"><a href="aggregatesegment.html#videotutorial_aggregatesegment"><i class="fa fa-check"></i><b>28.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="28.2.2" data-path="aggregatesegment.html"><a href="aggregatesegment.html#functions_aggregatesegment"><i class="fa fa-check"></i><b>28.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="28.2.3" data-path="aggregatesegment.html"><a href="aggregatesegment.html#initsteps_aggregatesegment"><i class="fa fa-check"></i><b>28.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="28.2.4" data-path="aggregatesegment.html"><a href="aggregatesegment.html#counts_bygroup"><i class="fa fa-check"></i><b>28.2.4</b> Counts By Group</a></li>
<li class="chapter" data-level="28.2.5" data-path="aggregatesegment.html"><a href="aggregatesegment.html#centraldispersion_bygroup"><i class="fa fa-check"></i><b>28.2.5</b> Measures of Central Tendency and Dispersion By Group</a></li>
<li class="chapter" data-level="28.2.6" data-path="aggregatesegment.html"><a href="aggregatesegment.html#addaggregatedvariable"><i class="fa fa-check"></i><b>28.2.6</b> Add Variable to Data Frame Containing Aggregated Values</a></li>
<li class="chapter" data-level="28.2.7" data-path="aggregatesegment.html"><a href="aggregatesegment.html#visualize_bygroup"><i class="fa fa-check"></i><b>28.2.7</b> Visualize Data By Group</a></li>
<li class="chapter" data-level="28.2.8" data-path="aggregatesegment.html"><a href="aggregatesegment.html#summary_aggregatesegment"><i class="fa fa-check"></i><b>28.2.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_supplement"><i class="fa fa-check"></i><b>28.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="28.3.1" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_supplement_functions"><i class="fa fa-check"></i><b>28.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="28.3.2" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_initsteps_supplement"><i class="fa fa-check"></i><b>28.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="28.3.3" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_describeby_supplement"><i class="fa fa-check"></i><b>28.3.3</b> <code>describeBy</code> Function from <code>psych</code> Package</a></li>
<li class="chapter" data-level="28.3.4" data-path="aggregatesegment.html"><a href="aggregatesegment.html#aggregatesegment_aggregate_supplement"><i class="fa fa-check"></i><b>28.3.4</b> <code>aggregate</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html"><i class="fa fa-check"></i><b>29</b> Estimating Internal Consistency Reliability Using Cronbach’s alpha</a>
<ul>
<li class="chapter" data-level="29.1" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#conceptualoverview_cronbachsalpha"><i class="fa fa-check"></i><b>29.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="29.2" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#tutorial_cronbachsalpha"><i class="fa fa-check"></i><b>29.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#videotutorial_cronbachsalpha"><i class="fa fa-check"></i><b>29.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="29.2.2" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#functions_cronbachsalpha"><i class="fa fa-check"></i><b>29.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="29.2.3" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#initsteps_cronbachsalpha"><i class="fa fa-check"></i><b>29.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="29.2.4" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#cronbachsalpha_alpha"><i class="fa fa-check"></i><b>29.2.4</b> Compute Cronbach’s alpha</a></li>
<li class="chapter" data-level="29.2.5" data-path="cronbachsalpha.html"><a href="cronbachsalpha.html#summary_cronbachsalpha"><i class="fa fa-check"></i><b>29.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="compositevariable.html"><a href="compositevariable.html"><i class="fa fa-check"></i><b>30</b> Creating a Composite Variable Based on a Multi-Item Measure</a>
<ul>
<li class="chapter" data-level="30.1" data-path="compositevariable.html"><a href="compositevariable.html#conceptualoverview_compositevariable"><i class="fa fa-check"></i><b>30.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="30.2" data-path="compositevariable.html"><a href="compositevariable.html#tutorial_compositevariable"><i class="fa fa-check"></i><b>30.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="compositevariable.html"><a href="compositevariable.html#videotutorial_compositevariable"><i class="fa fa-check"></i><b>30.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="30.2.2" data-path="compositevariable.html"><a href="compositevariable.html#functions_compositevariable"><i class="fa fa-check"></i><b>30.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="30.2.3" data-path="compositevariable.html"><a href="compositevariable.html#initsteps_compositevariable"><i class="fa fa-check"></i><b>30.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="30.2.4" data-path="compositevariable.html"><a href="compositevariable.html#compositevariable_cronbachsalpha"><i class="fa fa-check"></i><b>30.2.4</b> Compute Cronbach’s alpha</a></li>
<li class="chapter" data-level="30.2.5" data-path="compositevariable.html"><a href="compositevariable.html#compositevariable_composite"><i class="fa fa-check"></i><b>30.2.5</b> Create a Composite Variable</a></li>
<li class="chapter" data-level="30.2.6" data-path="compositevariable.html"><a href="compositevariable.html#summary_compositevariable"><i class="fa fa-check"></i><b>30.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VI Employee Training</b></span></li>
<li class="chapter" data-level="31" data-path="employeetraining.html"><a href="employeetraining.html"><i class="fa fa-check"></i><b>31</b> Introduction to Employee Training</a>
<ul>
<li class="chapter" data-level="31.1" data-path="employeetraining.html"><a href="employeetraining.html#needsassessment_employeetraining"><i class="fa fa-check"></i><b>31.1</b> Needs Assessment</a></li>
<li class="chapter" data-level="31.2" data-path="employeetraining.html"><a href="employeetraining.html#learningenvironmentenhancement_employeetraining"><i class="fa fa-check"></i><b>31.2</b> Learning Environment &amp; Enhancement</a></li>
<li class="chapter" data-level="31.3" data-path="employeetraining.html"><a href="employeetraining.html#trainingmethods_employeetraining"><i class="fa fa-check"></i><b>31.3</b> Training Methods</a></li>
<li class="chapter" data-level="31.4" data-path="employeetraining.html"><a href="employeetraining.html#trainingevaluation_employeetraining"><i class="fa fa-check"></i><b>31.4</b> Training Evaluation</a>
<ul>
<li class="chapter" data-level="31.4.1" data-path="employeetraining.html"><a href="employeetraining.html#causalinferences_employeetraining"><i class="fa fa-check"></i><b>31.4.1</b> Causal Inferences</a></li>
<li class="chapter" data-level="31.4.2" data-path="employeetraining.html"><a href="employeetraining.html#evaluationdesigns_employeetraining"><i class="fa fa-check"></i><b>31.4.2</b> Training Evaluation Designs &amp; Statistical Analysis</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="employeetraining.html"><a href="employeetraining.html#chapters_employeetraining"><i class="fa fa-check"></i><b>31.5</b> Chapters Included</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="pretestposttest.html"><a href="pretestposttest.html"><i class="fa fa-check"></i><b>32</b> Evaluating a Pre-Test/Post-Test without Control Group Design Using Paired-Samples <em>t</em>-test</a>
<ul>
<li class="chapter" data-level="32.1" data-path="pretestposttest.html"><a href="pretestposttest.html#conceptualoverview_pretestposttest_psttest"><i class="fa fa-check"></i><b>32.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="32.1.1" data-path="pretestposttest.html"><a href="pretestposttest.html#review_pretestposttest"><i class="fa fa-check"></i><b>32.1.1</b> Review of Pre-Test/Post-Test without Control Group Design</a></li>
<li class="chapter" data-level="32.1.2" data-path="pretestposttest.html"><a href="pretestposttest.html#review_psttest"><i class="fa fa-check"></i><b>32.1.2</b> Review of Paired-Samples <em>t</em>-test</a></li>
</ul></li>
<li class="chapter" data-level="32.2" data-path="pretestposttest.html"><a href="pretestposttest.html#tutorial_psttest"><i class="fa fa-check"></i><b>32.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="32.2.1" data-path="pretestposttest.html"><a href="pretestposttest.html#videotutorial_psttest"><i class="fa fa-check"></i><b>32.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="32.2.2" data-path="pretestposttest.html"><a href="pretestposttest.html#functions_psttest"><i class="fa fa-check"></i><b>32.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="32.2.3" data-path="pretestposttest.html"><a href="pretestposttest.html#initsteps_psttest"><i class="fa fa-check"></i><b>32.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="32.2.4" data-path="pretestposttest.html"><a href="pretestposttest.html#estimate_psttest"><i class="fa fa-check"></i><b>32.2.4</b> Estimate Paired-Samples <em>t</em>-test</a></li>
<li class="chapter" data-level="32.2.5" data-path="pretestposttest.html"><a href="pretestposttest.html#barchart_psttest"><i class="fa fa-check"></i><b>32.2.5</b> Visualize Results Using Bar Chart</a></li>
<li class="chapter" data-level="32.2.6" data-path="pretestposttest.html"><a href="pretestposttest.html#summary_psttest"><i class="fa fa-check"></i><b>32.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="pretestposttest.html"><a href="pretestposttest.html#psttest_supplement"><i class="fa fa-check"></i><b>32.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="32.3.1" data-path="pretestposttest.html"><a href="pretestposttest.html#psttest_supplement_functions"><i class="fa fa-check"></i><b>32.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="32.3.2" data-path="pretestposttest.html"><a href="pretestposttest.html#psttest_initsteps_supplement"><i class="fa fa-check"></i><b>32.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="32.3.3" data-path="pretestposttest.html"><a href="pretestposttest.html#t.test_function_psttest"><i class="fa fa-check"></i><b>32.3.3</b> <code>t.test</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="33" data-path="posttestonly.html"><a href="posttestonly.html"><i class="fa fa-check"></i><b>33</b> Evaluating a Post-Test-Only with Control Group Design Using Independent-Samples <em>t</em>-test</a>
<ul>
<li class="chapter" data-level="33.1" data-path="posttestonly.html"><a href="posttestonly.html#conceptualoverview_posttestonly_isttest"><i class="fa fa-check"></i><b>33.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="33.1.1" data-path="posttestonly.html"><a href="posttestonly.html#review_posttestonly"><i class="fa fa-check"></i><b>33.1.1</b> Review of Post-Test-Only with Control Group Design</a></li>
<li class="chapter" data-level="33.1.2" data-path="posttestonly.html"><a href="posttestonly.html#review_isttest"><i class="fa fa-check"></i><b>33.1.2</b> Review of Independent-Samples <em>t</em>-test</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="posttestonly.html"><a href="posttestonly.html#tutorial_isttest"><i class="fa fa-check"></i><b>33.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="33.2.1" data-path="posttestonly.html"><a href="posttestonly.html#videotutorial_isttest"><i class="fa fa-check"></i><b>33.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="33.2.2" data-path="posttestonly.html"><a href="posttestonly.html#functions_isttest"><i class="fa fa-check"></i><b>33.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="33.2.3" data-path="posttestonly.html"><a href="posttestonly.html#initsteps_isttest"><i class="fa fa-check"></i><b>33.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="33.2.4" data-path="posttestonly.html"><a href="posttestonly.html#estimate_isttest"><i class="fa fa-check"></i><b>33.2.4</b> Estimate Independent-Samples <em>t</em>-test</a></li>
<li class="chapter" data-level="33.2.5" data-path="posttestonly.html"><a href="posttestonly.html#barchart_isttest"><i class="fa fa-check"></i><b>33.2.5</b> Visualize Results Using Bar Chart</a></li>
<li class="chapter" data-level="33.2.6" data-path="posttestonly.html"><a href="posttestonly.html#summary_isttest"><i class="fa fa-check"></i><b>33.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="33.3" data-path="posttestonly.html"><a href="posttestonly.html#isttest_supplement"><i class="fa fa-check"></i><b>33.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="posttestonly.html"><a href="posttestonly.html#isttest_supplement_functions"><i class="fa fa-check"></i><b>33.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="33.3.2" data-path="posttestonly.html"><a href="posttestonly.html#isttest_initsteps_supplement"><i class="fa fa-check"></i><b>33.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="33.3.3" data-path="posttestonly.html"><a href="posttestonly.html#t.test_function_isttest"><i class="fa fa-check"></i><b>33.3.3</b> <code>t.test</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="34" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html"><i class="fa fa-check"></i><b>34</b> Evaluating a Post-Test-Only with Two Comparison Groups Design Using One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="34.1" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#conceptualoverview_posttestonly_threegroups_onewayanova"><i class="fa fa-check"></i><b>34.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="34.1.1" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#review_posttestonly_threegroups"><i class="fa fa-check"></i><b>34.1.1</b> Review of Post-Test-Only with Two Comparison Groups Design</a></li>
<li class="chapter" data-level="34.1.2" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#review_onewayanova"><i class="fa fa-check"></i><b>34.1.2</b> Review of One-Way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="34.2" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#tutorial_onewayanova"><i class="fa fa-check"></i><b>34.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="34.2.1" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#videotutorial_onewayanova"><i class="fa fa-check"></i><b>34.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="34.2.2" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#functions_onewayanova"><i class="fa fa-check"></i><b>34.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="34.2.3" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#initsteps_onewayanova"><i class="fa fa-check"></i><b>34.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="34.2.4" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#teststatisticalassumptions_onewayanova"><i class="fa fa-check"></i><b>34.2.4</b> Test Statistical Assumptions</a></li>
<li class="chapter" data-level="34.2.5" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#estimate_onewayanova"><i class="fa fa-check"></i><b>34.2.5</b> Estimate One-Way ANOVA</a></li>
<li class="chapter" data-level="34.2.6" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#barchart_onewayanova"><i class="fa fa-check"></i><b>34.2.6</b> Visualize Results Using Bar Chart</a></li>
<li class="chapter" data-level="34.2.7" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#summary_onewayanova"><i class="fa fa-check"></i><b>34.2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="34.3" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#onewayanova_supplement"><i class="fa fa-check"></i><b>34.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="34.3.1" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#onewayanova_supplement_functions"><i class="fa fa-check"></i><b>34.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="34.3.2" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#onewayanova_initsteps_supplement"><i class="fa fa-check"></i><b>34.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="34.3.3" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#aov_function_onewayanova"><i class="fa fa-check"></i><b>34.3.3</b> <code>aov</code> Function from Base R</a></li>
<li class="chapter" data-level="34.3.4" data-path="posttestonly_threegroups.html"><a href="posttestonly_threegroups.html#apatable_onewayanova"><i class="fa fa-check"></i><b>34.3.4</b> APA-Style Table of Results</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VII Employee Selection</b></span></li>
<li class="chapter" data-level="35" data-path="selection.html"><a href="selection.html"><i class="fa fa-check"></i><b>35</b> Introduction to Employee Selection</a>
<ul>
<li class="chapter" data-level="35.1" data-path="selection.html"><a href="selection.html#evaluating-selection-tools"><i class="fa fa-check"></i><b>35.1</b> Evaluating Selection Tools</a></li>
<li class="chapter" data-level="35.2" data-path="selection.html"><a href="selection.html#chapters_selection"><i class="fa fa-check"></i><b>35.2</b> Chapters Included</a></li>
</ul></li>
<li class="chapter" data-level="36" data-path="disparateimpact.html"><a href="disparateimpact.html"><i class="fa fa-check"></i><b>36</b> Investigating Disparate Impact</a>
<ul>
<li class="chapter" data-level="36.1" data-path="disparateimpact.html"><a href="disparateimpact.html#conceptualoverview_disparateimpact"><i class="fa fa-check"></i><b>36.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="36.2" data-path="disparateimpact.html"><a href="disparateimpact.html#tutorial_disparateimpact"><i class="fa fa-check"></i><b>36.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="36.2.1" data-path="disparateimpact.html"><a href="disparateimpact.html#videotutorial_disparateimpact"><i class="fa fa-check"></i><b>36.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="36.2.2" data-path="disparateimpact.html"><a href="disparateimpact.html#functions_disparateimpact"><i class="fa fa-check"></i><b>36.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="36.2.3" data-path="disparateimpact.html"><a href="disparateimpact.html#initsteps_disparateimpact"><i class="fa fa-check"></i><b>36.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="36.2.4" data-path="disparateimpact.html"><a href="disparateimpact.html#fourfifthsrule"><i class="fa fa-check"></i><b>36.2.4</b> 4/5ths Rule</a></li>
<li class="chapter" data-level="36.2.5" data-path="disparateimpact.html"><a href="disparateimpact.html#chisquaretest_disparateimpact"><i class="fa fa-check"></i><b>36.2.5</b> Chi-Square (<span class="math inline">\(\chi^2\)</span>) Test of Independence</a></li>
<li class="chapter" data-level="36.2.6" data-path="disparateimpact.html"><a href="disparateimpact.html#fisherexacttest"><i class="fa fa-check"></i><b>36.2.6</b> Fisher Exact Test</a></li>
<li class="chapter" data-level="36.2.7" data-path="disparateimpact.html"><a href="disparateimpact.html#zdifference_test_disparateimpact"><i class="fa fa-check"></i><b>36.2.7</b> <span class="math inline">\(Z_{D}\)</span> Test</a></li>
<li class="chapter" data-level="36.2.8" data-path="disparateimpact.html"><a href="disparateimpact.html#z_impactratiotest"><i class="fa fa-check"></i><b>36.2.8</b> <span class="math inline">\(Z_{IR}\)</span> Test</a></li>
<li class="chapter" data-level="36.2.9" data-path="disparateimpact.html"><a href="disparateimpact.html#summary_disparatetreatment"><i class="fa fa-check"></i><b>36.2.9</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="37" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html"><i class="fa fa-check"></i><b>37</b> Estimating Criterion-Related Validity of a Selection Tool Using Correlation</a>
<ul>
<li class="chapter" data-level="37.1" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#conceptualoverview_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="37.1.1" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#review_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.1.1</b> Review of Criterion-Related Validity</a></li>
<li class="chapter" data-level="37.1.2" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#review_correlation"><i class="fa fa-check"></i><b>37.1.2</b> Review of Correlation</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#tutorial_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="37.2.1" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#videotutorial_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="37.2.2" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#functions_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="37.2.3" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#initsteps_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="37.2.4" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#scatterplot_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.4</b> Visualize Association Using a Scatter Plot</a></li>
<li class="chapter" data-level="37.2.5" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#estimate_correlation"><i class="fa fa-check"></i><b>37.2.5</b> Estimate Correlation</a></li>
<li class="chapter" data-level="37.2.6" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#summary_criterionrelatedvalidity"><i class="fa fa-check"></i><b>37.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="37.3" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#criterionrelatedvalidity_supplement"><i class="fa fa-check"></i><b>37.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="37.3.1" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#criterionrelatedvalidity_supplement_functions"><i class="fa fa-check"></i><b>37.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="37.3.2" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#criterionrelatedvalidity_initsteps_supplement"><i class="fa fa-check"></i><b>37.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="37.3.3" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#cor_function"><i class="fa fa-check"></i><b>37.3.3</b> <code>cor</code> Function from Base R</a></li>
<li class="chapter" data-level="37.3.4" data-path="criterionrelatedvalidity.html"><a href="criterionrelatedvalidity.html#cortest_function"><i class="fa fa-check"></i><b>37.3.4</b> <code>cor.test</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="38" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html"><i class="fa fa-check"></i><b>38</b> Predicting Criterion Scores Based on Selection Tool Scores Using Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="38.1" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#conceptualoverview_predictingcriterionscores"><i class="fa fa-check"></i><b>38.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="38.1.1" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#review_slr"><i class="fa fa-check"></i><b>38.1.1</b> Review of Simple Linear Regression</a></li>
<li class="chapter" data-level="38.1.2" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#review_prediction_slr"><i class="fa fa-check"></i><b>38.1.2</b> Predicting Future Criterion Scores Using Simple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="38.2" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#tutorial_predictingcriterionscores"><i class="fa fa-check"></i><b>38.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="38.2.1" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#videotutorial_predictingcriterionscores"><i class="fa fa-check"></i><b>38.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="38.2.2" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#functions_predictingcriterionscores"><i class="fa fa-check"></i><b>38.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="38.2.3" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#initsteps_slr"><i class="fa fa-check"></i><b>38.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="38.2.4" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#estimate_slr"><i class="fa fa-check"></i><b>38.2.4</b> Estimate Simple Linear Regression Model</a></li>
<li class="chapter" data-level="38.2.5" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predictingcriterionscores_slr"><i class="fa fa-check"></i><b>38.2.5</b> Predict Criterion Scores</a></li>
<li class="chapter" data-level="38.2.6" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#summary_predictingcriterionscores"><i class="fa fa-check"></i><b>38.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="38.3" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predictingcriterionscores_supplement"><i class="fa fa-check"></i><b>38.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="38.3.1" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predictingcriterionscores_supplement_functions"><i class="fa fa-check"></i><b>38.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="38.3.2" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predictingcriterionscores_initsteps_supplement"><i class="fa fa-check"></i><b>38.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="38.3.3" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#lm_function_slr"><i class="fa fa-check"></i><b>38.3.3</b> <code>lm</code> Function from Base R</a></li>
<li class="chapter" data-level="38.3.4" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#predict_function_slr"><i class="fa fa-check"></i><b>38.3.4</b> <code>predict</code> Function from Base R</a></li>
<li class="chapter" data-level="38.3.5" data-path="predictingcriterionscores.html"><a href="predictingcriterionscores.html#apatable_slr"><i class="fa fa-check"></i><b>38.3.5</b> APA-Style Results Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="39" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html"><i class="fa fa-check"></i><b>39</b> Estimating Incremental Validity of a Selection Tool Using Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="39.1" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#conceptualoverview_incrementalvalidity"><i class="fa fa-check"></i><b>39.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="39.1.1" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#review_mlr"><i class="fa fa-check"></i><b>39.1.1</b> Review of Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="39.2" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#tutorial_incrementalvalidity"><i class="fa fa-check"></i><b>39.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="39.2.1" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#videotutorial_incrementalvalidity"><i class="fa fa-check"></i><b>39.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="39.2.2" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#function_incrementalvalidity"><i class="fa fa-check"></i><b>39.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="39.2.3" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#initsteps_mlr"><i class="fa fa-check"></i><b>39.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="39.2.4" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#estimate_mlr"><i class="fa fa-check"></i><b>39.2.4</b> Estimate Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="39.2.5" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#summary_incrementalvalidity"><i class="fa fa-check"></i><b>39.2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="39.3" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#incrementalvalidity_supplement"><i class="fa fa-check"></i><b>39.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="39.3.1" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#incrementalvalidity_supplement_functions"><i class="fa fa-check"></i><b>39.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="39.3.2" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#incrementalvalidity_initsteps_supplement"><i class="fa fa-check"></i><b>39.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="39.3.3" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#lm_function_mlr"><i class="fa fa-check"></i><b>39.3.3</b> <code>lm</code> Function from Base R</a></li>
<li class="chapter" data-level="39.3.4" data-path="incrementalvalidity.html"><a href="incrementalvalidity.html#apatable_mlr"><i class="fa fa-check"></i><b>39.3.4</b> APA-Style Results Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="40" data-path="compensatory.html"><a href="compensatory.html"><i class="fa fa-check"></i><b>40</b> Applying a Compensatory Approach to Selection Decisions Using Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="40.1" data-path="compensatory.html"><a href="compensatory.html#conceptualoverview_compensatory"><i class="fa fa-check"></i><b>40.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="40.1.1" data-path="compensatory.html"><a href="compensatory.html#review_compensatory_mlr"><i class="fa fa-check"></i><b>40.1.1</b> Review of Multiple Linear Regression</a></li>
<li class="chapter" data-level="40.1.2" data-path="compensatory.html"><a href="compensatory.html#review_compensatory"><i class="fa fa-check"></i><b>40.1.2</b> Review of Compensatory Approach</a></li>
</ul></li>
<li class="chapter" data-level="40.2" data-path="compensatory.html"><a href="compensatory.html#tutorial_compensatory"><i class="fa fa-check"></i><b>40.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="40.2.1" data-path="compensatory.html"><a href="compensatory.html#videotutorial_compensatory"><i class="fa fa-check"></i><b>40.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="40.2.2" data-path="compensatory.html"><a href="compensatory.html#function_compensatory"><i class="fa fa-check"></i><b>40.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="40.2.3" data-path="compensatory.html"><a href="compensatory.html#initsteps_compensatory"><i class="fa fa-check"></i><b>40.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="40.2.4" data-path="compensatory.html"><a href="compensatory.html#estimate_compensatory"><i class="fa fa-check"></i><b>40.2.4</b> Estimate Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="40.2.5" data-path="compensatory.html"><a href="compensatory.html#predictcriterionscores_compensatory"><i class="fa fa-check"></i><b>40.2.5</b> Predict Criterion Scores</a></li>
<li class="chapter" data-level="40.2.6" data-path="compensatory.html"><a href="compensatory.html#summary_compensatory"><i class="fa fa-check"></i><b>40.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="compensatory.html"><a href="compensatory.html#compensatory_supplement"><i class="fa fa-check"></i><b>40.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="40.3.1" data-path="compensatory.html"><a href="compensatory.html#compensatory_supplement_functions"><i class="fa fa-check"></i><b>40.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="40.3.2" data-path="compensatory.html"><a href="compensatory.html#compensatory_initsteps_supplement"><i class="fa fa-check"></i><b>40.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="40.3.3" data-path="compensatory.html"><a href="compensatory.html#lm_predict_functions_compensatory"><i class="fa fa-check"></i><b>40.3.3</b> <code>lm</code> &amp; <code>predict</code> Functions from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="41" data-path="multiplecutoff.html"><a href="multiplecutoff.html"><i class="fa fa-check"></i><b>41</b> Applying a Noncompensatory Approach to Selection Decisions Using Angoff Method</a>
<ul>
<li class="chapter" data-level="41.1" data-path="multiplecutoff.html"><a href="multiplecutoff.html#conceptualoverview_multiplecutoff"><i class="fa fa-check"></i><b>41.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="41.1.1" data-path="multiplecutoff.html"><a href="multiplecutoff.html#review_multiplecutoff"><i class="fa fa-check"></i><b>41.1.1</b> Review of Noncompensatory Approach</a></li>
</ul></li>
<li class="chapter" data-level="41.2" data-path="multiplecutoff.html"><a href="multiplecutoff.html#tutorial_multiplecutoff"><i class="fa fa-check"></i><b>41.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="41.2.1" data-path="multiplecutoff.html"><a href="multiplecutoff.html#videotutorial_multiplecutoff"><i class="fa fa-check"></i><b>41.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="41.2.2" data-path="multiplecutoff.html"><a href="multiplecutoff.html#function_multiplecutoff"><i class="fa fa-check"></i><b>41.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="41.2.3" data-path="multiplecutoff.html"><a href="multiplecutoff.html#initsteps_multiplecutoff"><i class="fa fa-check"></i><b>41.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="41.2.4" data-path="multiplecutoff.html"><a href="multiplecutoff.html#createcutoffscores_multiplecutoff"><i class="fa fa-check"></i><b>41.2.4</b> Create Cutoff Scores</a></li>
<li class="chapter" data-level="41.2.5" data-path="multiplecutoff.html"><a href="multiplecutoff.html#applycutoffscores_multiplecutoff"><i class="fa fa-check"></i><b>41.2.5</b> Apply Cutoff Scores to Make Selection Decisions</a></li>
<li class="chapter" data-level="41.2.6" data-path="multiplecutoff.html"><a href="multiplecutoff.html#summary_multiplecutoff"><i class="fa fa-check"></i><b>41.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="differentialprediction.html"><a href="differentialprediction.html"><i class="fa fa-check"></i><b>42</b> Testing for Differential Prediction Using Moderated Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="42.1" data-path="differentialprediction.html"><a href="differentialprediction.html#conceptualoverview_differentialprediction"><i class="fa fa-check"></i><b>42.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="42.1.1" data-path="differentialprediction.html"><a href="differentialprediction.html#review_mmlr"><i class="fa fa-check"></i><b>42.1.1</b> Review of Moderated Multiple Linear Regression</a></li>
<li class="chapter" data-level="42.1.2" data-path="differentialprediction.html"><a href="differentialprediction.html#review_differentialprediction"><i class="fa fa-check"></i><b>42.1.2</b> Review of Differential Prediction</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="differentialprediction.html"><a href="differentialprediction.html#tutorial_differentialprediction"><i class="fa fa-check"></i><b>42.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="42.2.1" data-path="differentialprediction.html"><a href="differentialprediction.html#videotutorial_differentialprediction"><i class="fa fa-check"></i><b>42.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="42.2.2" data-path="differentialprediction.html"><a href="differentialprediction.html#function_mmlr"><i class="fa fa-check"></i><b>42.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="42.2.3" data-path="differentialprediction.html"><a href="differentialprediction.html#initsteps_mmlr"><i class="fa fa-check"></i><b>42.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="42.2.4" data-path="differentialprediction.html"><a href="differentialprediction.html#center_mmlr"><i class="fa fa-check"></i><b>42.2.4</b> Grand-Mean Center Continuous Predictor Variables</a></li>
<li class="chapter" data-level="42.2.5" data-path="differentialprediction.html"><a href="differentialprediction.html#estimate_mmlr"><i class="fa fa-check"></i><b>42.2.5</b> Estimate Moderated Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="42.2.6" data-path="differentialprediction.html"><a href="differentialprediction.html#summary_differentialprediction"><i class="fa fa-check"></i><b>42.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="differentialprediction.html"><a href="differentialprediction.html#differentialprediction_supplement"><i class="fa fa-check"></i><b>42.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="42.3.1" data-path="differentialprediction.html"><a href="differentialprediction.html#differentialprediction_supplement_functions"><i class="fa fa-check"></i><b>42.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="42.3.2" data-path="differentialprediction.html"><a href="differentialprediction.html#differentialprediction_initsteps_supplement"><i class="fa fa-check"></i><b>42.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="42.3.3" data-path="differentialprediction.html"><a href="differentialprediction.html#lm_function_mmlr"><i class="fa fa-check"></i><b>42.3.3</b> <code>lm</code> Function from Base R</a></li>
<li class="chapter" data-level="42.3.4" data-path="differentialprediction.html"><a href="differentialprediction.html#apatable_mmlr"><i class="fa fa-check"></i><b>42.3.4</b> APA-Style Results Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="43" data-path="crossvalidation.html"><a href="crossvalidation.html"><i class="fa fa-check"></i><b>43</b> Statistically &amp; Empirically Cross-Validating a Selection Tool</a>
<ul>
<li class="chapter" data-level="43.1" data-path="crossvalidation.html"><a href="crossvalidation.html#conceptualoverview_crossvalidation"><i class="fa fa-check"></i><b>43.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="43.1.1" data-path="crossvalidation.html"><a href="crossvalidation.html#review_statistical_crossvalidation"><i class="fa fa-check"></i><b>43.1.1</b> Review of Statistical Cross-Validation</a></li>
<li class="chapter" data-level="43.1.2" data-path="crossvalidation.html"><a href="crossvalidation.html#review_empirical_crossvalidation"><i class="fa fa-check"></i><b>43.1.2</b> Review of Empirical Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="43.2" data-path="crossvalidation.html"><a href="crossvalidation.html#tutorial_crossvalidation"><i class="fa fa-check"></i><b>43.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="43.2.1" data-path="crossvalidation.html"><a href="crossvalidation.html#function_crossvalidation"><i class="fa fa-check"></i><b>43.2.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="43.2.2" data-path="crossvalidation.html"><a href="crossvalidation.html#initsteps_crossvalidation"><i class="fa fa-check"></i><b>43.2.2</b> Initial Steps</a></li>
<li class="chapter" data-level="43.2.3" data-path="crossvalidation.html"><a href="crossvalidation.html#crossvalidation_statistical"><i class="fa fa-check"></i><b>43.2.3</b> Perform Statistical Cross-Validation</a></li>
<li class="chapter" data-level="43.2.4" data-path="crossvalidation.html"><a href="crossvalidation.html#crossvalidation_empirical"><i class="fa fa-check"></i><b>43.2.4</b> Perform Empirical Cross-Validation</a></li>
<li class="chapter" data-level="43.2.5" data-path="crossvalidation.html"><a href="crossvalidation.html#summary_crossvalidation"><i class="fa fa-check"></i><b>43.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VIII Employee Separation &amp; Retention</b></span></li>
<li class="chapter" data-level="44" data-path="turnover.html"><a href="turnover.html"><i class="fa fa-check"></i><b>44</b> Introduction to Employee Separation &amp; Retention</a>
<ul>
<li class="chapter" data-level="44.1" data-path="turnover.html"><a href="turnover.html#chapters_turnover"><i class="fa fa-check"></i><b>44.1</b> Chapters Included</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="turnoverrate.html"><a href="turnoverrate.html"><i class="fa fa-check"></i><b>45</b> Computing Monthly &amp; Annual Turnover Rates</a>
<ul>
<li class="chapter" data-level="45.1" data-path="turnoverrate.html"><a href="turnoverrate.html#conceptualoverview_turnoverrate"><i class="fa fa-check"></i><b>45.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="45.2" data-path="turnoverrate.html"><a href="turnoverrate.html#tutorial_turnoverrate"><i class="fa fa-check"></i><b>45.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="45.2.1" data-path="turnoverrate.html"><a href="turnoverrate.html#videotutorial_turnoverrate"><i class="fa fa-check"></i><b>45.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="45.2.2" data-path="turnoverrate.html"><a href="turnoverrate.html#functions_turnoverrate"><i class="fa fa-check"></i><b>45.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="45.2.3" data-path="turnoverrate.html"><a href="turnoverrate.html#initsteps_turnoverrate"><i class="fa fa-check"></i><b>45.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="45.2.4" data-path="turnoverrate.html"><a href="turnoverrate.html#turnoverrate_monthlyturnoverrate"><i class="fa fa-check"></i><b>45.2.4</b> Compute Monthly Turnover Rates</a></li>
<li class="chapter" data-level="45.2.5" data-path="turnoverrate.html"><a href="turnoverrate.html#turnoverrate_annualturnoverrate"><i class="fa fa-check"></i><b>45.2.5</b> Compute Annual Turnover Rate</a></li>
<li class="chapter" data-level="45.2.6" data-path="turnoverrate.html"><a href="turnoverrate.html#summary_turnoverrate"><i class="fa fa-check"></i><b>45.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="46" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html"><i class="fa fa-check"></i><b>46</b> Estimating the Association Between Two Categorical Variables Using Chi-Square (<span class="math inline">\(\chi^2\)</span>) Test of Independence</a>
<ul>
<li class="chapter" data-level="46.1" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#conceptualoverview_turnoverchisquare"><i class="fa fa-check"></i><b>46.1</b> Conceptual Overview</a></li>
<li class="chapter" data-level="46.2" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#tutorial_turnoverchisquare"><i class="fa fa-check"></i><b>46.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="46.2.1" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#videotutorial_turnoverchisquare"><i class="fa fa-check"></i><b>46.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="46.2.2" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#functions_turnoverchisquare"><i class="fa fa-check"></i><b>46.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="46.2.3" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#initsteps_turnoverchisquare"><i class="fa fa-check"></i><b>46.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="46.2.4" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_contingencytable"><i class="fa fa-check"></i><b>46.2.4</b> Create a Contingency Table for Observed Data</a></li>
<li class="chapter" data-level="46.2.5" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_chisquare"><i class="fa fa-check"></i><b>46.2.5</b> Estimate Chi-Square (<span class="math inline">\(\chi^2\)</span>) Test of Independence</a></li>
<li class="chapter" data-level="46.2.6" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#summary_turnoverchisquare"><i class="fa fa-check"></i><b>46.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="46.3" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_supplement"><i class="fa fa-check"></i><b>46.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="46.3.1" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_supplement_functions"><i class="fa fa-check"></i><b>46.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="46.3.2" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#turnoverchisquare_initsteps_supplement"><i class="fa fa-check"></i><b>46.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="46.3.3" data-path="turnoverchisquare.html"><a href="turnoverchisquare.html#supplement_turnoverchisquare_oddsratio"><i class="fa fa-check"></i><b>46.3.3</b> Compute Odds Ratio for 2x2 Contingency Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>47</b> Identifying Predictors of Turnover Using Logistic Regression</a>
<ul>
<li class="chapter" data-level="47.1" data-path="logistic.html"><a href="logistic.html#conceptualoverview_logistic"><i class="fa fa-check"></i><b>47.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="47.1.1" data-path="logistic.html"><a href="logistic.html#review_logistic"><i class="fa fa-check"></i><b>47.1.1</b> Review of Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="47.2" data-path="logistic.html"><a href="logistic.html#tutorial_logistic"><i class="fa fa-check"></i><b>47.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="47.2.1" data-path="logistic.html"><a href="logistic.html#videotutorial_logistic"><i class="fa fa-check"></i><b>47.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="47.2.2" data-path="logistic.html"><a href="logistic.html#functions_logistic"><i class="fa fa-check"></i><b>47.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="47.2.3" data-path="logistic.html"><a href="logistic.html#initsteps_logistic"><i class="fa fa-check"></i><b>47.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="47.2.4" data-path="logistic.html"><a href="logistic.html#estimate_simple_logistic"><i class="fa fa-check"></i><b>47.2.4</b> Estimate Simple Logistic Regression Model</a></li>
<li class="chapter" data-level="47.2.5" data-path="logistic.html"><a href="logistic.html#estimate_multiple_logistic"><i class="fa fa-check"></i><b>47.2.5</b> Estimate Multiple Logistic Regression Model</a></li>
<li class="chapter" data-level="47.2.6" data-path="logistic.html"><a href="logistic.html#summary_logistic"><i class="fa fa-check"></i><b>47.2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="47.3" data-path="logistic.html"><a href="logistic.html#logistic_supplement"><i class="fa fa-check"></i><b>47.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="47.3.1" data-path="logistic.html"><a href="logistic.html#logistic_supplement_functions"><i class="fa fa-check"></i><b>47.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="47.3.2" data-path="logistic.html"><a href="logistic.html#logistic_initsteps_supplement"><i class="fa fa-check"></i><b>47.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="47.3.3" data-path="logistic.html"><a href="logistic.html#glm_function_simple_logistic"><i class="fa fa-check"></i><b>47.3.3</b> Simple Logistic Regression Model Using <code>glm</code> Function from Base R</a></li>
<li class="chapter" data-level="47.3.4" data-path="logistic.html"><a href="logistic.html#glm_function_multiple_logistic"><i class="fa fa-check"></i><b>47.3.4</b> Multiple Logistic Regression Using <code>glm</code> Function from Base R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="48" data-path="kfold.html"><a href="kfold.html"><i class="fa fa-check"></i><b>48</b> Applying <em>k</em>-Fold Cross-Validation to Logistic Regression</a>
<ul>
<li class="chapter" data-level="48.1" data-path="kfold.html"><a href="kfold.html#conceptualoverview_kfold"><i class="fa fa-check"></i><b>48.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="48.1.1" data-path="kfold.html"><a href="kfold.html#review_predictiveanalytics"><i class="fa fa-check"></i><b>48.1.1</b> Review of Predictive Analytics</a></li>
<li class="chapter" data-level="48.1.2" data-path="kfold.html"><a href="kfold.html#review_kfold"><i class="fa fa-check"></i><b>48.1.2</b> Review of <em>k</em>-Fold Cross-Validation</a></li>
<li class="chapter" data-level="48.1.3" data-path="kfold.html"><a href="kfold.html#conceptualvideo_kfold"><i class="fa fa-check"></i><b>48.1.3</b> Conceptual Video</a></li>
</ul></li>
<li class="chapter" data-level="48.2" data-path="kfold.html"><a href="kfold.html#tutorial_kfold"><i class="fa fa-check"></i><b>48.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="48.2.1" data-path="kfold.html"><a href="kfold.html#videotutorial_kfold"><i class="fa fa-check"></i><b>48.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="48.2.2" data-path="kfold.html"><a href="kfold.html#functions_kfold"><i class="fa fa-check"></i><b>48.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="48.2.3" data-path="kfold.html"><a href="kfold.html#initsteps_kfold"><i class="fa fa-check"></i><b>48.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="48.2.4" data-path="kfold.html"><a href="kfold.html#estimate_kfold_logistic"><i class="fa fa-check"></i><b>48.2.4</b> Apply <em>k</em>-Fold Cross-Validation Using Logistic Regression</a></li>
<li class="chapter" data-level="48.2.5" data-path="kfold.html"><a href="kfold.html#summary_kfold"><i class="fa fa-check"></i><b>48.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="survival.html"><a href="survival.html"><i class="fa fa-check"></i><b>49</b> Understanding Length of Service Using Survival Analysis</a>
<ul>
<li class="chapter" data-level="49.1" data-path="survival.html"><a href="survival.html#conceptualoverview_survival"><i class="fa fa-check"></i><b>49.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="49.1.1" data-path="survival.html"><a href="survival.html#review_censoring_survival"><i class="fa fa-check"></i><b>49.1.1</b> Censoring</a></li>
<li class="chapter" data-level="49.1.2" data-path="survival.html"><a href="survival.html#review_types_survival"><i class="fa fa-check"></i><b>49.1.2</b> Types of Survival Analysis</a></li>
<li class="chapter" data-level="49.1.3" data-path="survival.html"><a href="survival.html#conceptualvideo_survival"><i class="fa fa-check"></i><b>49.1.3</b> Conceptual Video</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="survival.html"><a href="survival.html#tutorial_survival"><i class="fa fa-check"></i><b>49.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="49.2.1" data-path="survival.html"><a href="survival.html#videotutorial_survival"><i class="fa fa-check"></i><b>49.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="49.2.2" data-path="survival.html"><a href="survival.html#functions_survival"><i class="fa fa-check"></i><b>49.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="49.2.3" data-path="survival.html"><a href="survival.html#initsteps_survival"><i class="fa fa-check"></i><b>49.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="49.2.4" data-path="survival.html"><a href="survival.html#createcensoring_survival"><i class="fa fa-check"></i><b>49.2.4</b> Create a Censoring Variable</a></li>
<li class="chapter" data-level="49.2.5" data-path="survival.html"><a href="survival.html#inspectlosdistribution_survival"><i class="fa fa-check"></i><b>49.2.5</b> Inspect Distribution of Length of Service</a></li>
<li class="chapter" data-level="49.2.6" data-path="survival.html"><a href="survival.html#conductkmanalysis_lifetable_survival"><i class="fa fa-check"></i><b>49.2.6</b> Conduct Kaplan-Meier Analysis &amp; Create Life Table</a></li>
<li class="chapter" data-level="49.2.7" data-path="survival.html"><a href="survival.html#estimatecox_survival"><i class="fa fa-check"></i><b>49.2.7</b> Estimate Cox Proportional Hazards Model</a></li>
<li class="chapter" data-level="49.2.8" data-path="survival.html"><a href="survival.html#summary_survival"><i class="fa fa-check"></i><b>49.2.8</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IX Employee Performance Management</b></span></li>
<li class="chapter" data-level="50" data-path="performancemanagement.html"><a href="performancemanagement.html"><i class="fa fa-check"></i><b>50</b> Introduction to Employee Performance Management</a>
<ul>
<li class="chapter" data-level="50.1" data-path="performancemanagement.html"><a href="performancemanagement.html#chapters_performancemanagement"><i class="fa fa-check"></i><b>50.1</b> Chapters Included</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html"><i class="fa fa-check"></i><b>51</b> Evaluating Convergent &amp; Discriminant Validity Using Scatter Plots &amp; Correlations</a>
<ul>
<li class="chapter" data-level="51.1" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#conceptualoverview_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="51.1.1" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#review_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.1.1</b> Review of Concurrent &amp; Discriminant Validity</a></li>
<li class="chapter" data-level="51.1.2" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#review_pearson_pointbiserial_correlation"><i class="fa fa-check"></i><b>51.1.2</b> Review of Pearson Product-Moment &amp; Point-Biserial Correlation</a></li>
<li class="chapter" data-level="51.1.3" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#review_bivariatescatterplot"><i class="fa fa-check"></i><b>51.1.3</b> Review of Bivariate Scatter Plot</a></li>
</ul></li>
<li class="chapter" data-level="51.2" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#tutorial_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="51.2.1" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#videotutorial_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="51.2.2" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#functions_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="51.2.3" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#initsteps_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="51.2.4" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#bivariatescatterplot_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.4</b> Visualize Association Using a Bivariate Scatter Plot</a></li>
<li class="chapter" data-level="51.2.5" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#estimate_correlation_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.5</b> Estimate Correlations</a></li>
<li class="chapter" data-level="51.2.6" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#correlationmatrix_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.6</b> Create Correlation Matrix</a></li>
<li class="chapter" data-level="51.2.7" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#summary_convergentdiscriminantvalidity"><i class="fa fa-check"></i><b>51.2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#convergentdiscriminantvalidity_supplement"><i class="fa fa-check"></i><b>51.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="51.3.1" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#convergentdiscriminantvalidity_supplement_functions"><i class="fa fa-check"></i><b>51.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="51.3.2" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#convergentdiscriminantvalidity_initsteps_supplement"><i class="fa fa-check"></i><b>51.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="51.3.3" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#shapiro.test_function"><i class="fa fa-check"></i><b>51.3.3</b> <code>shapiro.test</code> Function from Base R</a></li>
<li class="chapter" data-level="51.3.4" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#apatable_correlationmatrix"><i class="fa fa-check"></i><b>51.3.4</b> APA-Style Results Table</a></li>
<li class="chapter" data-level="51.3.5" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#cor.plot_psych_function"><i class="fa fa-check"></i><b>51.3.5</b> <code>cor.plot</code> Function from <code>psych</code> package</a></li>
<li class="chapter" data-level="51.3.6" data-path="convergentdiscriminantvalidity.html"><a href="convergentdiscriminantvalidity.html#corrgram_corrgram_function"><i class="fa fa-check"></i><b>51.3.6</b> <code>corrgram</code> Function from <code>corrgram</code> package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="52" data-path="polynomialregression.html"><a href="polynomialregression.html"><i class="fa fa-check"></i><b>52</b> Investigating Nonlinear Associations Using Polynomial Regression</a>
<ul>
<li class="chapter" data-level="52.1" data-path="polynomialregression.html"><a href="polynomialregression.html#conceptualoverview_polynomialregression"><i class="fa fa-check"></i><b>52.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="52.1.1" data-path="polynomialregression.html"><a href="polynomialregression.html#statisticalassumptions_polynomialregression"><i class="fa fa-check"></i><b>52.1.1</b> Statistical Assumptions</a></li>
<li class="chapter" data-level="52.1.2" data-path="polynomialregression.html"><a href="polynomialregression.html#statisticalsignficance_polynomialregression"><i class="fa fa-check"></i><b>52.1.2</b> Statistical Significance</a></li>
</ul></li>
<li class="chapter" data-level="52.2" data-path="polynomialregression.html"><a href="polynomialregression.html#tutorial_polynomialregression"><i class="fa fa-check"></i><b>52.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="52.2.1" data-path="polynomialregression.html"><a href="polynomialregression.html#functions_polynomialregression"><i class="fa fa-check"></i><b>52.2.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="52.2.2" data-path="polynomialregression.html"><a href="polynomialregression.html#initsteps_polynomialregression"><i class="fa fa-check"></i><b>52.2.2</b> Initial Steps</a></li>
<li class="chapter" data-level="52.2.3" data-path="polynomialregression.html"><a href="polynomialregression.html#bivariatescatterplot_polynomialregression"><i class="fa fa-check"></i><b>52.2.3</b> Visualize Association Using a Bivariate Scatter Plot</a></li>
<li class="chapter" data-level="52.2.4" data-path="polynomialregression.html"><a href="polynomialregression.html#estimate_polynomialregression"><i class="fa fa-check"></i><b>52.2.4</b> Estimate Polynomial Regression Model</a></li>
<li class="chapter" data-level="52.2.5" data-path="polynomialregression.html"><a href="polynomialregression.html#summary_polynomialregression"><i class="fa fa-check"></i><b>52.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="53" data-path="lassoregression.html"><a href="lassoregression.html"><i class="fa fa-check"></i><b>53</b> Supervised Statistical Learning Using Lasso Regression</a>
<ul>
<li class="chapter" data-level="53.1" data-path="lassoregression.html"><a href="lassoregression.html#conceptualoverview_lassoregression"><i class="fa fa-check"></i><b>53.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="53.1.1" data-path="lassoregression.html"><a href="lassoregression.html#shrinkage_lassoregression"><i class="fa fa-check"></i><b>53.1.1</b> Shrinkage</a></li>
<li class="chapter" data-level="53.1.2" data-path="lassoregression.html"><a href="lassoregression.html#regularization_lassoregression"><i class="fa fa-check"></i><b>53.1.2</b> Regularization</a></li>
<li class="chapter" data-level="53.1.3" data-path="lassoregression.html"><a href="lassoregression.html#tuning_lassoregression"><i class="fa fa-check"></i><b>53.1.3</b> Tuning</a></li>
<li class="chapter" data-level="53.1.4" data-path="lassoregression.html"><a href="lassoregression.html#modeltype_selection_lassoregression"><i class="fa fa-check"></i><b>53.1.4</b> Model Type Selection</a></li>
<li class="chapter" data-level="53.1.5" data-path="lassoregression.html"><a href="lassoregression.html#crossvalidation_lassoregression"><i class="fa fa-check"></i><b>53.1.5</b> Cross-Validation</a></li>
<li class="chapter" data-level="53.1.6" data-path="lassoregression.html"><a href="lassoregression.html#predictiveanalytics_lassoregression"><i class="fa fa-check"></i><b>53.1.6</b> Predictive Analytics</a></li>
<li class="chapter" data-level="53.1.7" data-path="lassoregression.html"><a href="lassoregression.html#conceptualvideo_lassoregression"><i class="fa fa-check"></i><b>53.1.7</b> Conceptual Video</a></li>
</ul></li>
<li class="chapter" data-level="53.2" data-path="lassoregression.html"><a href="lassoregression.html#tutorial_lassoregression"><i class="fa fa-check"></i><b>53.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="53.2.1" data-path="lassoregression.html"><a href="lassoregression.html#videotutorial_lassoregression"><i class="fa fa-check"></i><b>53.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="53.2.2" data-path="lassoregression.html"><a href="lassoregression.html#functions_lassoregression"><i class="fa fa-check"></i><b>53.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="53.2.3" data-path="lassoregression.html"><a href="lassoregression.html#initsteps_lassoregression"><i class="fa fa-check"></i><b>53.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="53.2.4" data-path="lassoregression.html"><a href="lassoregression.html#processoverview_lasso"><i class="fa fa-check"></i><b>53.2.4</b> Process Overview</a></li>
<li class="chapter" data-level="53.2.5" data-path="lassoregression.html"><a href="lassoregression.html#partitiondata_lasso"><i class="fa fa-check"></i><b>53.2.5</b> Partition the Data</a></li>
<li class="chapter" data-level="53.2.6" data-path="lassoregression.html"><a href="lassoregression.html#specify-k-fold-cross-validation"><i class="fa fa-check"></i><b>53.2.6</b> Specify <em>k</em>-Fold Cross-Validation</a></li>
<li class="chapter" data-level="53.2.7" data-path="lassoregression.html"><a href="lassoregression.html#trainlasso_lasso"><i class="fa fa-check"></i><b>53.2.7</b> Specify and Train Lasso Regression Model</a></li>
<li class="chapter" data-level="53.2.8" data-path="lassoregression.html"><a href="lassoregression.html#compare_ols_lasso"><i class="fa fa-check"></i><b>53.2.8</b> Optional: Compare to Lasso Model to OLS Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="53.2.9" data-path="lassoregression.html"><a href="lassoregression.html#summary_lasso"><i class="fa fa-check"></i><b>53.2.9</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="pathanalysis.html"><a href="pathanalysis.html"><i class="fa fa-check"></i><b>54</b> Investigating Processes Using Path Analysis</a>
<ul>
<li class="chapter" data-level="54.1" data-path="pathanalysis.html"><a href="pathanalysis.html#conceptualoverview_pathanalysis"><i class="fa fa-check"></i><b>54.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="54.1.1" data-path="pathanalysis.html"><a href="pathanalysis.html#pathdiagram_pathanalysis"><i class="fa fa-check"></i><b>54.1.1</b> Path Diagram</a></li>
<li class="chapter" data-level="54.1.2" data-path="pathanalysis.html"><a href="pathanalysis.html#modelidentification_pathanalysis"><i class="fa fa-check"></i><b>54.1.2</b> Model Identification</a></li>
<li class="chapter" data-level="54.1.3" data-path="pathanalysis.html"><a href="pathanalysis.html#modelfit_pathanalysis"><i class="fa fa-check"></i><b>54.1.3</b> Model Fit</a></li>
<li class="chapter" data-level="54.1.4" data-path="pathanalysis.html"><a href="pathanalysis.html#parameterestimatese_pathanalysis"><i class="fa fa-check"></i><b>54.1.4</b> Parameter Estimates</a></li>
<li class="chapter" data-level="54.1.5" data-path="pathanalysis.html"><a href="pathanalysis.html#statisticalassumptions_pathanalysis"><i class="fa fa-check"></i><b>54.1.5</b> Statistical Assumptions</a></li>
<li class="chapter" data-level="54.1.6" data-path="pathanalysis.html"><a href="pathanalysis.html#conceptualvideo_pathanalysis"><i class="fa fa-check"></i><b>54.1.6</b> Conceptual Video</a></li>
</ul></li>
<li class="chapter" data-level="54.2" data-path="pathanalysis.html"><a href="pathanalysis.html#tutorial_pathanalysis"><i class="fa fa-check"></i><b>54.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="54.2.1" data-path="pathanalysis.html"><a href="pathanalysis.html#videotutorial_pathanalysis"><i class="fa fa-check"></i><b>54.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="54.2.2" data-path="pathanalysis.html"><a href="pathanalysis.html#functions_pathanalysis"><i class="fa fa-check"></i><b>54.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="54.2.3" data-path="pathanalysis.html"><a href="pathanalysis.html#initsteps_pathanalysis"><i class="fa fa-check"></i><b>54.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="54.2.4" data-path="pathanalysis.html"><a href="pathanalysis.html#specifymodel_pathanalysis"><i class="fa fa-check"></i><b>54.2.4</b> Specify &amp; Estimate Path Analysis Models</a></li>
<li class="chapter" data-level="54.2.5" data-path="pathanalysis.html"><a href="pathanalysis.html#additionalinfo_pathanalysis"><i class="fa fa-check"></i><b>54.2.5</b> Additional Information on Model Specification Notation</a></li>
<li class="chapter" data-level="54.2.6" data-path="pathanalysis.html"><a href="pathanalysis.html#summary_pathanalysis"><i class="fa fa-check"></i><b>54.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="55" data-path="mediationanalysis.html"><a href="mediationanalysis.html"><i class="fa fa-check"></i><b>55</b> Estimating a Mediation Model Using Path Analysis</a>
<ul>
<li class="chapter" data-level="55.1" data-path="mediationanalysis.html"><a href="mediationanalysis.html#conceptualoverview_mediationanalysis"><i class="fa fa-check"></i><b>55.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="55.1.1" data-path="mediationanalysis.html"><a href="mediationanalysis.html#indirecteffect_mediationanalysis"><i class="fa fa-check"></i><b>55.1.1</b> Estimation of Indirect Effect</a></li>
<li class="chapter" data-level="55.1.2" data-path="mediationanalysis.html"><a href="mediationanalysis.html#modelidentification_mediationanalysis"><i class="fa fa-check"></i><b>55.1.2</b> Model Identification</a></li>
<li class="chapter" data-level="55.1.3" data-path="mediationanalysis.html"><a href="mediationanalysis.html#modelfit_mediationanalysis"><i class="fa fa-check"></i><b>55.1.3</b> Model Fit</a></li>
<li class="chapter" data-level="55.1.4" data-path="mediationanalysis.html"><a href="mediationanalysis.html#parameterestimatese_mediationanalysis"><i class="fa fa-check"></i><b>55.1.4</b> Parameter Estimates</a></li>
<li class="chapter" data-level="55.1.5" data-path="mediationanalysis.html"><a href="mediationanalysis.html#statisticalassumptions_mediationanalysis"><i class="fa fa-check"></i><b>55.1.5</b> Statistical Assumptions</a></li>
<li class="chapter" data-level="55.1.6" data-path="mediationanalysis.html"><a href="mediationanalysis.html#conceptualvideo_mediationanalysis"><i class="fa fa-check"></i><b>55.1.6</b> Conceptual Video</a></li>
</ul></li>
<li class="chapter" data-level="55.2" data-path="mediationanalysis.html"><a href="mediationanalysis.html#tutorial_mediationanalysis"><i class="fa fa-check"></i><b>55.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="55.2.1" data-path="mediationanalysis.html"><a href="mediationanalysis.html#videotutorial_mediationanalysis"><i class="fa fa-check"></i><b>55.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="55.2.2" data-path="mediationanalysis.html"><a href="mediationanalysis.html#functions_mediationanalysis"><i class="fa fa-check"></i><b>55.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="55.2.3" data-path="mediationanalysis.html"><a href="mediationanalysis.html#initsteps_mediationanalysis"><i class="fa fa-check"></i><b>55.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="55.2.4" data-path="mediationanalysis.html"><a href="mediationanalysis.html#specifymodel_mediationanalysis"><i class="fa fa-check"></i><b>55.2.4</b> Specify &amp; Estimate a Mediation Analysis Model</a></li>
<li class="chapter" data-level="55.2.5" data-path="mediationanalysis.html"><a href="mediationanalysis.html#summary_mediationanalysis"><i class="fa fa-check"></i><b>55.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>X Employee Compensation &amp; Reward Systems</b></span></li>
<li class="chapter" data-level="56" data-path="compensation.html"><a href="compensation.html"><i class="fa fa-check"></i><b>56</b> Introduction to Employee Compensation &amp; Reward Systems</a>
<ul>
<li class="chapter" data-level="56.1" data-path="compensation.html"><a href="compensation.html#chapters_compensation"><i class="fa fa-check"></i><b>56.1</b> Chapters Included</a></li>
</ul></li>
<li class="chapter" data-level="57" data-path="marketsurvey.html"><a href="marketsurvey.html"><i class="fa fa-check"></i><b>57</b> Preparing Market Survey Data</a>
<ul>
<li class="chapter" data-level="57.1" data-path="marketsurvey.html"><a href="marketsurvey.html#conceptualoverview_marketsurvey"><i class="fa fa-check"></i><b>57.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="57.1.1" data-path="marketsurvey.html"><a href="marketsurvey.html#agingdata_marketsurvey"><i class="fa fa-check"></i><b>57.1.1</b> Aging Market Survey Data</a></li>
<li class="chapter" data-level="57.1.2" data-path="marketsurvey.html"><a href="marketsurvey.html#applyingweights_marketsurvey"><i class="fa fa-check"></i><b>57.1.2</b> Applying Market Survey Weights</a></li>
<li class="chapter" data-level="57.1.3" data-path="marketsurvey.html"><a href="marketsurvey.html#conceptualvideo_marketsurvey"><i class="fa fa-check"></i><b>57.1.3</b> Conceptual Video</a></li>
</ul></li>
<li class="chapter" data-level="57.2" data-path="marketsurvey.html"><a href="marketsurvey.html#tutorial_marketsurvey"><i class="fa fa-check"></i><b>57.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="57.2.1" data-path="marketsurvey.html"><a href="marketsurvey.html#videotutorial_marketsurvey"><i class="fa fa-check"></i><b>57.2.1</b> Video Tutorials</a></li>
<li class="chapter" data-level="57.2.2" data-path="marketsurvey.html"><a href="marketsurvey.html#functions_marketsurvey"><i class="fa fa-check"></i><b>57.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="57.2.3" data-path="marketsurvey.html"><a href="marketsurvey.html#initsteps_marketsurvey"><i class="fa fa-check"></i><b>57.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="57.2.4" data-path="marketsurvey.html"><a href="marketsurvey.html#agedata_marketsurvey"><i class="fa fa-check"></i><b>57.2.4</b> Age the Data</a></li>
<li class="chapter" data-level="57.2.5" data-path="marketsurvey.html"><a href="marketsurvey.html#weightdata_marketsurvey"><i class="fa fa-check"></i><b>57.2.5</b> Compute the Sample-Weighted Means</a></li>
<li class="chapter" data-level="57.2.6" data-path="marketsurvey.html"><a href="marketsurvey.html#summary_marketsurvey"><i class="fa fa-check"></i><b>57.2.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="58" data-path="marketpayline.html"><a href="marketpayline.html"><i class="fa fa-check"></i><b>58</b> Estimating a Market Pay Line Using Linear &amp; Polynomial Regression</a>
<ul>
<li class="chapter" data-level="58.1" data-path="marketpayline.html"><a href="marketpayline.html#conceptualoverview_marketpayline"><i class="fa fa-check"></i><b>58.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="58.1.1" data-path="marketpayline.html"><a href="marketpayline.html#statisticalassumptions_marketpayline"><i class="fa fa-check"></i><b>58.1.1</b> Statistical Assumptions</a></li>
<li class="chapter" data-level="58.1.2" data-path="marketpayline.html"><a href="marketpayline.html#statisticalsignificance_marketpayline"><i class="fa fa-check"></i><b>58.1.2</b> Statistical Significance</a></li>
<li class="chapter" data-level="58.1.3" data-path="marketpayline.html"><a href="marketpayline.html#practicalsignificance_marketpayline"><i class="fa fa-check"></i><b>58.1.3</b> Practical Significance</a></li>
<li class="chapter" data-level="58.1.4" data-path="marketpayline.html"><a href="marketpayline.html#conceptualvideo_marketpayline"><i class="fa fa-check"></i><b>58.1.4</b> Conceptual Video</a></li>
</ul></li>
<li class="chapter" data-level="58.2" data-path="marketpayline.html"><a href="marketpayline.html#tutorial_marketpayline"><i class="fa fa-check"></i><b>58.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="58.2.1" data-path="marketpayline.html"><a href="marketpayline.html#videotutorial_marketpayline"><i class="fa fa-check"></i><b>58.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="58.2.2" data-path="marketpayline.html"><a href="marketpayline.html#functions_marketpayline"><i class="fa fa-check"></i><b>58.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="58.2.3" data-path="marketpayline.html"><a href="marketpayline.html#initsteps_marketpayline"><i class="fa fa-check"></i><b>58.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="58.2.4" data-path="marketpayline.html"><a href="marketpayline.html#estimate_slr_marketpayline"><i class="fa fa-check"></i><b>58.2.4</b> Estimate a Market Pay Line</a></li>
<li class="chapter" data-level="58.2.5" data-path="marketpayline.html"><a href="marketpayline.html#summary_marketpayline"><i class="fa fa-check"></i><b>58.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path="paydeterminants.html"><a href="paydeterminants.html"><i class="fa fa-check"></i><b>59</b> Identifying Pay Determinants &amp; Evaluating Pay Equity Using Hierarchical Linear Regression</a>
<ul>
<li class="chapter" data-level="59.1" data-path="paydeterminants.html"><a href="paydeterminants.html#conceptualoverview_paydeterminants"><i class="fa fa-check"></i><b>59.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="59.1.1" data-path="paydeterminants.html"><a href="paydeterminants.html#review_hiearchicallinearregression_paydeterminants"><i class="fa fa-check"></i><b>59.1.1</b> Review of Hiearchical Linear Regression</a></li>
<li class="chapter" data-level="59.1.2" data-path="paydeterminants.html"><a href="paydeterminants.html#conceptualvideo_paydeterminants"><i class="fa fa-check"></i><b>59.1.2</b> Conceptual Videos</a></li>
</ul></li>
<li class="chapter" data-level="59.2" data-path="paydeterminants.html"><a href="paydeterminants.html#tutorial_paydeterminants"><i class="fa fa-check"></i><b>59.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="59.2.1" data-path="paydeterminants.html"><a href="paydeterminants.html#videotutorial_paydeterminants"><i class="fa fa-check"></i><b>59.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="59.2.2" data-path="paydeterminants.html"><a href="paydeterminants.html#functions_paydeterminants"><i class="fa fa-check"></i><b>59.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="59.2.3" data-path="paydeterminants.html"><a href="paydeterminants.html#initsteps_paydeterminants"><i class="fa fa-check"></i><b>59.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="59.2.4" data-path="paydeterminants.html"><a href="paydeterminants.html#perform_hiearchicallinearregression_paydeterminants"><i class="fa fa-check"></i><b>59.2.4</b> Perform Hierarchical Linear Regression</a></li>
<li class="chapter" data-level="59.2.5" data-path="paydeterminants.html"><a href="paydeterminants.html#summary_paydeterminants"><i class="fa fa-check"></i><b>59.2.5</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path="comparatio.html"><a href="comparatio.html"><i class="fa fa-check"></i><b>60</b> Computing Compa-Ratios &amp; Investigating Pay Compression</a>
<ul>
<li class="chapter" data-level="60.1" data-path="comparatio.html"><a href="comparatio.html#conceptualoverview_comparatio"><i class="fa fa-check"></i><b>60.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="60.1.1" data-path="comparatio.html"><a href="comparatio.html#conceptualvideo_comparatio"><i class="fa fa-check"></i><b>60.1.1</b> Conceptual Videos</a></li>
</ul></li>
<li class="chapter" data-level="60.2" data-path="comparatio.html"><a href="comparatio.html#tutorial_comparatio"><i class="fa fa-check"></i><b>60.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="60.2.1" data-path="comparatio.html"><a href="comparatio.html#videotutorial_comparatio"><i class="fa fa-check"></i><b>60.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="60.2.2" data-path="comparatio.html"><a href="comparatio.html#functions_comparatio"><i class="fa fa-check"></i><b>60.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="60.2.3" data-path="comparatio.html"><a href="comparatio.html#initsteps_comparatio"><i class="fa fa-check"></i><b>60.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="60.2.4" data-path="comparatio.html"><a href="comparatio.html#compute_comparatio_employee"><i class="fa fa-check"></i><b>60.2.4</b> Compute Compa-Ratio for Each Employee</a></li>
<li class="chapter" data-level="60.2.5" data-path="comparatio.html"><a href="comparatio.html#compute_comparatio_group"><i class="fa fa-check"></i><b>60.2.5</b> Compute Compa-Ratio for Group of Employees</a></li>
<li class="chapter" data-level="60.2.6" data-path="comparatio.html"><a href="comparatio.html#compute_comparatio_scatterplot"><i class="fa fa-check"></i><b>60.2.6</b> Investigate Pay Compression and Pay Inversion</a></li>
<li class="chapter" data-level="60.2.7" data-path="comparatio.html"><a href="comparatio.html#summary_comparatio"><i class="fa fa-check"></i><b>60.2.7</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>XI Odds &amp; Ends</b></span></li>
<li class="chapter" data-level="61" data-path="primerdata.html"><a href="primerdata.html"><i class="fa fa-check"></i><b>61</b> Primer on Data</a></li>
<li class="chapter" data-level="62" data-path="legalethical.html"><a href="legalethical.html"><i class="fa fa-check"></i><b>62</b> Legal &amp; Ethical Issues</a></li>
<li class="chapter" data-level="63" data-path="jdm_bias.html"><a href="jdm_bias.html"><i class="fa fa-check"></i><b>63</b> Judgment, Decision Making, &amp; Bias</a></li>
<li class="chapter" data-level="64" data-path="languageconsiderations.html"><a href="languageconsiderations.html"><i class="fa fa-check"></i><b>64</b> Language Considerations</a></li>
<li class="chapter" data-level="65" data-path="create_portfolio.html"><a href="create_portfolio.html"><i class="fa fa-check"></i><b>65</b> Creating a Data Analytics Portfolio</a></li>
<li class="chapter" data-level="66" data-path="literature_search_review.html"><a href="literature_search_review.html"><i class="fa fa-check"></i><b>66</b> Conducting a Literature Search &amp; Review</a></li>
<li class="chapter" data-level="67" data-path="statistical_practical_significance.html"><a href="statistical_practical_significance.html"><i class="fa fa-check"></i><b>67</b> Statistical &amp; Practical Significance</a></li>
<li class="chapter" data-level="68" data-path="missingdata.html"><a href="missingdata.html"><i class="fa fa-check"></i><b>68</b> Missing Data</a></li>
<li class="chapter" data-level="69" data-path="poweranalysis.html"><a href="poweranalysis.html"><i class="fa fa-check"></i><b>69</b> Power Analysis</a></li>
<li class="chapter" data-level="70" data-path="cfa.html"><a href="cfa.html"><i class="fa fa-check"></i><b>70</b> Evaluating Measurement Models Using Confirmatory Factor Analysis</a>
<ul>
<li class="chapter" data-level="70.1" data-path="cfa.html"><a href="cfa.html#conceptualoverview_cfa"><i class="fa fa-check"></i><b>70.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="70.1.1" data-path="cfa.html"><a href="cfa.html#pathdiagram_cfa"><i class="fa fa-check"></i><b>70.1.1</b> Path Diagrams</a></li>
<li class="chapter" data-level="70.1.2" data-path="cfa.html"><a href="cfa.html#modelidentification_cfa"><i class="fa fa-check"></i><b>70.1.2</b> Model Identification</a></li>
<li class="chapter" data-level="70.1.3" data-path="cfa.html"><a href="cfa.html#modelfit_cfa"><i class="fa fa-check"></i><b>70.1.3</b> Model Fit</a></li>
<li class="chapter" data-level="70.1.4" data-path="cfa.html"><a href="cfa.html#parameterestimates_cfa"><i class="fa fa-check"></i><b>70.1.4</b> Parameter Estimates</a></li>
<li class="chapter" data-level="70.1.5" data-path="cfa.html"><a href="cfa.html#modelcomparisons_cfa"><i class="fa fa-check"></i><b>70.1.5</b> Model Comparisons</a></li>
<li class="chapter" data-level="70.1.6" data-path="cfa.html"><a href="cfa.html#statisticalassumptions_cfa"><i class="fa fa-check"></i><b>70.1.6</b> Statistical Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="70.2" data-path="cfa.html"><a href="cfa.html#tutorial_cfa"><i class="fa fa-check"></i><b>70.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="70.2.1" data-path="cfa.html"><a href="cfa.html#videotutorial_cfa"><i class="fa fa-check"></i><b>70.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="70.2.2" data-path="cfa.html"><a href="cfa.html#functions_cfa"><i class="fa fa-check"></i><b>70.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="70.2.3" data-path="cfa.html"><a href="cfa.html#initsteps_cfa"><i class="fa fa-check"></i><b>70.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="70.2.4" data-path="cfa.html"><a href="cfa.html#onefactor_cfa"><i class="fa fa-check"></i><b>70.2.4</b> Estimate One-Factor CFA Models</a></li>
<li class="chapter" data-level="70.2.5" data-path="cfa.html"><a href="cfa.html#multifactor_cfa"><i class="fa fa-check"></i><b>70.2.5</b> Estimate Multi-Factor CFA Models</a></li>
<li class="chapter" data-level="70.2.6" data-path="cfa.html"><a href="cfa.html#nestedmodels_cfa"><i class="fa fa-check"></i><b>70.2.6</b> Nested Model Comparisons</a></li>
<li class="chapter" data-level="70.2.7" data-path="cfa.html"><a href="cfa.html#secondorder_cfa"><i class="fa fa-check"></i><b>70.2.7</b> Estimate Second-Order Model</a></li>
<li class="chapter" data-level="70.2.8" data-path="cfa.html"><a href="cfa.html#missingdata_cfa"><i class="fa fa-check"></i><b>70.2.8</b> Estimating Models with Missing Data</a></li>
<li class="chapter" data-level="70.2.9" data-path="cfa.html"><a href="cfa.html#dynamicfit_cfa"><i class="fa fa-check"></i><b>70.2.9</b> Simulate Dynamic Fit Index Cutoffs</a></li>
<li class="chapter" data-level="70.2.10" data-path="cfa.html"><a href="cfa.html#summary_cfa"><i class="fa fa-check"></i><b>70.2.10</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="71" data-path="lgm.html"><a href="lgm.html"><i class="fa fa-check"></i><b>71</b> Estimating Change Using Latent Growth Modeling</a>
<ul>
<li class="chapter" data-level="71.1" data-path="lgm.html"><a href="lgm.html#conceptualoverview_lgm"><i class="fa fa-check"></i><b>71.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="71.1.1" data-path="lgm.html"><a href="lgm.html#pathdiagram_lgm"><i class="fa fa-check"></i><b>71.1.1</b> Path Diagrams</a></li>
<li class="chapter" data-level="71.1.2" data-path="lgm.html"><a href="lgm.html#modelidentification_lgm"><i class="fa fa-check"></i><b>71.1.2</b> Model Identification</a></li>
<li class="chapter" data-level="71.1.3" data-path="lgm.html"><a href="lgm.html#modelfit_lgm"><i class="fa fa-check"></i><b>71.1.3</b> Model Fit</a></li>
<li class="chapter" data-level="71.1.4" data-path="lgm.html"><a href="lgm.html#parameterestimates_lgm"><i class="fa fa-check"></i><b>71.1.4</b> Parameter Estimates</a></li>
<li class="chapter" data-level="71.1.5" data-path="lgm.html"><a href="lgm.html#modelcomparisons_lgm"><i class="fa fa-check"></i><b>71.1.5</b> Model Comparisons</a></li>
<li class="chapter" data-level="71.1.6" data-path="lgm.html"><a href="lgm.html#statisticalassumptions_lgm"><i class="fa fa-check"></i><b>71.1.6</b> Statistical Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="71.2" data-path="lgm.html"><a href="lgm.html#tutorial_lgm"><i class="fa fa-check"></i><b>71.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="71.2.1" data-path="lgm.html"><a href="lgm.html#videotutorial_lgm"><i class="fa fa-check"></i><b>71.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="71.2.2" data-path="lgm.html"><a href="lgm.html#functions_lgm"><i class="fa fa-check"></i><b>71.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="71.2.3" data-path="lgm.html"><a href="lgm.html#initsteps_lgm"><i class="fa fa-check"></i><b>71.2.3</b> Initial Steps</a></li>
<li class="chapter" data-level="71.2.4" data-path="lgm.html"><a href="lgm.html#dataviz_lgm"><i class="fa fa-check"></i><b>71.2.4</b> Visualizing Change</a></li>
<li class="chapter" data-level="71.2.5" data-path="lgm.html"><a href="lgm.html#unconditional_lgm"><i class="fa fa-check"></i><b>71.2.5</b> Estimate Unconditional Unconstrained Latent Growth Model</a></li>
<li class="chapter" data-level="71.2.6" data-path="lgm.html"><a href="lgm.html#nestedmodels_lgm"><i class="fa fa-check"></i><b>71.2.6</b> Nested Model Comparisons</a></li>
<li class="chapter" data-level="71.2.7" data-path="lgm.html"><a href="lgm.html#nonlinear_lgm"><i class="fa fa-check"></i><b>71.2.7</b> Estimate Nonlinear Latent Growth Models</a></li>
<li class="chapter" data-level="71.2.8" data-path="lgm.html"><a href="lgm.html#missingdata_lgm"><i class="fa fa-check"></i><b>71.2.8</b> Estimating Models with Missing Data</a></li>
<li class="chapter" data-level="71.2.9" data-path="lgm.html"><a href="lgm.html#summary_lgm"><i class="fa fa-check"></i><b>71.2.9</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="72" data-path="mixedfactorial.html"><a href="mixedfactorial.html"><i class="fa fa-check"></i><b>72</b> Evaluating a Pre-Test/Post-Test with Control Group Design Using an Independent-Samples <em>t</em>-test</a>
<ul>
<li class="chapter" data-level="72.1" data-path="mixedfactorial.html"><a href="mixedfactorial.html#conceptualoverview_mixedfactorial"><i class="fa fa-check"></i><b>72.1</b> Conceptual Overview</a>
<ul>
<li class="chapter" data-level="72.1.1" data-path="mixedfactorial.html"><a href="mixedfactorial.html#statisticalassumptions_mixedfactorial"><i class="fa fa-check"></i><b>72.1.1</b> Statistical Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="72.2" data-path="mixedfactorial.html"><a href="mixedfactorial.html#tutorial_mixedfactorial"><i class="fa fa-check"></i><b>72.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="72.2.1" data-path="mixedfactorial.html"><a href="mixedfactorial.html#videotutorial_mixedfactorial"><i class="fa fa-check"></i><b>72.2.1</b> Video Tutorial</a></li>
<li class="chapter" data-level="72.2.2" data-path="mixedfactorial.html"><a href="mixedfactorial.html#functions_mixedfactorial"><i class="fa fa-check"></i><b>72.2.2</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="72.2.3" data-path="mixedfactorial.html"><a href="mixedfactorial.html#initial-steps-initsteps_mixedfactorial"><i class="fa fa-check"></i><b>72.2.3</b> Initial Steps {#initsteps_mixedfactorial}}</a></li>
<li class="chapter" data-level="72.2.4" data-path="mixedfactorial.html"><a href="mixedfactorial.html#prepostcontrol_mixedfactorial"><i class="fa fa-check"></i><b>72.2.4</b> Evaluate a Pre-Test/Post-Test with Control Group Design</a></li>
<li class="chapter" data-level="72.2.5" data-path="mixedfactorial.html"><a href="mixedfactorial.html#summary_mixedfactorial"><i class="fa fa-check"></i><b>72.2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="72.3" data-path="mixedfactorial.html"><a href="mixedfactorial.html#mixedfactorial_supplement"><i class="fa fa-check"></i><b>72.3</b> Chapter Supplement</a>
<ul>
<li class="chapter" data-level="72.3.1" data-path="mixedfactorial.html"><a href="mixedfactorial.html#mixedfactorial_supplement_functions"><i class="fa fa-check"></i><b>72.3.1</b> Functions &amp; Packages Introduced</a></li>
<li class="chapter" data-level="72.3.2" data-path="mixedfactorial.html"><a href="mixedfactorial.html#mixedfactorial_initsteps_supplement"><i class="fa fa-check"></i><b>72.3.2</b> Initial Steps</a></li>
<li class="chapter" data-level="72.3.3" data-path="mixedfactorial.html"><a href="mixedfactorial.html#slr_mixedfactorial_supplement"><i class="fa fa-check"></i><b>72.3.3</b> Estimating a Simple Linear Regression Model with a Difference Score Outcome Variable</a></li>
<li class="chapter" data-level="72.3.4" data-path="mixedfactorial.html"><a href="mixedfactorial.html#bisercor_mixedfactorial_supplement"><i class="fa fa-check"></i><b>72.3.4</b> Estimating a Biserial Correlation with a Difference Score Outcome Variable</a></li>
<li class="chapter" data-level="72.3.5" data-path="mixedfactorial.html"><a href="mixedfactorial.html#mixedfactorialanova_mixedfactorial_supplement"><i class="fa fa-check"></i><b>72.3.5</b> Estimating a 2x2 Mixed-Factorial ANOVA Model</a></li>
<li class="chapter" data-level="72.3.6" data-path="mixedfactorial.html"><a href="mixedfactorial.html#rcm_mixedfactorial_supplement"><i class="fa fa-check"></i><b>72.3.6</b> Estimating a Random-Coefficients Multilevel Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R for HR:<br />
<em>An Introduction to Human Resource Analytics Using R</em></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="differentialprediction" class="section level1 hasAnchor" number="42">
<h1><span class="header-section-number">Chapter 42</span> Testing for Differential Prediction Using Moderated Multiple Linear Regression<a href="differentialprediction.html#differentialprediction" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter, we will learn how to apply test whether a selection tool shows evidence of differential prediction by using moderating multiple linear regression. We’ll begin with conceptual overviews of the moderated multiple linear regression and differential prediction, and we’ll conclude with a tutorial.</p>
<div id="conceptualoverview_differentialprediction" class="section level2 hasAnchor" number="42.1">
<h2><span class="header-section-number">42.1</span> Conceptual Overview<a href="differentialprediction.html#conceptualoverview_differentialprediction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we will learn how to use an ordinary least squares (OLS) moderated multiple linear regression model to test for differential prediction of an employee selection tool due to protected class membership. Thus, the way in which we build and interpret our moderated multiple regression model will be couched in the context of differential prediction. Nonetheless, this tutorial should still provide you with the technical and interpretation skills to understand how to apply moderated multiple linear regression in other non-selection contexts.</p>
<div id="review_mmlr" class="section level3 hasAnchor" number="42.1.1">
<h3><span class="header-section-number">42.1.1</span> Review of Moderated Multiple Linear Regression<a href="differentialprediction.html#review_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<iframe src="https://youtube.com/embed/mkia_KLjJ0M?rel=0" width="672" height="400px" data-external="1">
</iframe>
<p>Link to conceptual video: <a href="https://youtu.be/mkia_KLjJ0M" class="uri">https://youtu.be/mkia_KLjJ0M</a></p>
<p><strong>Moderated multiple linear regression (MMLR)</strong> is a specific type of multiple linear regression, which means that MMLR involves multiple predictor variables and a single outcome variable. For more information on multiple linear regression, check out the <a href="incrementalvalidity.html#incrementalvalidity">chapter on estimating incremental validity</a>. In MMLR, we are in effect determining whether the association between a predictor variable and the outcome variable is conditional upon the level/value of another predictor variable, the latter of which we often refer to as a moderator or moderator variable.</p>
<p><strong>Moderators:</strong> A <strong>moderator</strong> (i.e., moderator variable) is a predictor variable upon which an association between two other variables is conditional. A moderator variable can be continuous (e.g., age: measured in years) or categorical (e.g., location: Portland vs. Beaverton). When we find that one variable moderates the association between two other variables, we often refer to this as an <strong>interaction</strong> or interaction effect. For example, let’s imagine that we are interested in the association between job satisfaction and job performance in our organization. By introducing the categorical moderator variable of employee location (Portland vs. Beaverton), we can determine whether the magnitude and/or sign of the association between job satisfaction and job performance varies by the location at which employees work. Perhaps we find that the association between job satisfaction and job performance is significantly stronger for employees who work in Beaverton as compared to employees who work in Portland (see figure below), and thus we would conclude that there is a significant interaction between job satisfaction and location in relation to job performance.</p>
<div class="float">
<img src="mmlr_example1.png" alt="This line and scatter plot illustrates pictorially how a variable like employee location might moderate the association between job satisfaction and job performance." />
<div class="figcaption">This line and scatter plot illustrates pictorially how a variable like employee location might moderate the association between job satisfaction and job performance.</div>
</div>
<p>When investigating whether an interaction exists between two variables relative to the outcome variable, we need to create a new variable called an <strong>interaction term</strong> (i.e., <strong>product term</strong>). An interaction term is created by multiplying the scores of two predictor variables – or in other words, the computing the product of two variables’ respective scores. In fact, the presence of an in interaction term – and associated multiplication – signals why MMLR is referred to as a <em>multiplicative model</em>. In terms of the language we use to describe an interaction and the associated interaction term, we often refer to one of the predictor variables involved in an interaction as the moderator. For an illustration of how an interaction term is created, please refer to the table below.</p>
<div class="float">
<img src="mmlr_product_term_example.png" alt="To create an interaction term (i.e., product term), we simply multiply the associated predictor variables’ scores (e.g., predictor variable and moderator variable) for each case (e.g., employee)." />
<div class="figcaption">To create an interaction term (i.e., product term), we simply multiply the associated predictor variables’ scores (e.g., predictor variable and moderator variable) for each case (e.g., employee).</div>
</div>
<p><strong>Centering Predictor &amp; Moderator Variables:</strong> To improve the interpretability of the main effects (but not the interaction term) and to reduce collinearity between the predictor variables involved in the interaction term, we typically grand-mean center any continuous (interval, ratio) predictor variables; we do <em>not</em> need to center the outcome variable or a predictor or moderator variable that is categorical (e.g., dichotomous). As discussed in the <a href="center.html#center">chapter on centering and standardizing variables</a>, grand-mean centering refers to the process of subtracting the overall sample mean for a variable from each case’s score on that variable. We center the predictor variables (i.e., predictor and moderator variables) <em>before</em> computing the interaction term based on those variables. To illustrate how grand-mean centering works, take a look at the table below, and note that we are just subtracting the (grand) mean for the sample from the specific value on the predictor variable for each case.</p>
<div class="float">
<img src="mmlr_centering_example.png" alt="To grand-mean center a variable, we subtract the overall sample mean of the variable from each case’s score on that variable." />
<div class="figcaption">To grand-mean center a variable, we subtract the overall sample mean of the variable from each case’s score on that variable.</div>
</div>
<p>When we grand-mean center the predictor variables in a regression model, it also changes our interpretation of the <span class="math inline">\(\hat{Y}\)</span>-intercept value. If you recall from prior reviews of <a href="predictingcriterionscores.html#review_slr">simple linear regression</a> and <a href="incrementalvalidity.html#review_mlr">multiple linear regression</a>, the <span class="math inline">\(\hat{Y}\)</span>-intercept value is the mean of the outcome variable when each predictor variable(s) in the model is/are set to zero. Thus, when we center each predictor variable, we shift the mean of each variable to zero, which means that after grand-mean centering, the <span class="math inline">\(\hat{Y}\)</span>-intercept value is the mean of the outcome variable when each predictor variable is set to its mean. Beyond moderated multiple linear regression, grand-mean centering can be useful in simple and multiple linear regression models when interpreting the regression coefficients associated with the intercept and the slope(s), as in some cases, a score of zero on the predictor variable is theoretically meaningless, implausible, or both. For example, if one of our predictor variables has an interval measurement scale that ranges from 10-100, then a score of zero is not even part of the scale range, which would make shifting the zero value to the grand-mean a more meaningful value.</p>
<p>Regardless of your decision to grand-mean center or to not grand-mean center the predictor variable and moderator variables, the interaction term’s significance level (<em>p</em>-value) and model fit (i.e., <em>R</em><sup>2</sup>) will remain the same. In fact, sometimes it makes more sense to plot the findings of your model based on the uncentered version of the variables. That choice is really up to you and should be based on the context at hand.</p>
<p><strong>Moderated Multiple Linear Regression:</strong> In moderated multiple linear regression (MMLR), we have three or more predictor variables and a single outcome variable, where one of the predictor variables is the interaction term (i.e., product term) between two of the predictor variables (e.g., predictor and moderator variables). Just like multiple linear regression, MMLR allows for a series of covariates (control variables) to be included in the model; accordingly, each regression coefficient (i.e., slope, weight) represents the relationship between the associated predictor and the outcome variable when statistically controlling for all other predictors in the model.</p>
<p>To better understand what MMLR is and how it works, I find that it’s useful to consider a MMLR model in equation form. Specifically, let’s consider a scenario in which we estimate a MMLR with two predictor variables, their interaction term (i.e., product term), and a single outcome variable. The equation for such a model with <em>unstandardized</em> regression coefficients (<span class="math inline">\(b\)</span>) would be as follows:</p>
<p><span class="math inline">\(\hat{Y} = b_{0} + b_{1}X_1 + b_{2}X_2 + b_{3}X_1*X_2 + e\)</span></p>
<p>where <span class="math inline">\(\hat{Y}\)</span> represents the predicted score on the outcome variable (<span class="math inline">\(Y\)</span>), <span class="math inline">\(b_{0}\)</span> represents the <span class="math inline">\(\hat{Y}\)</span>-intercept value (i.e., model constant) when the predictor variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> and interaction term <span class="math inline">\(X_1*X_2\)</span> are equal to zero, <span class="math inline">\(b_{1}\)</span>, <span class="math inline">\(b_{2}\)</span>, and <span class="math inline">\(b_{3}\)</span> represent the unstandardized coefficients (i.e., weights, slopes) of the associations between the predictor variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> and interaction term <span class="math inline">\(X_1*X_2\)</span>, respectively, and the outcome variable <span class="math inline">\(\hat{Y}\)</span>, and <span class="math inline">\(e\)</span> represents the (residual) error in prediction. If the regression coefficient associated with the interaction term (<span class="math inline">\(b_{3}\)</span>) is found to be statistically significant, then we would conclude that there is evidence of a significant interaction effect.</p>
<p>If we conceptualize one of the predictor variables as a moderator variable, then we might re-write the equation from above by swapping out <span class="math inline">\(X_2\)</span> with <span class="math inline">\(W\)</span> (or <span class="math inline">\(Z\)</span>). The meaning of the equation remains the same, but changing the notation in this way may signal more clearly which variable we are labeling a moderator.</p>
<p><span class="math inline">\(\hat{Y} = b_{0} + b_{1}X + b_{2}W + b_{3}X*W + e\)</span></p>
<p>Unstandardized regression coefficient indicates the “raw” regression coefficient (i.e., weight, slope) when controlling for the associations between all other predictors in the model and the outcome variable; accordingly, each unstandardized regression coefficient represents how many unstandardized units of <span class="math inline">\(\hat{Y}\)</span> increase/decrease as a result of a single unit increase in a predictor variable, when statistically controlling for the effects of other predictors in the regression model.</p>
<p>Typically, we are most interested in whether slope differences exist; with that being said, in the context of testing for differential prediction (described below), we are also interested in whether intercept differences exist. In essence, a significant interaction term indicates the presence of <strong>slope differences</strong>, where slopes differences refer to significant variation in the association (i.e., slope) between the predictor variable and outcome variable by levels/values of the moderator variable. In the context of our first MMLR equation (see above), if the regression coefficient (<span class="math inline">\(b_{3}\)</span>) associated with the interaction term (<span class="math inline">\(X_1*X_2\)</span>) is statistically significant, we conclude that there is significant interaction and thus significant slope differences. In fact, we might even us language like, “<span class="math inline">\(X_2\)</span> moderates the association between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(Y\)</span>.”</p>
<p>When we find a statistically significant interaction, it is customary to plot the <strong>simple slopes</strong> and estimate whether each of the simple slopes is significantly different from zero. Simple slopes allow us to probe the form of the significant interaction so that we can more accurately describe it. Plus, the follow-up simple slopes analysis helps us understand at which levels of the moderator variable the association between the predictor and outcome variables is statistically significant. For a <em>continuous</em> moderator variable, we typically plot and estimate the simple slopes at 1 standard deviation (SD) above and below the mean for the variable – and sometimes at the mean of the variable as well; with that being said, if we want, we can choose more theoretically or empirically meaningful values for the moderator variable. For a <em>categorical</em> variable, we plot and estimate the simple slopes based on the different discrete levels (categories) of the variable. For example, if our moderator variable captures gender identity operationalized as man (0) and woman (1), then we would plot the simple slopes when sex is equal to man (0) and when sex is equal to woman (1).</p>
<div id="statisticalassumptions_mmlr" class="section level4 hasAnchor" number="42.1.1.1">
<h4><span class="header-section-number">42.1.1.1</span> Statistical Assumptions<a href="differentialprediction.html#statisticalassumptions_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The statistical assumptions that should be met prior to running and/or interpreting estimates from a moderated multiple linear regression model are the same as those for conventional multiple linear regression include:</p>
<ul>
<li>Cases are randomly sampled from the population, such that the variable scores for one individual are independent of the variable scores of another individual;</li>
<li>Data are free of multivariate outliers;</li>
<li>The association between the predictor and outcome variables is linear;</li>
<li>There is no (multi)collinearity between predictor variables;</li>
<li>Average residual error value is zero for all levels of the predictor variables;</li>
<li>Variances of residual errors are equal for all levels of the predictor variables, which is referred to as the assumption of homoscedasticity;</li>
<li>Residual errors are normally distributed for all levels of the predictor variables.</li>
</ul>
<p>The fourth statistical assumption refers to the concept of <strong>collinearity</strong> (<strong>multicollinearity</strong>). This can be a tricky concept to understand, so let’s take a moment to unpack it. When two or more predictor variables are specified in a regression model, as is the case with multiple linear regression, we need to be wary of collinearity. Collinearity refers to the extent to which predictor variables correlate with each other. Some level of intercorrelation between predictor variables is to be expected and is acceptable; however, if collinearity becomes substantial, it can affect the weights – and even the signs – of the regression coefficients in our model, which can be problematic from an interpretation standpoint. As such, we should avoid including predictors in a multiple linear regression model that correlate highly with one another. The <strong>tolerance</strong> statistic is commonly computed and serves as an indicator of collinearity. The tolerance statistic is computed by computing the shared variance (<em>R</em><sup>2</sup>) of just the predictor variables in a single model (excluding the outcome variable), and subtracting that <em>R</em><sup>2</sup> value from 1 (i.e., 1 - <em>R</em><sup>2</sup>). We typically grow concerned when the tolerance statistic falls below .20 and closer to .00. Ideally, we want the tolerance statistic to approach 1.00, as this indicates that there are lower levels of collinearity. From time to time, you might also see the <strong>variance inflation factor</strong> (<strong>VIF</strong>) reported as an indicator of collinearity; the VIF is just the reciprocal of the tolerance (i.e., 1/tolerance), and in my opinion, it is redundant to report and interpret both the tolerance and VIF. My recommendation is to focus just on the tolerance statistic when inferring whether the statistical assumption of no collinearity might have been violated.</p>
<p>Finally, with respect to the assumption that cases are randomly sampled from population, we will assume in this chapter’s data that this is not an issue. If we were to suspect, however, that there were some clustering or nesting of cases in units/groups (e.g., by supervisors, units, or facilities) with respect to our outcome variable, then we would need to run some type of multilevel model (e.g., hierarchical linear model, multilevel structural equation model), which is beyond the scope of this tutorial. An <em>intraclass correlation (ICC)</em> can be used to diagnose such nesting or cluster. Failing to account for clustering or nesting in the data can bias estimates of standard errors, which ultimately influences the <em>p</em>-values and inferences of statistical significance.</p>
</div>
<div id="statisticalsignficance_mmlr" class="section level4 hasAnchor" number="42.1.1.2">
<h4><span class="header-section-number">42.1.1.2</span> Statistical Signficance<a href="differentialprediction.html#statisticalsignficance_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Using null hypothesis significance testing (NHST), we interpret a <em>p</em>-value that is <em>less than .05</em> (or whatever two- or one-tailed alpha level we set) to meet the standard for statistical significance, meaning that we reject the null hypothesis that the regression coefficient is equal to zero when controlling for the effects of the other predictor variable(s) and interaction term variable in the model. In other words, if a regression coefficient’s <em>p</em>-value is less than .05, we conclude that the regression coefficient differs from zero to a statistically significant extent when controlling for the effects of other predictor variables in the model. In contrast, if the regression coefficient’s <em>p</em>-value is <em>equal to or greater than .05</em>, then we fail to reject the null hypothesis that the regression coefficient is equal to zero when controlling for the effects of other predictor variable(s) and interaction term variable in the model. Put differently, if a regression coefficient’s <em>p</em>-value is equal to or greater than .05, we conclude that the regression coefficient does <em>not</em> differ from zero to a statistically significant extent, leading us to conclude that there is no association between the predictor variable (or interaction term variable) and the outcome variable in the population – when controlling for the effects of other predictor variables and interaction term variable in the model.</p>
<p>When setting an alpha threshold, such as the conventional two-tailed .05 level, sometimes the question comes up regarding whether borderline <em>p</em>-values signify significance or nonsignificance. For our purposes, let’s be very strict in our application of the chosen alpha level. For example, if we set our alpha level at .05, <em>p</em> = .049 would be considered statistically significant, and <em>p</em> = .050 would be considered statistically nonsignificant.</p>
<p>Because our regression model estimates are based on data from a sample that is drawn from an underlying population, sampling error will affect the extent to which our sample is representative of the population from which its drawn. That is, a regression coefficient estimate (<em>b</em>) is a <em>point estimate</em> of the population parameter that is subject to sampling error. Fortunately, confidence intervals can give us a better idea of what the true population parameter value might be. If we apply an alpha level of .05 (two-tailed), then the equivalent confidence interval (CI) is a 95% CI. In terms of whether a regression coefficient is statistically significant, if the lower and upper limits of 95% CI do <em>not</em> include zero, then this tells us the same thing as a <em>p</em>-value that is less than .05. Strictly speaking, a 95% CI indicates that if we were to hypothetically draw many more samples from the underlying population and construct CIs for each of those samples, then the true parameter (i.e., true value of the regression coefficient in the population) would likely fall within the lower and upper bounds of 95% of the estimated CIs. In other words, the 95% CI gives us an indication of plausible values for the population parameter while taking into consideration sampling error. A wide CI (i.e., large difference between the lower and upper limits) signifies more sampling error, and a narrow CI signifies less sampling error.</p>
</div>
<div id="practicalsignficance_mmlr" class="section level4 hasAnchor" number="42.1.1.3">
<h4><span class="header-section-number">42.1.1.3</span> Practical Significance<a href="differentialprediction.html#practicalsignficance_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>As a reminder, an effect size is a standardized metric that can be compared across samples. In a moderated multiple linear regression (MMLR) model, an <em>unstandardized</em> regression coefficient (<span class="math inline">\(b\)</span>) is <em>not</em> an effect size. The reason being, an unstandardized regression coefficient estimate is based on the original scaling of the predictor and outcome variables, and thus the same effect will take on different regression coefficients to the extent that the predictor and outcome variables have different scalings across samples.</p>
<p>A <em>standardized</em> regression coefficient (<span class="math inline">\(\beta\)</span>) can be interpreted as an effect size (and thus an indicator of practical significance) given that it is standardized. With that being said, I suggest doing so with caution as collinearity (i.e., correlation) between predictor variables in the model can bias our interpretation of <span class="math inline">\(\beta\)</span> as an effect size. Thus, if your goal is just to understand the bivariate association between a predictor variable and an outcome variable (without introducing statistical control), then I recommend to just estimate a correlation coefficient as an indicator of practical significance, which I discuss in the chapter on <a href="criterionrelatedvalidity.html#practicalsignficance_correlation">estimating criterion-related validity using correlations</a>.</p>
<p>In a MMLR model, we can also describe the magnitude of the effect in terms of the proportion of variance explained in the outcome variable by the predictor variables (i.e., <em>R</em><sup>2</sup>). That is, in a multiple linear regression model, <em>R</em><sup>2</sup> represents the proportion of <em>collective</em> variance explained in the outcome variable by all of the predictor variables. Conceptually, we can think of the overlap between the variability in the predictor variables and and outcome variable as the variance explained (<em>R</em><sup>2</sup>), and <em>R</em><sup>2</sup> is a way to evaluate how well a model fits the data (i.e., model fit). I’ve found that the <em>R</em><sup>2</sup> is often readily interpretable by non-analytics audiences. For example, an <em>R</em><sup>2</sup> of .25 in a MMLR model can be interpreted as: the predictor variable and interaction term variable scores explain 25% of the variability in scores on the outcome variable. That is, to convert an <em>R</em><sup>2</sup> from a proportion to a percent, we just multiply by 100.</p>
<table>
<thead>
<tr class="header">
<th align="center"><em>R</em><sup>2</sup></th>
<th align="center">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">.01</td>
<td align="center">Small</td>
</tr>
<tr class="even">
<td align="center">.09</td>
<td align="center">Medium</td>
</tr>
<tr class="odd">
<td align="center">.25</td>
<td align="center">Large</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="review_differentialprediction" class="section level3 hasAnchor" number="42.1.2">
<h3><span class="header-section-number">42.1.2</span> Review of Differential Prediction<a href="differentialprediction.html#review_differentialprediction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Differential prediction</strong> refers to differences in intercepts, slopes, or both based on subgroup (projected class) membership <span class="citation">(<a href="#ref-siop2018">Society for Industrial &amp; Organizational Psychology 2018</a>; <a href="#ref-cleary1968test">Cleary 1968</a>)</span>, and sometimes differential prediction is referred to as <em>predictive bias</em>. Assuming a single regression line is used to predict the criterion (e.g., job performance) scores of applicants, differential prediction is concerned with overpredicting or underpredicting criterion scores for one subgroup relative to another <span class="citation">(<a href="#ref-cascio2005applied">Cascio and Aguinis 2005</a>)</span>. A common regression line would be inappropriate when evidence of intercept differences, slope differences, or both exist.</p>
<p>In the U.S., the use of separate regression lines – one for each subgroup – is legally murky, with some interpreting separate regression lines as violation of federal law and others cautioning that the practice might be interpreted as score adjustment, thereby running afoul of the Civil Rights Act of 1991 <span class="citation">(<a href="#ref-berry2015differential">Berry 2015</a>; <a href="#ref-saad2002investigating">Saad and Sackett 2002</a>)</span>. Specifically, Section 106 of the <a href="https://www.eeoc.gov/civil-rights-act-1991-original-text">Civil Rights Act of 1991</a> amends Section 703 of the Civil Rights Act of 1964 to prohibit the discriminatory use of selection test scores:</p>
<blockquote>
<p>“It shall be an unlawful employment practice for a respondent,
in connection with the selection or referral of applicants or
candidates for employment or promotion, to adjust the scores of,
use different cutoff scores for, or otherwise alter the results of,
employment related tests on the basis of race, color, religion,
sex, or national origin.”</p>
<footer>
— Section 106, U.S. Civil Rights Act of 1991
</footer>
</blockquote>
<p>Thus, a legally cautious approach would be to discontinue the use of a selection tool in its current form should evidence of differential prediction come to light.</p>
<p>We’ll begin by considering an example of <strong>intercept differences</strong> when predicting scores on the criterion (e.g., job performance) based on scores on a selection tool. Imagine a situation in which scores on a selection tool differentially predict scores on job performance for men and women, such that the slopes are the same, but the intercepts of each slope are different (see figure below). The dashed black line indicates what a common regression line would look like if it were used. As you can see, if we were to use a single common regression line when intercept differences exist between men and women, then we would tend to <em>underpredict</em> job performance scores for men and <em>overpredict</em> for women.</p>
<div class="float">
<img src="DiffPred_Figure2.png" alt="This simple slopes plot illustrates intercept differences by group but not slope differences. The dashed line indicates what a single regression line would like if it were used." />
<div class="figcaption">This simple slopes plot illustrates <strong>intercept differences</strong> by group but not slope differences. The dashed line indicates what a single regression line would like if it were used.</div>
</div>
<p>Next, we’ll consider an example involving <strong>slope differences</strong> in the context of differential prediction. In the figure below, the slopes (e.g., criterion-related validities) are different when the selection tool is used for men as compared to women. Again, the dashed black line represents what would happen if a common regression line were used, which would clearly be inappropriate. Note that, in this particular example, the job performance scores would generally be <em>underpredicted</em> for men and <em>overpredicted</em> for women when using the same regression. Further, the selection tool appears to show criterion-related validity (i.e., a significant slope) for men but not for women. Accordingly, based on this sample, the selection tool might only be a valid predictor of job performance for men. Clearly this would be a problem.</p>
<div class="float">
<img src="DiffPred_Figure4.png" alt="This simple slopes plot illustrates slope differences by group (i.e., different criterion-related validities) but not intercept differences. The dashed line indicates what a single regression line would like if it were used." />
<div class="figcaption">This simple slopes plot illustrates <strong>slope differences</strong> by group (i.e., different criterion-related validities) but not intercept differences. The dashed line indicates what a single regression line would like if it were used.</div>
</div>
<p>Finally, we’ll consider an example involving <strong>both intercept differences and slope differences</strong>. The figure below shows that use of a common regression line would pose problems in terms of predictive bias. In this example, for men, using of a common regression line would <em>overpredict</em> job performance scores for a certain range of selection tool scores and <em>underpredict</em> job performance scores for another range of selection tool scores; the opposite would be true for women.</p>
<div class="float">
<img src="DiffPred_Figure6.png" alt="This simple slopes plot illustrates both intercept differences and slope differences by group. The dashed line indicates what a single regression line would like if it were used." />
<div class="figcaption">This simple slopes plot illustrates <strong>both intercept differences and slope differences</strong> by group. The dashed line indicates what a single regression line would like if it were used.</div>
</div>
<p><strong>Words of Caution:</strong> In this tutorial, we will learn how to apply MMLR in the service of detecting differential predication using an approach that is generally supported by the U.S. court system and researchers. With that said, using MMLR to detect differential prediction should be used cautiously with small samples, as failure to detect differential prediction that actually exists (i.e., Type II Error, false negative) could be the result of low statistical power, and relatedly, unreliability or bias in the selection tool or criterion and violation of certain statistical assumptions (e.g., homoscedasticity of residual error variances) can affect our ability to find differential prediction that actually exists <span class="citation">(<a href="#ref-aguinis1998heterogeneity">Aguinis and Pierce 1998</a>)</span>. Further, when one subgroup is less than 30% of the total sample size, statistical power is also diminished <span class="citation">(<a href="#ref-stone1994type">Stone-Romero, Alliger, and Aguinis 1994</a>)</span>. The take-home message is to remain cautious and thoughtful when investigating differential prediction.</p>
<p><strong>Multistep MMLR Process for Differential Prediction:</strong> We will use a three-step “step-up” process for investigating differential prediction using MMLR <span class="citation">(<a href="#ref-siop2018">Society for Industrial &amp; Organizational Psychology 2018</a>; <a href="#ref-cleary1968test">Cleary 1968</a>)</span>. This process uses what is referred to as hierarchical regression, as additional predictor variables are added at each subsequent step, and their incremental validity above and beyond the other predictors in the model is assessed.</p>
<p>In the <strong>first step</strong>, we will regress the criterion variable on the selection tool variable, and in this step, we will verify whether the selection tool shows <em>criterion-related validity</em> by itself. If we find evidence of criterion-related validity for the selection tool in this first step, then we proceed to the second and third steps.</p>
<p>In the <strong>second step</strong>, we include the selection tool variable as before but add the dichotomous (binary) protected class/group variable to the model. If the protected class variable is statistically significant when controlling for the selection tool variable, then there is evidence of <em>intercept differences</em>. You might be asking yourself: What happens when a protected class variable is not inherently categorical or, specifically, dichotomous? When it comes to the protected class of race, many organizations have more than two races represented among their employees. In this situation, it is customary (at least within the U.S.) to compare two subgroups at time (e.g., White and Black) or to create a dichotomy consisting of the majority race and members of other non-majority races (e.g., White and Non-White). For a inherently continuous variable like age, classically, the standard procedure was to dichotomize the age variable by those who are 40 years and older and those who are younger than 40 years, as this is consistent with the U.S. Age Discrimination in Employment Act (ADEA) of 1967. There are two potential issues with this: (a) Some states have further age protections in place that protect workers under 40 as well, and (b) Some jobs in organizations have very young workforces, leaving the question of whether people in their 30s are being favored over people in their 20s, or vice versa (for example). In addition, when we look at organizations with workers who are well into their 50s, 60s, and 70s, then there might be evidence of age discrimination and differential prediction for those who are in their 50s compared to those who are in their 60s. Dichotomizing the age variable using a 40 and above vs. under 40 split might miss these issues and generally nuance. <span class="citation">(For a review of this topic, see <a href="#ref-fisher2017age">Fisher et al. 2017</a>.)</span> As such, with a variable like age, there might be some advantages to keeping it as a continuous variable, as MMLR can handle this.</p>
<p>In the <strong>third step</strong>, we include the selection tool and protected class variables as before but add the interaction term between the selection tool and protected class variables. If the interaction term is statistically significant, then there is evidence of differential prediction in the form of <em>slope differences</em>.</p>
<div id="samplewriteup_mmlr" class="section level4 hasAnchor" number="42.1.2.1">
<h4><span class="header-section-number">42.1.2.1</span> Sample Write-Up<a href="differentialprediction.html#samplewriteup_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Our HR analytics team recently found evidence in support of the criterion-related validity of a new structured interview selection procedure. As a next step, we investigated whether there might be evidence of differential prediction for the structured interview based on the U.S. protected class of gender. Based on a sample of 370 individuals, we applied a three-step “step up” process with moderated multiple linear regression, which is consistent with established principles <span class="citation">(<a href="#ref-siop2018">Society for Industrial &amp; Organizational Psychology 2018</a>; <a href="#ref-cleary1968test">Cleary 1968</a>)</span>. Based on our analyses, we found evidence of differential prediction (i.e., predictive bias) based on gender for the new structured interview procedure, and specifically, we found evidence of slope differences. In the first step, we found evidence of criterion-related validity based on a simple linear regression model, as structured interview scores were positively and significantly associated with job performance (<em>b</em> = .192, <em>p</em> &lt; .001), thereby indicating some degree of job-relatedness and -relevance. In the second step, we added the protected class variable associated with gender to the model, resulting in a multiple linear regression model, but we did not find evidence of intercept differences (<em>b</em> = .166, <em>p</em> = .146). In the third step, we added the interaction term between the structured interview and gender variables, resulting in a moderated multiple linear regression model, and we found that gender moderated the association between interview scores and job performance scores to a statistically significant extent (<em>b</em> = -.373, <em>p</em> &lt; .001). Based on follow-up simple slopes analyses, we found that the association between structured interview scores and job performance scores was statistically significant and positive for men (<em>b</em> = .39, <em>p</em> &lt; .01), such that for every one unit increase in structured interview scores, job performance scores tended to increase by .39 units; in contrast, the association between structured interview scores and job performance scores for women was nonsignificant (<em>b</em> = .02, <em>p</em> = .72). In sum, we found evidence of slope differences, which means that this interview tool shows evidence of predictive bias with respect to gender, making the application of a common regression line (i.e., equation) egally problematic within the United States. If possible, this structured interview should be redesigned or the interviewers should be trained to reduce the predictive bias based on gender.
In the interim, we caution against using separate regression lines for men and women, as this may be interpreted as running afoul of the U.S. Civil Rights Act of 1991 <span class="citation">(<a href="#ref-saad2002investigating">Saad and Sackett 2002</a>)</span>. A more conservative approach would be to develop a structured interview process that allows for the use of a common regression line across legally protected groups.</p>
</div>
</div>
</div>
<div id="tutorial_differentialprediction" class="section level2 hasAnchor" number="42.2">
<h2><span class="header-section-number">42.2</span> Tutorial<a href="differentialprediction.html#tutorial_differentialprediction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter’s tutorial demonstrates how to use moderated multiple linear regression in the service of detecting differential prediction in a selection tool.</p>
<div id="videotutorial_differentialprediction" class="section level3 hasAnchor" number="42.2.1">
<h3><span class="header-section-number">42.2.1</span> Video Tutorial<a href="differentialprediction.html#videotutorial_differentialprediction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As usual, you have the choice to follow along with the written tutorial in this chapter or to watch the video tutorial below.</p>
<iframe src="https://youtube.com/embed/3n2vvMc4yHs?rel=0" width="672" height="400px" data-external="1">
</iframe>
<p>Link to video tutorial: <a href="https://youtu.be/3n2vvMc4yHs" class="uri">https://youtu.be/3n2vvMc4yHs</a></p>
</div>
<div id="function_mmlr" class="section level3 hasAnchor" number="42.2.2">
<h3><span class="header-section-number">42.2.2</span> Functions &amp; Packages Introduced<a href="differentialprediction.html#function_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr class="header">
<th>Function</th>
<th>Package</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>mean</code></td>
<td>base R</td>
</tr>
<tr class="even">
<td><code>Regression</code></td>
<td><code>lessR</code></td>
</tr>
<tr class="odd">
<td><code>reg_brief</code></td>
<td><code>lessR</code></td>
</tr>
<tr class="even">
<td><code>probe_interaction</code></td>
<td><code>interactions</code></td>
</tr>
</tbody>
</table>
</div>
<div id="initsteps_mmlr" class="section level3 hasAnchor" number="42.2.3">
<h3><span class="header-section-number">42.2.3</span> Initial Steps<a href="differentialprediction.html#initsteps_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you haven’t already, save the file <strong>“DifferentialPrediction.csv”</strong> into a folder that you will subsequently set as your working directory. Your working directory will likely be different than the one shown below (i.e., <code>"H:/RWorkshop"</code>). As a reminder, you can access all of the data files referenced in this book by downloading them as a compressed (zipped) folder from the my GitHub site: <a href="https://github.com/davidcaughlin/R-Tutorial-Data-Files" class="uri">https://github.com/davidcaughlin/R-Tutorial-Data-Files</a>; once you’ve followed the link to GitHub, just click “Code” (or “Download”) followed by “Download ZIP”, which will download all of the data files referenced in this book. For the sake of parsimony, I recommend downloading all of the data files into the same folder on your computer, which will allow you to set that same folder as your working directory for each of the chapters in this book.</p>
<p>Next, using the <code>setwd</code> function, set your working directory to the folder in which you saved the data file for this chapter. Alternatively, you can manually set your working directory folder in your drop-down menus by going to <em>Session &gt; Set Working Directory &gt; Choose Directory…</em>. Be sure to create a new R script file (.R) or update an existing R script file so that you can save your script and annotations. If you need refreshers on how to set your working directory and how to create and save an R script, please refer to <a href="setwd.html#setwd">Setting a Working Directory</a> and <a href="gettingstarted.html#createRscript">Creating &amp; Saving an R Script</a>.</p>
<div class="sourceCode" id="cb1402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1402-1"><a href="differentialprediction.html#cb1402-1" tabindex="-1"></a><span class="co"># Set your working directory</span></span>
<span id="cb1402-2"><a href="differentialprediction.html#cb1402-2" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">&quot;H:/RWorkshop&quot;</span>)</span></code></pre></div>
<p>Next, read in the .csv data file <strong>“DifferentialPrediction.csv”</strong> using your choice of read function. In this example, I use the <code>read_csv</code> function from the <code>readr</code> package <span class="citation">(<a href="#ref-R-readr">Wickham, Hester, and Bryan 2024</a>)</span>. If you choose to use the <code>read_csv</code> function, be sure that you have installed and accessed the <code>readr</code> package using the <code>install.packages</code> and <code>library</code> functions. <em>Note: You don’t need to install a package every time you wish to access it; in general, I would recommend updating a package installation once ever 1-3 months.</em> For refreshers on installing packages and reading data into R, please refer to <a href="gentleintro.html#packages">Packages</a> and <a href="read.html#read">Reading Data into R</a>.</p>
<div class="sourceCode" id="cb1403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1403-1"><a href="differentialprediction.html#cb1403-1" tabindex="-1"></a><span class="co"># Install readr package if you haven&#39;t already</span></span>
<span id="cb1403-2"><a href="differentialprediction.html#cb1403-2" tabindex="-1"></a><span class="co"># [Note: You don&#39;t need to install a package every </span></span>
<span id="cb1403-3"><a href="differentialprediction.html#cb1403-3" tabindex="-1"></a><span class="co"># time you wish to access it]</span></span>
<span id="cb1403-4"><a href="differentialprediction.html#cb1403-4" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;readr&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1404-1"><a href="differentialprediction.html#cb1404-1" tabindex="-1"></a><span class="co"># Access readr package</span></span>
<span id="cb1404-2"><a href="differentialprediction.html#cb1404-2" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb1404-3"><a href="differentialprediction.html#cb1404-3" tabindex="-1"></a></span>
<span id="cb1404-4"><a href="differentialprediction.html#cb1404-4" tabindex="-1"></a><span class="co"># Read data and name data frame (tibble) object</span></span>
<span id="cb1404-5"><a href="differentialprediction.html#cb1404-5" tabindex="-1"></a>DiffPred <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;DifferentialPrediction.csv&quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 320 Columns: 6
## ── Column specification ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## chr (3): emp_id, gender, race
## dbl (3): perf_eval, interview, age
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb1406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1406-1"><a href="differentialprediction.html#cb1406-1" tabindex="-1"></a><span class="co"># Print the names of the variables in the data frame (tibble) objects</span></span>
<span id="cb1406-2"><a href="differentialprediction.html#cb1406-2" tabindex="-1"></a><span class="fu">names</span>(DiffPred)</span></code></pre></div>
<pre><code>## [1] &quot;emp_id&quot;    &quot;perf_eval&quot; &quot;interview&quot; &quot;gender&quot;    &quot;age&quot;       &quot;race&quot;</code></pre>
<div class="sourceCode" id="cb1408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1408-1"><a href="differentialprediction.html#cb1408-1" tabindex="-1"></a><span class="co"># View variable type for each variable in data frame</span></span>
<span id="cb1408-2"><a href="differentialprediction.html#cb1408-2" tabindex="-1"></a><span class="fu">str</span>(DiffPred)</span></code></pre></div>
<pre><code>## spc_tbl_ [320 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ emp_id   : chr [1:320] &quot;EE200&quot; &quot;EE202&quot; &quot;EE203&quot; &quot;EE206&quot; ...
##  $ perf_eval: num [1:320] 6.2 6.6 5 4 5.3 5.9 5.5 3.8 5.7 3.8 ...
##  $ interview: num [1:320] 8.5 5.7 7 6.8 9.6 6 7.5 5.9 9.6 8.3 ...
##  $ gender   : chr [1:320] &quot;woman&quot; &quot;woman&quot; &quot;man&quot; &quot;woman&quot; ...
##  $ age      : num [1:320] 30 45.6 39.2 36.9 24.5 41.5 35.1 43.2 25.7 27.8 ...
##  $ race     : chr [1:320] &quot;black&quot; &quot;black&quot; &quot;asian&quot; &quot;black&quot; ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   emp_id = col_character(),
##   ..   perf_eval = col_double(),
##   ..   interview = col_double(),
##   ..   gender = col_character(),
##   ..   age = col_double(),
##   ..   race = col_character()
##   .. )
##  - attr(*, &quot;problems&quot;)=&lt;externalptr&gt;</code></pre>
<div class="sourceCode" id="cb1410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1410-1"><a href="differentialprediction.html#cb1410-1" tabindex="-1"></a><span class="co"># View first 6 rows of data frame</span></span>
<span id="cb1410-2"><a href="differentialprediction.html#cb1410-2" tabindex="-1"></a><span class="fu">head</span>(DiffPred)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 6
##   emp_id perf_eval interview gender   age race 
##   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;
## 1 EE200        6.2       8.5 woman   30   black
## 2 EE202        6.6       5.7 woman   45.6 black
## 3 EE203        5         7   man     39.2 asian
## 4 EE206        4         6.8 woman   36.9 black
## 5 EE209        5.3       9.6 woman   24.5 white
## 6 EE214        5.9       6   woman   41.5 asian</code></pre>
<p>There are 6 variables and 370 cases (i.e., employees) in the <code>DiffPred</code> data frame: <code>emp_id</code>, <code>perf_eval</code>, <code>interview</code>, <code>age</code>, <code>gender</code>, and <code>race</code>. Per the output of the <code>str</code> (structure) function above, the variables <code>perf_eval</code>, <code>interview</code>, and <code>age</code> are of type <em>numeric</em> (continuous: interval/ratio), and the variables <code>emp_id</code>, <code>gender</code>, and <code>race</code> are of type <em>character</em> (nominal/categorical). The variable <code>emp_id</code> is the unique employee identifier. Imagine that these data were collected as part of a criterion-related validation study - specifically, a concurrent validation design in which job incumbents were administered a rated structured interview (<code>interview</code>) 90 days after entering the organization. The structured interview (<code>interview</code>) variable was designed to assess individuals’ interpersonal skills, and ratings can range from 1 (very weak interpersonal skills) to 10 (very strong interpersonal skills). The interviews were scored by untrained raters who were often the hiring managers but not always. The <code>perf_eval</code> variable is the criterion (outcome) of interest, and it is a 90-day-post-hire measure of supervisor-rated job performance, with possible ratings ranging from 1-7, with 7 indicating high performance. The <code>age</code> variable represents the job incumbents’ ages (in years). The <code>gender</code> variable represents the job incumbents’ tender identify and is defined by two levels/categories/values: <em>man</em> and <em>woman</em>. Finally, the <code>race</code> variable represents the job incumbents’ race/ethnicity and is defined by three levels/categories/values: <em>asian</em>, <em>black</em>, and <em>white</em>.</p>
</div>
<div id="center_mmlr" class="section level3 hasAnchor" number="42.2.4">
<h3><span class="header-section-number">42.2.4</span> Grand-Mean Center Continuous Predictor Variables<a href="differentialprediction.html#center_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To improve the interpretability of our model and to reduce the collinearity between the predictor and moderator variables with their interaction term, we will grand-mean center continuous predictor and moderator variables. <em>[Note: A moderator variable is just a predictor variable that we are framing as a moderator.]</em> With regard to interpretability, grand-mean centering aids in our interpretation of the regression coefficients associated with our predictor and moderator variables in our MMLR by reducing collinearity between these variables and their interaction term and by estimating the y-intercept when all predictors are at their respective means (averages), as opposed to when they are at zero (which is not always a plausible or meaningful value for some variables). Further, when interpreting the association between one predictor variable and the outcome variable while statistically controlling for other variables in the model, grand-mean centering allows us to interpret the effect of the focal predictor variable when the other predictor variables are at their respective means (as opposed to zero). For more detailed information on centering, check out the <a href="center.html#center">chapter on centering and standardizing variables</a>.</p>
<p>We only center predictor and moderator variables that are of type <em>numeric</em> and that we conceptualize as having a continuous (interval or ratio) measurement scale. In our current data frame, we will grand-mean center just the <code>interview</code> and <code>age</code> variables. We will use what is perhaps the most intuitive approach for grand-mean centering variables. We must begin by coming up with a new name for one of our soon-to-be grand-mean centered variable, and in this example, we will center the <code>interview</code> variable. I typically like to name the centered variable by simply adding the <code>c_</code> prefix to the existing variable’s names (e.g., <code>c_interview</code>). Type the name of the data frame object to which the new centered variable will be attached (<code>DiffPred</code>), followed by the <code>$</code> operator and the name of the new variable we are creating (<code>c_interview</code>). Next, add the <code>&lt;-</code> operator to indicate what values you will assign to this new variable. To create a vector of values to assign to this new <code>c_interview</code> variable, we will subtract the mean (average) score for the original variable (<code>interview</code>) from each case’s value on the variable. Specifically, enter the name of the data frame object, followed by the <code>$</code> operator and the name of the original variable (<code>interview</code>). After that, enter the subtraction operator (<code>-</code>). And finally, type the name of the <code>mean</code> function from base R. As the first argument in the <code>mean</code> function, enter the name of the data frame object (<code>DiffPred</code>), followed by the <code>$</code> operator and the name of the original variable (<code>interview</code>). As the second argument, enter <code>na.rm=TRUE</code> to indicate that you wish to drop missing values when calculating the grand mean for the sample. Now repeat those same steps for the <code>age</code> variable.</p>
<div class="sourceCode" id="cb1412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1412-1"><a href="differentialprediction.html#cb1412-1" tabindex="-1"></a><span class="co"># Grand-mean centering: Using basic arithmetic and the mean function from base R</span></span>
<span id="cb1412-2"><a href="differentialprediction.html#cb1412-2" tabindex="-1"></a>DiffPred<span class="sc">$</span>c_interview <span class="ot">&lt;-</span> DiffPred<span class="sc">$</span>interview <span class="sc">-</span> <span class="fu">mean</span>(DiffPred<span class="sc">$</span>interview, <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span>
<span id="cb1412-3"><a href="differentialprediction.html#cb1412-3" tabindex="-1"></a>DiffPred<span class="sc">$</span>c_age <span class="ot">&lt;-</span> DiffPred<span class="sc">$</span>age <span class="sc">-</span> <span class="fu">mean</span>(DiffPred<span class="sc">$</span>age, <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="estimate_mmlr" class="section level3 hasAnchor" number="42.2.5">
<h3><span class="header-section-number">42.2.5</span> Estimate Moderated Multiple Linear Regression Model<a href="differentialprediction.html#estimate_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As described <a href="differentialprediction.html#review_differentialprediction">above</a>, we will use the standard three-step differential prediction assessment using MMLR. We will repeat this three step process for all three protected class variables in our data frame: <code>gender</code>, <code>c_age</code>, and <code>race</code>. [Note that we are using the grand-mean centered age variable we created above.]. Our selection tool of interest is our <code>c_interview</code> (which is the grand-mean centered version of the variable we created above), and our criterion of interest is <code>perf_eval</code>. I will show you how to test differential prediction for each of these protected class variables using the <code>Regression</code> (or <code>reg_brief</code>) function from <code>lessR</code> <span class="citation">(<a href="#ref-R-lessR">Gerbing, Business, and University 2021</a>)</span>.</p>
<p><em>Note:</em> To reduce the overall length of this tutorial, I have omitted the diagnostic tests of the statistical assumptions, and thus for the purposes of this tutorial, we will assume that the statistical assumptions have been met. For your own work, be sure to run diagnostic tests to evaluate whether your model meets these statistical assumptions. For more information on statistical assumption testing in this context, check out the <a href="#incremental%20validity">chapter on estimating increment validity using multiple linear regression</a>.</p>
<p>If you haven’t already install and access the <code>lessR</code> package using the <code>install.packages</code> and <code>library</code> functions, respectively (see above). This will allow us to access the <code>Regression</code> and <code>reg_brief</code> functions.</p>
<div class="sourceCode" id="cb1413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1413-1"><a href="differentialprediction.html#cb1413-1" tabindex="-1"></a><span class="co"># Install lessR package if you haven&#39;t already</span></span>
<span id="cb1413-2"><a href="differentialprediction.html#cb1413-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;lessR&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1414-1"><a href="differentialprediction.html#cb1414-1" tabindex="-1"></a><span class="co"># Access lessR package</span></span>
<span id="cb1414-2"><a href="differentialprediction.html#cb1414-2" tabindex="-1"></a><span class="fu">library</span>(lessR)</span></code></pre></div>
<div id="gender_differentialprediction" class="section level4 hasAnchor" number="42.2.5.1">
<h4><span class="header-section-number">42.2.5.1</span> Test Differential Prediction Based on <code>gender</code><a href="differentialprediction.html#gender_differentialprediction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s start with investigating whether differential prediction exists for our <code>interview</code> selection tool in relation to <code>perf_eval</code> based <code>gender</code> subgroup membership (i.e., man, woman).</p>
<p><strong>Step One:</strong> Let’s being by regressing the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code>. Here we are just establishing whether the selection tool shows evidence of criterion-related validity. See the chapters on <a href="predictingcriterionscores.html#predictingcriterionscores">predicting criterion scores using simple linear regression</a> if you would like more information on regression-based approaches to assessing criterion-related validity, including determining whether statistical assumptions have been met. You can use either the <code>Regression</code> or <code>reg_brief</code> function from <code>lessR</code>, where the latter provides less output. To keep the amount of output in this tutorial to a minimum, I will use the <code>reg_brief</code> function, but when you evaluate whether statistical assumptions have been met, be sure to use the full <code>Regression</code> function.</p>
<div class="sourceCode" id="cb1415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1415-1"><a href="differentialprediction.html#cb1415-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool)</span></span>
<span id="cb1415-2"><a href="differentialprediction.html#cb1415-2" tabindex="-1"></a><span class="fu">reg_brief</span>(perf_eval <span class="sc">~</span> c_interview, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-874-1.png" width="672" /></p>
<pre><code>## &gt;&gt;&gt; Suggestion
## # Create an R markdown file for interpretative output with  Rmd = &quot;file_name&quot;
## reg(perf_eval ~ c_interview, data=DiffPred, Rmd=&quot;eg&quot;)  
## 
## 
##   BACKGROUND 
## 
## Data Frame:  DiffPred 
##  
## Response Variable: perf_eval 
## Predictor Variable: c_interview 
##  
## Number of cases (rows) of data:  320 
## Number of cases retained for analysis:  320 
## 
## 
##   BASIC ANALYSIS 
## 
##              Estimate    Std Err  t-value  p-value   Lower 95%   Upper 95% 
## (Intercept)     4.708      0.054   86.472    0.000       4.600       4.815 
## c_interview     0.192      0.041    4.629    0.000       0.110       0.273 
## 
## Standard deviation of perf_eval: 1.005 
##  
## Standard deviation of residuals:  0.974 for 318 degrees of freedom 
## 95% range of residual variation:  3.832 = 2 * (1.967 * 0.974) 
##  
## R-squared:  0.063    Adjusted R-squared:  0.060    PRESS R-squared:  0.051 
## 
## Null hypothesis of all 0 population slope coefficients:
##   F-statistic: 21.425     df: 1 and 318     p-value:  0.000 
## 
## -- Analysis of Variance 
##  
##               df    Sum Sq   Mean Sq   F-value   p-value 
## Model          1    20.319    20.319    21.425     0.000 
## Residuals    318   301.583     0.948 
## perf_eval    319   321.902     1.009 
## 
## 
##   K-FOLD CROSS-VALIDATION 
## 
## 
##   RELATIONS AMONG THE VARIABLES 
## 
## 
##   RESIDUALS AND INFLUENCE 
## 
## 
##   PREDICTION ERROR</code></pre>
<p>The unstandardized regression coefficient for <code>c_interview</code> is statistically significant and positive (<em>b</em> = .192, <em>p</em> &lt; .001), which provides evidence of criterion-related validity. The amount of variance explained by <code>c_interview</code> in <code>perf_eval</code> is small-medium in magnitude (<em>R</em><sup>2</sup> = .063, adjusted <em>R</em><sup>2</sup> = .060, <em>p</em> &lt; .001); that is, approximately 6% of the variability in <code>perf_eval</code> can be explained by <code>c_interview</code>. See the table below for common rules of thumbs for qualitatively describing <em>R</em><sup>2</sup> values.</p>
<table>
<thead>
<tr class="header">
<th align="center"><em>R</em><sup>2</sup></th>
<th align="center">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">.01</td>
<td align="center">Small</td>
</tr>
<tr class="even">
<td align="center">.09</td>
<td align="center">Medium</td>
</tr>
<tr class="odd">
<td align="center">.25</td>
<td align="center">Large</td>
</tr>
</tbody>
</table>
<p>Because Step One revealed a statistically significant association between <code>c_interview</code> and <code>perf_eval</code> – and thus evidence of criterion-related validity for the selection tool – we will proceed to Step Two and Step Three. Had we <em>not</em> found evidence of criterion-related validity in Step One, we would have stopped at that step; after all, it won’t be worthwhile to look for evidence of differential prediction if we won’t be using the selection tool moving forward (given that it’s not job related).</p>
<p><strong>Step Two:</strong> Next, let’s add the protected class variable <code>gender</code> to our model to investigate whether <em>intercept differences</em> exist. For more information on how to interpret and test the statistical assumptions of a multiple linear regression model, check out the <a href="#incremental%20validity">chapter on estimating incremental validity using multiple linear regression</a>. Note that this model can be called an <em>additive model</em>.</p>
<div class="sourceCode" id="cb1417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1417-1"><a href="differentialprediction.html#cb1417-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool) and protected class (gender)</span></span>
<span id="cb1417-2"><a href="differentialprediction.html#cb1417-2" tabindex="-1"></a><span class="fu">reg_brief</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">+</span> gender, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<pre><code>## 
## &gt;&gt;&gt;  gender is not numeric. Converted to indicator variables.</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-875-1.png" width="672" /></p>
<pre><code>## &gt;&gt;&gt; Suggestion
## # Create an R markdown file for interpretative output with  Rmd = &quot;file_name&quot;
## reg(perf_eval ~ c_interview + gender, data=DiffPred, Rmd=&quot;eg&quot;)  
## 
## 
##   BACKGROUND 
## 
## Data Frame:  DiffPred 
##  
## Response Variable: perf_eval 
## Predictor Variable 1: c_interview 
## Predictor Variable 2: genderwoman 
##  
## Number of cases (rows) of data:  320 
## Number of cases retained for analysis:  320 
## 
## 
##   BASIC ANALYSIS 
## 
##              Estimate    Std Err  t-value  p-value   Lower 95%   Upper 95% 
## (Intercept)     4.630      0.076   60.719    0.000       4.480       4.780 
## c_interview     0.211      0.043    4.861    0.000       0.125       0.296 
## genderwoman     0.166      0.114    1.458    0.146      -0.058       0.391 
## 
## Standard deviation of perf_eval: 1.005 
##  
## Standard deviation of residuals:  0.972 for 317 degrees of freedom 
## 95% range of residual variation:  3.825 = 2 * (1.967 * 0.972) 
##  
## R-squared:  0.069    Adjusted R-squared:  0.063    PRESS R-squared:  NA 
## 
## Null hypothesis of all 0 population slope coefficients:
##   F-statistic: 11.813     df: 2 and 317     p-value:  0.000 
## 
## -- Analysis of Variance from Type II Sums of Squares 
##  
##               df    Sum Sq   Mean Sq   F-value   p-value 
## c_interview    1    22.328    22.328    23.626     0.000 
## genderwoman    1     2.009     2.009     2.125     0.146 
## Residuals    317   299.574     0.945 
## 
## -- Test of Interaction 
##   
## c_interview:gender  df: 1  df resid: 316  SS: 17.514  F: 19.622  p-value: 0 
##   
## -- Assume parallel lines, no interaction of gender with c_interview 
##  
## Level man: y^_perf_eval = 4.630 + 0.211(x_c_interview) 
## Level woman: y^_perf_eval = 4.796 + 0.211(x_c_interview) 
##   
## -- Visualize Separately Computed Regression Lines 
## 
## Plot(c_interview, perf_eval, by=gender, fit=&quot;lm&quot;) 
## 
## 
##   K-FOLD CROSS-VALIDATION 
## 
## 
##   RELATIONS AMONG THE VARIABLES 
## 
## 
##   RESIDUALS AND INFLUENCE 
## 
## 
##   PREDICTION ERROR</code></pre>
<p>The unstandardized regression coefficient associated with <code>gender</code> (or more specifically <code>genderwoman</code>) is not statistically significant (<em>b</em> = .166, <em>p</em> = .146) when controlling for <code>c_interview</code>, which indicates that there is <em>no</em> evidence of intercept differences. Note that the name of the regression coefficient for <code>gender</code> has <code>woman</code> appended to it; this means that the intercept represents the <code>perf_eval</code> scores of women minus those for men. Behind the scenes, the <code>reg_brief</code> function has converted the <code>gender</code> variable to a dichotomous factor, where alphabetically <code>man</code> becomes 0 and <code>woman</code> becomes 1. Because the coefficient is negative, it implies that the intercept value is higher for women relative to men; however, please note that we wouldn’t interpret the direction of this effect because it was not statistically significant. The amount of variance explained by <code>c_interview</code> <em>and</em> <code>gender</code> in <code>perf_eval</code> is small-medium in magnitude (<em>R</em><sup>2</sup> = .069, adjusted <em>R</em><sup>2</sup> = .063, <em>p</em> &lt; .001), which is slightly larger than when just <code>c_interview</code> was included in the model (see Step One above).</p>
<p>Because there is no evidence of intercept differences for Step Two, we won’t plot/graph the our model, as doing so might mislead someone who sees such a plot without knowing or understanding the results of the model we just estimated. We will now proceed to Step Three.</p>
<p><strong>Step Three:</strong> As the final step, it’s time to add the interaction term (also known as a product term) between <code>c_interview</code> and <code>gender</code> to the model, which creates what is referred to as a <em>multiplicative model</em>. Fortunately, this is very easy to do in R. All we need to do is change the <code>+</code> operator from our previous regression model script to the <code>*</code>, where the <code>*</code> implies an interaction in the context of a model. Conceptually, the <code>*</code> is appropriate because we are estimating a multiplicative model containing an interaction term.</p>
<div class="sourceCode" id="cb1420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1420-1"><a href="differentialprediction.html#cb1420-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool), protected class (gender), </span></span>
<span id="cb1420-2"><a href="differentialprediction.html#cb1420-2" tabindex="-1"></a><span class="co"># and interaction between selection tool and protected class</span></span>
<span id="cb1420-3"><a href="differentialprediction.html#cb1420-3" tabindex="-1"></a><span class="fu">reg_brief</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">*</span> gender, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<pre><code>## 
## &gt;&gt;&gt;  gender is not numeric. Converted to indicator variables.</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-876-1.png" width="672" /></p>
<pre><code>## &gt;&gt;&gt; Suggestion
## # Create an R markdown file for interpretative output with  Rmd = &quot;file_name&quot;
## reg(perf_eval ~ c_interview * gender, data=DiffPred, Rmd=&quot;eg&quot;)  
## 
## 
##   BACKGROUND 
## 
## Data Frame:  DiffPred 
##  
## Response Variable: perf_eval 
## Predictor Variable 1: c_interview 
## Predictor Variable 2: genderwoman 
## Predictor Variable 3: c_interview.genderwoman 
##  
## Number of cases (rows) of data:  320 
## Number of cases retained for analysis:  320 
## 
## 
##   BASIC ANALYSIS 
## 
##                          Estimate    Std Err  t-value  p-value   Lower 95%   Upper 95% 
##             (Intercept)     4.562      0.076   60.298    0.000       4.413       4.711 
##             c_interview     0.394      0.059    6.672    0.000       0.278       0.511 
##             genderwoman     0.155      0.111    1.397    0.163      -0.063       0.373 
## c_interview.genderwoman    -0.373      0.084   -4.430    0.000      -0.539      -0.207 
## 
## Standard deviation of perf_eval: 1.005 
##  
## Standard deviation of residuals:  0.945 for 316 degrees of freedom 
## 95% range of residual variation:  3.718 = 2 * (1.967 * 0.945) 
##  
## R-squared:  0.124    Adjusted R-squared:  0.115    PRESS R-squared:  NA 
## 
## Null hypothesis of all 0 population slope coefficients:
##   F-statistic: 14.879     df: 3 and 316     p-value:  0.000 
## 
## -- Analysis of Variance from Type II Sums of Squares 
##  
##                           df    Sum Sq   Mean Sq   F-value   p-value 
##             c_interview    1    22.328    22.328    23.626     0.000 
##             genderwoman    1     2.009     2.009     2.250     0.135 
## c_interview.genderwoman    1    17.514    17.514    19.622     0.000 
## Residuals                316   282.060     0.893 
## 
## -- Test of Interaction 
##   
## c_interview:gender  df: 1  df resid: 316  SS: 17.514  F: 19.622  p-value: 0 
##   
## -- Assume parallel lines, no interaction of gender with c_interview 
##  
## Level man: y^_perf_eval = 4.562 + 0.394(x_c_interview) 
## Level woman: y^_perf_eval = 4.717 + 0.394(x_c_interview) 
##   
## -- Visualize Separately Computed Regression Lines 
## 
## Plot(c_interview, perf_eval, by=gender, fit=&quot;lm&quot;) 
## 
## 
##   K-FOLD CROSS-VALIDATION 
## 
## 
##   RELATIONS AMONG THE VARIABLES 
## 
## 
##   RESIDUALS AND INFLUENCE 
## 
## 
##   PREDICTION ERROR</code></pre>
<p>In our output, we now have an unstandardized regression coefficient called <code>c_interview:gender</code> (or <code>c_interview.gender</code>), which represents our interaction term for <code>c_interview</code> and <code>gender</code>. The regression coefficient associated with the interaction term (<code>c_interview:gender</code>) is negative and statistically significant (<em>b</em> = -.373, <em>p</em> &lt; .001), but we shouldn’t pay too much attention to the sign of the interaction term as it is difficult to interpret it without graphing the regression model in its entirety. We should, however, pay attention to the fact that the interaction term is statistically significant, which indicates that there is evidence of <em>slope differences</em>; in other words, there seems to be multiplicative effect between <code>c_interview</code> and <code>gender</code>. Although we didn’t find evidence of intercept differences in Step Two, here in Step Three, we do find evidence that the criterion-related validities for the selection tool (<code>c_interview</code>) in relation to the criterion (<code>perf_eval</code>) are significantly different from one another; in other words, we found evidence that the slopes for men and women differ. The amount of variance explained by <code>c_interview</code>, <code>gender</code>, <em>and</em> their interaction in relation to <code>perf_eval</code> is medium in magnitude (<em>R</em><sup>2</sup> = .124, adjusted <em>R</em><sup>2</sup> = .115, <em>p</em> &lt; .001), which is larger than when just <code>c_interview</code> and <code>gender</code> were included in the model (see Step Two above).</p>
<p>Given the statistically significant interaction term, it is appropriate (and helpful) to probe the interaction by plotting it. This will help us understand the form of the interaction. We can do so by creating a plot of the simple slopes. To do so, we will use a package called <code>interactions</code> <span class="citation">(<a href="#ref-interactions">Long 2019</a>)</span>, so if you haven’t already, install and access the package.</p>
<div class="sourceCode" id="cb1423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1423-1"><a href="differentialprediction.html#cb1423-1" tabindex="-1"></a><span class="co"># Install interactions package if you haven&#39;t already</span></span>
<span id="cb1423-2"><a href="differentialprediction.html#cb1423-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;interactions&quot;</span>)</span>
<span id="cb1423-3"><a href="differentialprediction.html#cb1423-3" tabindex="-1"></a></span>
<span id="cb1423-4"><a href="differentialprediction.html#cb1423-4" tabindex="-1"></a><span class="co"># Note: You may need to install the sandwich package independently if you </span></span>
<span id="cb1423-5"><a href="differentialprediction.html#cb1423-5" tabindex="-1"></a><span class="co"># receive an error when attempting to run the probe_interaction function</span></span>
<span id="cb1423-6"><a href="differentialprediction.html#cb1423-6" tabindex="-1"></a><span class="co"># install.packages(&quot;sandwich&quot;)</span></span></code></pre></div>
<div class="sourceCode" id="cb1424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1424-1"><a href="differentialprediction.html#cb1424-1" tabindex="-1"></a><span class="co"># Access interactions package</span></span>
<span id="cb1424-2"><a href="differentialprediction.html#cb1424-2" tabindex="-1"></a><span class="fu">library</span>(interactions)</span></code></pre></div>
<p>As input to the <code>probe_interaction</code> function from the <code>interactions</code> package, we will need to use the <code>lm</code> function base R to specify the same regression model we estimated above. We can just copy and paste the same arguments from the <code>reg_brief</code> function into the <code>lm</code> function parentheses. We need to name this model something so that we can reference it in the next function, so let’s name it <code>Slope_Model</code> (for slope differences model) using the <code>&lt;-</code> operator.</p>
<div class="sourceCode" id="cb1425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1425-1"><a href="differentialprediction.html#cb1425-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool), protected class (gender), </span></span>
<span id="cb1425-2"><a href="differentialprediction.html#cb1425-2" tabindex="-1"></a><span class="co"># and interaction between selection tool and protected class</span></span>
<span id="cb1425-3"><a href="differentialprediction.html#cb1425-3" tabindex="-1"></a>Slope_Model <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">*</span> gender, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<p>Now we’re ready to apply the <code>probe_interaction</code> in order to plot this multiplicative model. As the first argument, enter the name of the regression model we just created above (<code>Slope_Model</code>). As the second argument, type the name of the variable you are framing as the predictor after <code>pred=</code>, which in our case is the selection tool variable (<code>c_interview</code>). As the third argument, type the name of the variable you are framing as the moderator after <code>modx=</code>, which in our case is the protected class variable (<code>gender</code>). As the fourth argument, enter <code>johnson_neyman=FALSE</code>, as we aren’t requesting the Johnson-Neyman test in this tutorial. Finally, if you choose to, you can use <code>x.label=</code> and <code>y.label=</code> to create more informative names for the predictor and outcome variables, respectively. You could also add, if you should choose to do so, the <code>legend.main=</code> argument to provide a more informative name for the moderator variable, and/or the <code>modx.labels=</code> to provide more informative names for the moderator variable labels.</p>
<div class="sourceCode" id="cb1426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1426-1"><a href="differentialprediction.html#cb1426-1" tabindex="-1"></a><span class="co"># Probe the significant interaction (slope differences)</span></span>
<span id="cb1426-2"><a href="differentialprediction.html#cb1426-2" tabindex="-1"></a><span class="fu">probe_interaction</span>(Slope_Model, </span>
<span id="cb1426-3"><a href="differentialprediction.html#cb1426-3" tabindex="-1"></a>                  <span class="at">pred=</span>c_interview, </span>
<span id="cb1426-4"><a href="differentialprediction.html#cb1426-4" tabindex="-1"></a>                  <span class="at">modx=</span>gender,</span>
<span id="cb1426-5"><a href="differentialprediction.html#cb1426-5" tabindex="-1"></a>                  <span class="at">johnson_neyman=</span><span class="cn">FALSE</span>,</span>
<span id="cb1426-6"><a href="differentialprediction.html#cb1426-6" tabindex="-1"></a>                  <span class="at">x.label=</span><span class="st">&quot;Interview Score&quot;</span>,</span>
<span id="cb1426-7"><a href="differentialprediction.html#cb1426-7" tabindex="-1"></a>                  <span class="at">y.label=</span><span class="st">&quot;Job Performance&quot;</span>)</span></code></pre></div>
<pre><code>## SIMPLE SLOPES ANALYSIS 
## 
## Slope of c_interview when gender = man: 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.39   0.06     6.67   0.00
## 
## Slope of c_interview when gender = woman: 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.02   0.06     0.35   0.72</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-880-1.png" width="672" /></p>
<p>The plot output shows that the two slopes are indeed different, such that there doesn’t seem to be much of an association between the selection tool (<code>c_interview</code>) and the criterion (<code>perf_eval</code>) for women, but there seems to be a positive association for men. Now take a look at the text output in your console. The simple slopes analysis automatically estimates the regression coefficient (slope) for both levels of the moderator variable (<code>gender</code>: man, woman). Corroborating what we see in the plot, we find that the simple slope for men is indeed statistically significant and positive (<em>b</em> = .39, <em>p</em> &lt; .01), such that for every one unit increase in interview scores, job performance scores tend to go up by .39 units. In contrast, we find that the simple slope for women is nonsignificant (<em>b</em> = .02, <em>p</em> = .72).</p>
<p>In sum, we found evidence of slope differences – but not intercept differences – for the selection tool (<code>c_interview</code>) in relation to the criterion (<code>perf_eval</code>) that were conditional upon the levels/subgroups of the protected class variable (<code>gender</code>). Thus, we can conclude that there is evidence of differential prediction based on gender for this interview selection tool, which means that it would be inappropriate to use a common regression line when predicting scores on the criterion based on the interview selection tool.</p>
<p><strong>Sample Write-Up:</strong> Our HR analytics team recently found evidence in support of the criterion-related validity of a new structured interview selection procedure. As a next step, we investigated whether there might be evidence of differential prediction of the structured interview based on the U.S. protected class of gender. Based on a sample of 370 individuals, we applied a three-step process with moderated multiple linear regression, which is consistent with established principles <span class="citation">(<a href="#ref-siop2018">Society for Industrial &amp; Organizational Psychology 2018</a>; <a href="#ref-cleary1968test">Cleary 1968</a>)</span>. Based on our analyses, we found evidence differential prediction (i.e., predictive bias) based on gender for the new structured interview procedure, and specifically, we found evidence of slope differences. In the first step, we found evidence of criterion-related validity based on a simple linear regression model, as structured interview scores were positively and significantly associated with job performance (<em>b</em> = .192, <em>p</em> &lt; .001), thereby indicating some degree of job-relatedness and -relevance. In the second step, we added the protected class variable associated with gender to the model, resulting in a multiple linear regression model, but did not find evidence of intercept differences based on gender (<em>b</em> = .166, <em>p</em> = .146). In the third step, we added the interaction term between the structured interview and gender variables, resulting in a moderated multiple linear regression model, and we found that gender moderated the association between structured interview scores and job performance scores to a statistically significant extent (<em>b</em> = -.373, <em>p</em> &lt; .001). Based on follow-up simple slopes analyses, we found that the association between structured interview scores and job performance scores was statistically significant for men (<em>b</em> = .39, <em>p</em> &lt; .01), such that for every one unit increase in structured interview scores, job performance scores tended to increase by .39 units; in contrast, the associated between structured interview scores and job performance scores for women was nonsignificant (<em>b</em> = .02, <em>p</em> = .72). In sum, we found evidence slope differences, which means that this structured interview tool shows predictive bias with respect to gender, making the application of a common regression line (i.e., equation) legally problematic within the United States. If possible, this structured interview should be redesigned or the interviewers should be trained to reduce the predictive bias based on gender. In the interim, we caution against using separate regression lines for men and women, as this may be interpreted as running afoul of the U.S. Civil Rights Act of 1991 <span class="citation">(<a href="#ref-saad2002investigating">Saad and Sackett 2002</a>)</span>. A more conservative approach would be to develop a structured interview process that allows for the use of a common regression line across legally protected groups.</p>
</div>
<div id="age_differentialprediction" class="section level4 hasAnchor" number="42.2.5.2">
<h4><span class="header-section-number">42.2.5.2</span> Test Differential Prediction Based on <code>c_age</code><a href="differentialprediction.html#age_differentialprediction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Investigating whether differential prediction exists for <code>c_interview</code> in relation to <code>perf_eval</code> based on the continuous moderator variable <code>c_age</code> will unfold very similarly to the process we used for the dichotomous <code>gender</code> variable from above. The only differences will occur when it comes to estimating and visualizing the intercept differences and simple slopes (assuming we find statistically significant effects). Given this, we will breeze through the steps, which means I will provide less explanation.</p>
<p><strong>Step One:</strong> Regress the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code>.</p>
<div class="sourceCode" id="cb1428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1428-1"><a href="differentialprediction.html#cb1428-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool)</span></span>
<span id="cb1428-2"><a href="differentialprediction.html#cb1428-2" tabindex="-1"></a><span class="fu">reg_brief</span>(perf_eval <span class="sc">~</span> c_interview, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-881-1.png" width="672" /></p>
<pre><code>## &gt;&gt;&gt; Suggestion
## # Create an R markdown file for interpretative output with  Rmd = &quot;file_name&quot;
## reg(perf_eval ~ c_interview, data=DiffPred, Rmd=&quot;eg&quot;)  
## 
## 
##   BACKGROUND 
## 
## Data Frame:  DiffPred 
##  
## Response Variable: perf_eval 
## Predictor Variable: c_interview 
##  
## Number of cases (rows) of data:  320 
## Number of cases retained for analysis:  320 
## 
## 
##   BASIC ANALYSIS 
## 
##              Estimate    Std Err  t-value  p-value   Lower 95%   Upper 95% 
## (Intercept)     4.708      0.054   86.472    0.000       4.600       4.815 
## c_interview     0.192      0.041    4.629    0.000       0.110       0.273 
## 
## Standard deviation of perf_eval: 1.005 
##  
## Standard deviation of residuals:  0.974 for 318 degrees of freedom 
## 95% range of residual variation:  3.832 = 2 * (1.967 * 0.974) 
##  
## R-squared:  0.063    Adjusted R-squared:  0.060    PRESS R-squared:  0.051 
## 
## Null hypothesis of all 0 population slope coefficients:
##   F-statistic: 21.425     df: 1 and 318     p-value:  0.000 
## 
## -- Analysis of Variance 
##  
##               df    Sum Sq   Mean Sq   F-value   p-value 
## Model          1    20.319    20.319    21.425     0.000 
## Residuals    318   301.583     0.948 
## perf_eval    319   321.902     1.009 
## 
## 
##   K-FOLD CROSS-VALIDATION 
## 
## 
##   RELATIONS AMONG THE VARIABLES 
## 
## 
##   RESIDUALS AND INFLUENCE 
## 
## 
##   PREDICTION ERROR</code></pre>
<p>The regression coefficient for <code>c_interview</code> is statistically significant and positive (<em>b</em> = .192, <em>p</em> &lt; .001), which provides evidence of criterion-related validity. The amount of variance explained by <code>c_interview</code> in <code>perf_eval</code> is small-medium in magnitude (<em>R</em><sup>2</sup> = .063, adjusted <em>R</em><sup>2</sup> = .060, <em>p</em> &lt; .001).</p>
<p><strong>Step Two:</strong> Regress the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code> and the protected class variable <code>c_age</code>.</p>
<div class="sourceCode" id="cb1430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1430-1"><a href="differentialprediction.html#cb1430-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool) and protected class (c_age)</span></span>
<span id="cb1430-2"><a href="differentialprediction.html#cb1430-2" tabindex="-1"></a><span class="fu">reg_brief</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">+</span> c_age, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-882-1.png" width="672" /></p>
<pre><code>## &gt;&gt;&gt; Suggestion
## # Create an R markdown file for interpretative output with  Rmd = &quot;file_name&quot;
## reg(perf_eval ~ c_interview + c_age, data=DiffPred, Rmd=&quot;eg&quot;)  
## 
## 
##   BACKGROUND 
## 
## Data Frame:  DiffPred 
##  
## Response Variable: perf_eval 
## Predictor Variable 1: c_interview 
## Predictor Variable 2: c_age 
##  
## Number of cases (rows) of data:  320 
## Number of cases retained for analysis:  320 
## 
## 
##   BASIC ANALYSIS 
## 
##              Estimate    Std Err  t-value  p-value   Lower 95%   Upper 95% 
## (Intercept)     4.708      0.050   94.164    0.000       4.609       4.806 
## c_interview     0.978      0.108    9.028    0.000       0.765       1.191 
##       c_age     0.129      0.017    7.752    0.000       0.096       0.161 
## 
## Standard deviation of perf_eval: 1.005 
##  
## Standard deviation of residuals:  0.894 for 317 degrees of freedom 
## 95% range of residual variation:  3.519 = 2 * (1.967 * 0.894) 
##  
## R-squared:  0.212    Adjusted R-squared:  0.207    PRESS R-squared:  0.192 
## 
## Null hypothesis of all 0 population slope coefficients:
##   F-statistic: 42.749     df: 2 and 317     p-value:  0.000 
## 
## -- Analysis of Variance 
##  
##               df    Sum Sq   Mean Sq   F-value   p-value 
## c_interview    1    20.319    20.319    25.406     0.000 
##       c_age    1    48.059    48.059    60.092     0.000 
##  
## Model          2    68.378    34.189    42.749     0.000 
## Residuals    317   253.524     0.800 
## perf_eval    319   321.902     1.009 
## 
## 
##   K-FOLD CROSS-VALIDATION 
## 
## 
##   RELATIONS AMONG THE VARIABLES 
## 
## 
##   RESIDUALS AND INFLUENCE 
## 
## 
##   PREDICTION ERROR</code></pre>
<p>The regression coefficient associated with <code>c_age</code> is positive and statistically significant (<em>b</em> = .129, <em>p</em> &lt; .001) when controlling for <code>c_interview</code>, which indicates that there is evidence of intercept differences. Because the coefficient is positive, it implies that the intercept value is significantly higher for older workers relative to younger workers. The amount of variance explained by <code>c_interview</code> <em>and</em> <code>c_age</code> in <code>perf_eval</code> is medium-large in magnitude (<em>R</em><sup>2</sup> = .212, adjusted <em>R</em><sup>2</sup> = .207, <em>p</em> &lt; .001), which is notably larger than when just <code>c_interview</code> was included in the model (see Step One above).</p>
<p>Using the <code>probe_interaction</code> function from the <code>interactions</code> package, we will visualize the intercept differences. As input to the <code>probe_interaction</code> function, we will use the <code>lm</code> function base R to specify our regression model from above. Name this model something so that we can reference it in the next function (<code>Int_Model</code>).</p>
<div class="sourceCode" id="cb1432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1432-1"><a href="differentialprediction.html#cb1432-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool) and protected class (c_age)</span></span>
<span id="cb1432-2"><a href="differentialprediction.html#cb1432-2" tabindex="-1"></a>Int_Model <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">+</span> c_age, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<p>Now, we will specify the arguments in the <code>probe_interaction</code> function. Note that the function automatically categorizes the continuous moderator variable by its mean and 1 standard deviation (SD) below and above the mean. As you can see in the plot, individuals whose age is 1 SD above the mean have the highest intercept value, where the intercept is the value of <code>perf_eval</code> (Job Performance) when <code>interview</code> (Interview) is equal to zero.</p>
<div class="sourceCode" id="cb1433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1433-1"><a href="differentialprediction.html#cb1433-1" tabindex="-1"></a><span class="co"># Visualize intercept differences</span></span>
<span id="cb1433-2"><a href="differentialprediction.html#cb1433-2" tabindex="-1"></a><span class="fu">probe_interaction</span>(Int_Model, </span>
<span id="cb1433-3"><a href="differentialprediction.html#cb1433-3" tabindex="-1"></a>                  <span class="at">pred=</span>c_interview, </span>
<span id="cb1433-4"><a href="differentialprediction.html#cb1433-4" tabindex="-1"></a>                  <span class="at">modx=</span>c_age,</span>
<span id="cb1433-5"><a href="differentialprediction.html#cb1433-5" tabindex="-1"></a>                  <span class="at">johnson_neyman=</span><span class="cn">FALSE</span>,</span>
<span id="cb1433-6"><a href="differentialprediction.html#cb1433-6" tabindex="-1"></a>                  <span class="at">x.label=</span><span class="st">&quot;Interview Score&quot;</span>,</span>
<span id="cb1433-7"><a href="differentialprediction.html#cb1433-7" tabindex="-1"></a>                  <span class="at">y.label=</span><span class="st">&quot;Job Performance&quot;</span>)</span></code></pre></div>
<pre><code>## SIMPLE SLOPES ANALYSIS 
## 
## Slope of c_interview when c_age = -8.593122204199181268791 (- 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.98   0.11     9.03   0.00
## 
## Slope of c_interview when c_age = -0.000000000000003164136 (Mean): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.98   0.11     9.03   0.00
## 
## Slope of c_interview when c_age =  8.593122204199174163364 (+ 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.98   0.11     9.03   0.00</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-884-1.png" width="672" /></p>
<p><strong>Step Three:</strong> Now, we will add the interaction term between <code>c_interview</code> and <code>c_age</code> to the model using the <code>*</code> operator.</p>
<div class="sourceCode" id="cb1435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1435-1"><a href="differentialprediction.html#cb1435-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool), protected class (c_age), </span></span>
<span id="cb1435-2"><a href="differentialprediction.html#cb1435-2" tabindex="-1"></a><span class="co"># and interaction between selection tool and protected class</span></span>
<span id="cb1435-3"><a href="differentialprediction.html#cb1435-3" tabindex="-1"></a><span class="fu">reg_brief</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">*</span> c_age, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-885-1.png" width="672" /></p>
<pre><code>## &gt;&gt;&gt; Suggestion
## # Create an R markdown file for interpretative output with  Rmd = &quot;file_name&quot;
## reg(perf_eval ~ c_interview * c_age, data=DiffPred, Rmd=&quot;eg&quot;)  
## 
## 
##   BACKGROUND 
## 
## Data Frame:  DiffPred 
##  
## Response Variable: perf_eval 
## Predictor Variable 1: c_interview 
## Predictor Variable 2: c_age 
##  
## Number of cases (rows) of data:  320 
## Number of cases retained for analysis:  320 
## 
## 
##   BASIC ANALYSIS 
## 
##                    Estimate    Std Err  t-value  p-value   Lower 95%   Upper 95% 
##       (Intercept)     4.995      0.068   73.937    0.000       4.862       5.128 
##       c_interview     1.711      0.160   10.700    0.000       1.397       2.026 
##             c_age     0.263      0.027    9.590    0.000       0.209       0.317 
## c_interview:c_age     0.027      0.005    5.986    0.000       0.018       0.036 
## 
## Standard deviation of perf_eval: 1.005 
##  
## Standard deviation of residuals:  0.849 for 316 degrees of freedom 
## 95% range of residual variation:  3.340 = 2 * (1.967 * 0.849) 
##  
## R-squared:  0.293    Adjusted R-squared:  0.286    PRESS R-squared:  0.275 
## 
## Null hypothesis of all 0 population slope coefficients:
##   F-statistic: 43.573     df: 3 and 316     p-value:  0.000 
## 
## -- Analysis of Variance 
##  
##                     df    Sum Sq   Mean Sq   F-value   p-value 
##       c_interview    1    20.319    20.319    28.198     0.000 
##             c_age    1    48.059    48.059    66.694     0.000 
## c_interview:c_age    1    25.817    25.817    35.827     0.000 
##  
## Model                3    94.195    31.398    43.573     0.000 
## Residuals          316   227.707     0.721 
## perf_eval          319   321.902     1.009 
## 
## 
##   K-FOLD CROSS-VALIDATION 
## 
## 
##   RELATIONS AMONG THE VARIABLES 
## 
## 
##   RESIDUALS AND INFLUENCE 
## 
## 
##   PREDICTION ERROR</code></pre>
<p>The regression coefficient associated with the interaction term (<code>c_interview:c_age</code>) is positive and statistically significant (<em>b</em> = .027, <em>p</em> &lt; .001), which indicates that there is evidence of <em>slope differences</em>. The amount of variance explained by <code>c_interview</code>, <code>c_age</code>, <em>and</em> their interaction in relation to <code>perf_eval</code> is large in magnitude (<em>R</em><sup>2</sup> = .293, adjusted <em>R</em><sup>2</sup> = .286, <em>p</em> &lt; .001), which is larger than when just <code>c_interview</code> and <code>c_age</code> were included in the model.</p>
<p>Given the statistically significant interaction term, we will use the <code>probe_interaction</code> function from the <code>interactions</code> package to probe the interaction. As input to the <code>probe_interaction</code> function from the <code>interactions</code> package, we will need to use the <code>lm</code> function base R to specify our regression model from above. We need to name this model something so that we can reference it in the next function, so let’s name it <code>Slope_Model</code> (for slope differences model) using the <code>&lt;-</code> operator.</p>
<div class="sourceCode" id="cb1437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1437-1"><a href="differentialprediction.html#cb1437-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool), protected class (c_age), </span></span>
<span id="cb1437-2"><a href="differentialprediction.html#cb1437-2" tabindex="-1"></a><span class="co"># and interaction between selection tool and protected class</span></span>
<span id="cb1437-3"><a href="differentialprediction.html#cb1437-3" tabindex="-1"></a>Slope_Model <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">*</span> c_age, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<p>We’re ready to use the <code>probe_interaction</code> to plot this multiplicative model.</p>
<div class="sourceCode" id="cb1438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1438-1"><a href="differentialprediction.html#cb1438-1" tabindex="-1"></a><span class="co"># Probe the significant interaction (slope differences)</span></span>
<span id="cb1438-2"><a href="differentialprediction.html#cb1438-2" tabindex="-1"></a><span class="fu">probe_interaction</span>(Slope_Model, </span>
<span id="cb1438-3"><a href="differentialprediction.html#cb1438-3" tabindex="-1"></a>                  <span class="at">pred=</span>c_interview, </span>
<span id="cb1438-4"><a href="differentialprediction.html#cb1438-4" tabindex="-1"></a>                  <span class="at">modx=</span>c_age,</span>
<span id="cb1438-5"><a href="differentialprediction.html#cb1438-5" tabindex="-1"></a>                  <span class="at">johnson_neyman=</span><span class="cn">FALSE</span>,</span>
<span id="cb1438-6"><a href="differentialprediction.html#cb1438-6" tabindex="-1"></a>                  <span class="at">x.label=</span><span class="st">&quot;Interview Score&quot;</span>,</span>
<span id="cb1438-7"><a href="differentialprediction.html#cb1438-7" tabindex="-1"></a>                  <span class="at">y.label=</span><span class="st">&quot;Job Performance&quot;</span>)</span></code></pre></div>
<pre><code>## SIMPLE SLOPES ANALYSIS 
## 
## Slope of c_interview when c_age = -8.593122204199181268791 (- 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   1.48   0.13    11.16   0.00
## 
## Slope of c_interview when c_age = -0.000000000000003164136 (Mean): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   1.71   0.16    10.70   0.00
## 
## Slope of c_interview when c_age =  8.593122204199174163364 (+ 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   1.95   0.19    10.16   0.00</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-887-1.png" width="672" /></p>
<p>The plot and the simple slopes analyses output show that the two slopes are indeed different, such that the association between the selection tool (<code>c_interview</code>, Interview) and the criterion (<code>perf_eval</code>, Job Performance) is more positive for older workers (<em>b</em> = 1.95, <em>p</em> &lt; .01), than for average-aged workers (<em>b</em> = 1.71, <em>p</em> &lt; .01) and younger workers (<em>b</em> = 1.48, <em>p</em> &lt; .01). Notably, all three simple slopes are statistically significant and positive, but the slope is more positive for older workers.</p>
<p>In sum, we found evidence of both intercept <em>and</em> slope differences for the selection tool (<code>c_interview</code>) in relation to the criterion (<code>perf_eval</code>) that were conditional upon the age protected class variable (<code>c_age</code>). Thus, it would be inappropriate to use a common regression line when predicting scores on the criterion based on the interview selection tool.</p>
</div>
<div id="race_differentialprediction" class="section level4 hasAnchor" number="42.2.5.3">
<h4><span class="header-section-number">42.2.5.3</span> Test Differential Prediction Based on <code>race</code><a href="differentialprediction.html#race_differentialprediction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To investigate whether differential prediction exists for <code>c_interview</code> in relation to <code>perf_eval</code> based on <code>race</code>, we will follow mostly the same process as we did with the dichotomous variable <code>gender</code> above. However, we will filter our data within the regression function to compare just Black individuals with White individuals, as it is customary to compare just two races/ethnicities at a time. The decision to focus on only Black and White individuals is arbitrary and just for demonstration purposes. Note that in the <code>DiffPred</code> data frame object that both <code>black</code> and <code>white</code> are lowercase category labels in the <code>race</code> variable.</p>
<p><strong>Step one:</strong> Regress the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code>. To subset the data such that only individuals who are Black or White are retained, we will add the following argument: <code>rows=(race=="black" | race=="white")</code>. This argument uses conditional statements to indicate that we want to retain those cases for which <code>race</code> is equal to Black <em>or</em> for which <code>race</code> is equal to White. We have effectively dichotomized the <code>race</code> variable using this approach. If you need to review conditional/logical statements when filtering data, check out the <a href="filter.html#filter">chapter on filtering data</a>.</p>
<div class="sourceCode" id="cb1440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1440-1"><a href="differentialprediction.html#cb1440-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool)</span></span>
<span id="cb1440-2"><a href="differentialprediction.html#cb1440-2" tabindex="-1"></a><span class="fu">reg_brief</span>(perf_eval <span class="sc">~</span> c_interview, <span class="at">data=</span>DiffPred, </span>
<span id="cb1440-3"><a href="differentialprediction.html#cb1440-3" tabindex="-1"></a>          <span class="at">rows=</span>(race<span class="sc">==</span><span class="st">&quot;black&quot;</span> <span class="sc">|</span> race<span class="sc">==</span><span class="st">&quot;white&quot;</span>))</span></code></pre></div>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-888-1.png" width="672" /></p>
<pre><code>## &gt;&gt;&gt; Suggestion
## # Create an R markdown file for interpretative output with  Rmd = &quot;file_name&quot;
## reg(perf_eval ~ c_interview, data=DiffPred, rows=(race == &quot;black&quot; | race == &quot;white&quot;), Rmd=&quot;eg&quot;)  
## 
## 
##   BACKGROUND 
## 
## Data Frame:  DiffPred 
##  
## Response Variable: perf_eval 
## Predictor Variable: c_interview 
##  
## Number of cases (rows) of data:  212 
## Number of cases retained for analysis:  212 
## 
## 
##   BASIC ANALYSIS 
## 
##              Estimate    Std Err  t-value  p-value   Lower 95%   Upper 95% 
## (Intercept)     4.715      0.068   69.164    0.000       4.580       4.849 
## c_interview     0.140      0.052    2.672    0.008       0.037       0.243 
## 
## Standard deviation of perf_eval: 1.004 
##  
## Standard deviation of residuals:  0.989 for 210 degrees of freedom 
## 95% range of residual variation:  3.901 = 2 * (1.971 * 0.989) 
##  
## R-squared:  0.033    Adjusted R-squared:  0.028    PRESS R-squared:  0.014 
## 
## Null hypothesis of all 0 population slope coefficients:
##   F-statistic: 7.139     df: 1 and 210     p-value:  0.008 
## 
## -- Analysis of Variance 
##  
##               df    Sum Sq   Mean Sq   F-value   p-value 
## Model          1     6.990     6.990     7.139     0.008 
## Residuals    210   205.600     0.979 
## perf_eval    211   212.590     1.008 
## 
## 
##   K-FOLD CROSS-VALIDATION 
## 
## 
##   RELATIONS AMONG THE VARIABLES 
## 
## 
##   RESIDUALS AND INFLUENCE 
## 
## 
##   PREDICTION ERROR</code></pre>
<p>We should begin by noting that our effective sample size is now 212, whereas previously it was 370 when we included individuals of all races. The regression coefficient for <code>c_interview</code> is statistically significant and positive (<em>b</em> = .140, <em>p</em> = .008) based on this reduced sample of 212 individuals, which provides evidence of criterion-related validity. The amount of variance explained by <code>c_interview</code> in <code>perf_eval</code> is small in magnitude (<em>R</em><sup>2</sup> = .033, adjusted <em>R</em><sup>2</sup> = .028, <em>p</em> &lt; .001).</p>
<p><strong>Step Two:</strong> We will regress the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code> and the protected class variable <code>race</code>.</p>
<div class="sourceCode" id="cb1442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1442-1"><a href="differentialprediction.html#cb1442-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool) and protected class (race)</span></span>
<span id="cb1442-2"><a href="differentialprediction.html#cb1442-2" tabindex="-1"></a><span class="fu">reg_brief</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">+</span> race, <span class="at">data=</span>DiffPred,</span>
<span id="cb1442-3"><a href="differentialprediction.html#cb1442-3" tabindex="-1"></a>          <span class="at">rows=</span>(race<span class="sc">==</span><span class="st">&quot;black&quot;</span> <span class="sc">|</span> race<span class="sc">==</span><span class="st">&quot;white&quot;</span>))</span></code></pre></div>
<pre><code>## 
## &gt;&gt;&gt;  race is not numeric. Converted to indicator variables.</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-889-1.png" width="672" /></p>
<pre><code>## &gt;&gt;&gt; Suggestion
## # Create an R markdown file for interpretative output with  Rmd = &quot;file_name&quot;
## reg(perf_eval ~ c_interview + race, data=DiffPred, rows=(race == &quot;black&quot; | race == &quot;white&quot;), Rmd=&quot;eg&quot;)  
## 
## 
##   BACKGROUND 
## 
## Data Frame:  DiffPred 
##  
## Response Variable: perf_eval 
## Predictor Variable 1: c_interview 
## Predictor Variable 2: racewhite 
##  
## Number of cases (rows) of data:  212 
## Number of cases retained for analysis:  212 
## 
## 
##   BASIC ANALYSIS 
## 
##              Estimate    Std Err  t-value  p-value   Lower 95%   Upper 95% 
## (Intercept)     4.911      0.089   54.922    0.000       4.735       5.087 
## c_interview     0.127      0.051    2.469    0.014       0.026       0.228 
##   racewhite    -0.440      0.134   -3.287    0.001      -0.705      -0.176 
## 
## Standard deviation of perf_eval: 1.004 
##  
## Standard deviation of residuals:  0.967 for 209 degrees of freedom 
## 95% range of residual variation:  3.813 = 2 * (1.971 * 0.967) 
##  
## R-squared:  0.080    Adjusted R-squared:  0.072    PRESS R-squared:  NA 
## 
## Null hypothesis of all 0 population slope coefficients:
##   F-statistic: 9.139     df: 2 and 209     p-value:  0.000 
## 
## -- Analysis of Variance from Type II Sums of Squares 
##  
##               df    Sum Sq   Mean Sq   F-value   p-value 
## c_interview    1     5.700     5.700     6.094     0.014 
##   racewhite    1    10.107    10.107    10.806     0.001 
## Residuals    209   195.493     0.935 
## 
## -- Test of Interaction 
##   
## c_interview:race  df: 1  df resid: 208  SS: 3.343  F: 3.618  p-value: 0.059 
##   
## -- Assume parallel lines, no interaction of race with c_interview 
##  
## Level black: y^_perf_eval = 4.911 + 0.127(x_c_interview) 
## Level white: y^_perf_eval = 4.470 + 0.127(x_c_interview) 
##   
## -- Visualize Separately Computed Regression Lines 
## 
## Plot(c_interview, perf_eval, by=race, fit=&quot;lm&quot;) 
## 
## 
##   K-FOLD CROSS-VALIDATION 
## 
## 
##   RELATIONS AMONG THE VARIABLES 
## 
## 
##   RESIDUALS AND INFLUENCE 
## 
## 
##   PREDICTION ERROR</code></pre>
<p>The regression coefficient associated with <code>race</code> (or more specifically <code>racewhite</code>) is negative and statistically significant (<em>b</em> = -.440, <em>p</em> = .001) when controlling for <code>c_interview</code>, which indicates that there is evidence of intercept differences. Because the coefficient is negative and because <code>white</code> is appended to the <code>race</code> variable name, it implies that the intercept value is significantly lower for White individuals compared to Black individuals. The amount of variance explained by <code>c_interview</code> <em>and</em> <code>race</code> in <code>perf_eval</code> is small-medium in magnitude (<em>R</em><sup>2</sup> = .080, adjusted <em>R</em><sup>2</sup> = .072, <em>p</em> &lt; .001).</p>
<p>Using the <code>probe_interaction</code> function from the <code>interactions</code> package, we will visualize the intercept differences. As input to the <code>probe_interaction</code> function, use the <code>lm</code> function base R to specify our regression model from above. The <code>subset=</code> argument functions the same way as the <code>rows=</code> argument from the <code>reg_brief</code> and <code>Regression</code> functions from <code>lessR</code>, so we’ll use that instead for the <code>lm</code> function. Name this model something so that we can reference it in the next function (<code>Int_Model</code>).</p>
<div class="sourceCode" id="cb1445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1445-1"><a href="differentialprediction.html#cb1445-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool) and protected class (race)</span></span>
<span id="cb1445-2"><a href="differentialprediction.html#cb1445-2" tabindex="-1"></a>Int_Model <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">+</span> race, <span class="at">data=</span>DiffPred,</span>
<span id="cb1445-3"><a href="differentialprediction.html#cb1445-3" tabindex="-1"></a>                <span class="at">subset=</span>(race<span class="sc">==</span><span class="st">&quot;black&quot;</span> <span class="sc">|</span> race<span class="sc">==</span><span class="st">&quot;white&quot;</span>))</span></code></pre></div>
<p>Let’s specify the arguments in the <code>probe_interaction</code> function to plot the intercept differences.</p>
<div class="sourceCode" id="cb1446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1446-1"><a href="differentialprediction.html#cb1446-1" tabindex="-1"></a><span class="co"># Visualize intercept differences</span></span>
<span id="cb1446-2"><a href="differentialprediction.html#cb1446-2" tabindex="-1"></a><span class="fu">probe_interaction</span>(Int_Model, </span>
<span id="cb1446-3"><a href="differentialprediction.html#cb1446-3" tabindex="-1"></a>                  <span class="at">pred=</span>c_interview, </span>
<span id="cb1446-4"><a href="differentialprediction.html#cb1446-4" tabindex="-1"></a>                  <span class="at">modx=</span>race,</span>
<span id="cb1446-5"><a href="differentialprediction.html#cb1446-5" tabindex="-1"></a>                  <span class="at">johnson_neyman=</span><span class="cn">FALSE</span>,</span>
<span id="cb1446-6"><a href="differentialprediction.html#cb1446-6" tabindex="-1"></a>                  <span class="at">x.label=</span><span class="st">&quot;Interview Score&quot;</span>,</span>
<span id="cb1446-7"><a href="differentialprediction.html#cb1446-7" tabindex="-1"></a>                  <span class="at">y.label=</span><span class="st">&quot;Job Performance&quot;</span>)</span></code></pre></div>
<pre><code>## SIMPLE SLOPES ANALYSIS 
## 
## Slope of c_interview when race = white: 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.13   0.05     2.47   0.01
## 
## Slope of c_interview when race = black: 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.13   0.05     2.47   0.01</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-891-1.png" width="672" /></p>
<p><strong>Step Three:</strong> Finally, let’s add the interaction term between <code>c_interview</code> and <code>race</code> to the model using the <code>*</code> operator.</p>
<div class="sourceCode" id="cb1448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1448-1"><a href="differentialprediction.html#cb1448-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool), protected class (race), </span></span>
<span id="cb1448-2"><a href="differentialprediction.html#cb1448-2" tabindex="-1"></a><span class="co"># and interaction between selection tool and protected class</span></span>
<span id="cb1448-3"><a href="differentialprediction.html#cb1448-3" tabindex="-1"></a><span class="fu">reg_brief</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">*</span> race, <span class="at">data=</span>DiffPred,</span>
<span id="cb1448-4"><a href="differentialprediction.html#cb1448-4" tabindex="-1"></a>          <span class="at">rows=</span>(race<span class="sc">==</span><span class="st">&quot;black&quot;</span> <span class="sc">|</span> race<span class="sc">==</span><span class="st">&quot;white&quot;</span>))</span></code></pre></div>
<pre><code>## 
## &gt;&gt;&gt;  race is not numeric. Converted to indicator variables.</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-892-1.png" width="672" /></p>
<pre><code>## &gt;&gt;&gt; Suggestion
## # Create an R markdown file for interpretative output with  Rmd = &quot;file_name&quot;
## reg(perf_eval ~ c_interview * race, data=DiffPred, rows=(race == &quot;black&quot; | race == &quot;white&quot;), Rmd=&quot;eg&quot;)  
## 
## 
##   BACKGROUND 
## 
## Data Frame:  DiffPred 
##  
## Response Variable: perf_eval 
## Predictor Variable 1: c_interview 
## Predictor Variable 2: racewhite 
## Predictor Variable 3: c_interview.racewhite 
##  
## Number of cases (rows) of data:  212 
## Number of cases retained for analysis:  212 
## 
## 
##   BASIC ANALYSIS 
## 
##                        Estimate    Std Err  t-value  p-value   Lower 95%   Upper 95% 
##           (Intercept)     4.912      0.089   55.275    0.000       4.737       5.087 
##           c_interview     0.218      0.070    3.112    0.002       0.080       0.357 
##             racewhite    -0.463      0.134   -3.466    0.001      -0.727      -0.200 
## c_interview.racewhite    -0.194      0.102   -1.902    0.059      -0.396       0.007 
## 
## Standard deviation of perf_eval: 1.004 
##  
## Standard deviation of residuals:  0.961 for 208 degrees of freedom 
## 95% range of residual variation:  3.790 = 2 * (1.971 * 0.961) 
##  
## R-squared:  0.096    Adjusted R-squared:  0.083    PRESS R-squared:  NA 
## 
## Null hypothesis of all 0 population slope coefficients:
##   F-statistic: 7.375     df: 3 and 208     p-value:  0.000 
## 
## -- Analysis of Variance from Type II Sums of Squares 
##  
##                         df    Sum Sq   Mean Sq   F-value   p-value 
##           c_interview    1     5.700     5.700     6.094     0.014 
##             racewhite    1    10.107    10.107    10.941     0.001 
## c_interview.racewhite    1     3.343     3.343     3.618     0.059 
## Residuals              208   192.150     0.924 
## 
## -- Test of Interaction 
##   
## c_interview:race  df: 1  df resid: 208  SS: 3.343  F: 3.618  p-value: 0.059 
##   
## -- Assume parallel lines, no interaction of race with c_interview 
##  
## Level black: y^_perf_eval = 4.912 + 0.218(x_c_interview) 
## Level white: y^_perf_eval = 4.448 + 0.218(x_c_interview) 
##   
## -- Visualize Separately Computed Regression Lines 
## 
## Plot(c_interview, perf_eval, by=race, fit=&quot;lm&quot;) 
## 
## 
##   K-FOLD CROSS-VALIDATION 
## 
## 
##   RELATIONS AMONG THE VARIABLES 
## 
## 
##   RESIDUALS AND INFLUENCE 
## 
## 
##   PREDICTION ERROR</code></pre>
<p>The regression coefficient associated with the interaction term (<code>c_interview:racewhite</code>) is <em>not</em> statistically significant (<em>b</em> = -.194, <em>p</em> = .059), which indicates that there is no evidence of <em>slope differences</em>. Given this, we won’t probe the interaction because, well, there is not an interaction to probe.</p>
<p>In sum, we found evidence of intercept differences for the selection tool <code>c_interview</code> in relation to the criterion <code>perf_eval</code> that were conditional upon the protected class variable <code>race</code>. Thus, it would be inappropriate to use a common regression line when predicting scores on the criterion based on the interview selection tool.</p>
</div>
</div>
<div id="summary_differentialprediction" class="section level3 hasAnchor" number="42.2.6">
<h3><span class="header-section-number">42.2.6</span> Summary<a href="differentialprediction.html#summary_differentialprediction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this chapter, we learned how to use moderated multiple linear regression (MMLR) to test whether evidence of differential prediction exists. To do so, we learned how to use the <code>Regression</code> function (well, technically we used the <code>reg_brief</code> function) from <code>lessR</code>. In addition, we used the <code>probe_interaction</code> function from the <code>interactions</code> package to probe the intercept differences and slope differences visually and using simple slopes analyses.</p>
</div>
</div>
<div id="differentialprediction_supplement" class="section level2 hasAnchor" number="42.3">
<h2><span class="header-section-number">42.3</span> Chapter Supplement<a href="differentialprediction.html#differentialprediction_supplement" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In addition to the <code>Regression</code> function from the <code>lessR</code> package covered <a href="incrementalvalidity.html#estimate_mlr">above</a>, we can use the <code>lm</code> function from base R to estimate a moderated multiple linear regression (MMLR) model. Because this function comes from base R, we do not need to install and access an additional package. In this supplement, you will also have an opportunity to learn how to make an APA (American Psychological Association) style table of regression results.</p>
<div id="differentialprediction_supplement_functions" class="section level3 hasAnchor" number="42.3.1">
<h3><span class="header-section-number">42.3.1</span> Functions &amp; Packages Introduced<a href="differentialprediction.html#differentialprediction_supplement_functions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr class="header">
<th>Function</th>
<th>Package</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>mean</code></td>
<td>base R</td>
</tr>
<tr class="even">
<td><code>lm</code></td>
<td>base R</td>
</tr>
<tr class="odd">
<td><code>summary</code></td>
<td>base R</td>
</tr>
<tr class="even">
<td><code>anova</code></td>
<td>base R</td>
</tr>
<tr class="odd">
<td><code>probe_interaction</code></td>
<td><code>interactions</code></td>
</tr>
<tr class="even">
<td><code>apa.reg.table</code></td>
<td><code>apaTables</code></td>
</tr>
</tbody>
</table>
</div>
<div id="differentialprediction_initsteps_supplement" class="section level3 hasAnchor" number="42.3.2">
<h3><span class="header-section-number">42.3.2</span> Initial Steps<a href="differentialprediction.html#differentialprediction_initsteps_supplement" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If required, please refer to the <a href="differentialprediction.html#initsteps_mmlr">Initial Steps</a> section from this chapter for more information on these initial steps.</p>
<div class="sourceCode" id="cb1451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1451-1"><a href="differentialprediction.html#cb1451-1" tabindex="-1"></a><span class="co"># Set your working directory</span></span>
<span id="cb1451-2"><a href="differentialprediction.html#cb1451-2" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">&quot;H:/RWorkshop&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1452-1"><a href="differentialprediction.html#cb1452-1" tabindex="-1"></a><span class="co"># Install readr package if you haven&#39;t already</span></span>
<span id="cb1452-2"><a href="differentialprediction.html#cb1452-2" tabindex="-1"></a><span class="co"># [Note: You don&#39;t need to install a package every </span></span>
<span id="cb1452-3"><a href="differentialprediction.html#cb1452-3" tabindex="-1"></a><span class="co"># time you wish to access it]</span></span>
<span id="cb1452-4"><a href="differentialprediction.html#cb1452-4" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;readr&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1453-1"><a href="differentialprediction.html#cb1453-1" tabindex="-1"></a><span class="co"># Access readr package</span></span>
<span id="cb1453-2"><a href="differentialprediction.html#cb1453-2" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb1453-3"><a href="differentialprediction.html#cb1453-3" tabindex="-1"></a></span>
<span id="cb1453-4"><a href="differentialprediction.html#cb1453-4" tabindex="-1"></a><span class="co"># Read data and name data frame (tibble) object</span></span>
<span id="cb1453-5"><a href="differentialprediction.html#cb1453-5" tabindex="-1"></a>DiffPred <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;DifferentialPrediction.csv&quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 320 Columns: 6
## ── Column specification ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## chr (3): emp_id, gender, race
## dbl (3): perf_eval, interview, age
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb1455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1455-1"><a href="differentialprediction.html#cb1455-1" tabindex="-1"></a><span class="co"># Print the names of the variables in the data frame (tibble) objects</span></span>
<span id="cb1455-2"><a href="differentialprediction.html#cb1455-2" tabindex="-1"></a><span class="fu">names</span>(DiffPred)</span></code></pre></div>
<pre><code>## [1] &quot;emp_id&quot;    &quot;perf_eval&quot; &quot;interview&quot; &quot;gender&quot;    &quot;age&quot;       &quot;race&quot;</code></pre>
<div class="sourceCode" id="cb1457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1457-1"><a href="differentialprediction.html#cb1457-1" tabindex="-1"></a><span class="co"># View variable type for each variable in data frame</span></span>
<span id="cb1457-2"><a href="differentialprediction.html#cb1457-2" tabindex="-1"></a><span class="fu">str</span>(DiffPred)</span></code></pre></div>
<pre><code>## spc_tbl_ [320 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ emp_id   : chr [1:320] &quot;EE200&quot; &quot;EE202&quot; &quot;EE203&quot; &quot;EE206&quot; ...
##  $ perf_eval: num [1:320] 6.2 6.6 5 4 5.3 5.9 5.5 3.8 5.7 3.8 ...
##  $ interview: num [1:320] 8.5 5.7 7 6.8 9.6 6 7.5 5.9 9.6 8.3 ...
##  $ gender   : chr [1:320] &quot;woman&quot; &quot;woman&quot; &quot;man&quot; &quot;woman&quot; ...
##  $ age      : num [1:320] 30 45.6 39.2 36.9 24.5 41.5 35.1 43.2 25.7 27.8 ...
##  $ race     : chr [1:320] &quot;black&quot; &quot;black&quot; &quot;asian&quot; &quot;black&quot; ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   emp_id = col_character(),
##   ..   perf_eval = col_double(),
##   ..   interview = col_double(),
##   ..   gender = col_character(),
##   ..   age = col_double(),
##   ..   race = col_character()
##   .. )
##  - attr(*, &quot;problems&quot;)=&lt;externalptr&gt;</code></pre>
<div class="sourceCode" id="cb1459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1459-1"><a href="differentialprediction.html#cb1459-1" tabindex="-1"></a><span class="co"># View first 6 rows of data frame</span></span>
<span id="cb1459-2"><a href="differentialprediction.html#cb1459-2" tabindex="-1"></a><span class="fu">head</span>(DiffPred)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 6
##   emp_id perf_eval interview gender   age race 
##   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;
## 1 EE200        6.2       8.5 woman   30   black
## 2 EE202        6.6       5.7 woman   45.6 black
## 3 EE203        5         7   man     39.2 asian
## 4 EE206        4         6.8 woman   36.9 black
## 5 EE209        5.3       9.6 woman   24.5 white
## 6 EE214        5.9       6   woman   41.5 asian</code></pre>
</div>
<div id="lm_function_mmlr" class="section level3 hasAnchor" number="42.3.3">
<h3><span class="header-section-number">42.3.3</span> <code>lm</code> Function from Base R<a href="differentialprediction.html#lm_function_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We will use the <code>lm</code> function from base R to specify and estimate our regression functions. As I did above, I will show you how to apply moderated multiple linear regression (MMLR) in the service of detecting differential prediction of a selection tool based on protected class membership.</p>
<p><strong>Grand-Mean Center Variables:</strong> Before we estimate the regression models, however, we need to grand-mean center certain variables. We only center predictor and moderator variables that are of type <em>numeric</em> and that we conceptualize as having a continuous (interval or ratio) measurement scale. In our current data frame, we will grand-mean center just the <code>interview</code> and <code>age</code> variables. We will use what is perhaps the most intuitive approach for grand-mean centering variables. We must begin by coming up with a new name for one of our soon-to-be grand-mean centered variable, and in this example, we will center the <code>interview</code> variable. I typically like to name the centered variable by simply adding the <code>c_</code> prefix to the existing variable’s names (e.g., <code>c_interview</code>). Type the name of the data frame object to which the new centered variable will be attached (<code>DiffPred</code>), followed by the <code>$</code> operator and the name of the new variable we are creating (<code>c_interview</code>). Next, add the <code>&lt;-</code> operator to indicate what values you will assign to this new variable. To create a vector of values to assign to this new <code>c_interview</code> variable, we will subtract the mean (average) score for the original variable (<code>interview</code>) from each case’s value on the variable. Specifically, enter the name of the data frame object, followed by the <code>$</code> operator and the name of the original variable (<code>interview</code>). After that, enter the subtraction operator (<code>-</code>). And finally, type the name of the <code>mean</code> function from base R. As the first argument in the <code>mean</code> function, enter the name of the data frame object (<code>DiffPred</code>), followed by the <code>$</code> operator and the name of the original variable (<code>interview</code>). As the second argument, enter <code>na.rm=TRUE</code> to indicate that you wish to drop missing values when calculating the grand mean for the sample. Now repeat those same steps for the <code>age</code> variable.</p>
<div class="sourceCode" id="cb1461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1461-1"><a href="differentialprediction.html#cb1461-1" tabindex="-1"></a><span class="co"># Grand-mean centering: Using basic arithmetic and the mean function from base R</span></span>
<span id="cb1461-2"><a href="differentialprediction.html#cb1461-2" tabindex="-1"></a>DiffPred<span class="sc">$</span>c_interview <span class="ot">&lt;-</span> DiffPred<span class="sc">$</span>interview <span class="sc">-</span> <span class="fu">mean</span>(DiffPred<span class="sc">$</span>interview, <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span>
<span id="cb1461-3"><a href="differentialprediction.html#cb1461-3" tabindex="-1"></a>DiffPred<span class="sc">$</span>c_age <span class="ot">&lt;-</span> DiffPred<span class="sc">$</span>age <span class="sc">-</span> <span class="fu">mean</span>(DiffPred<span class="sc">$</span>age, <span class="at">na.rm=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<div id="gender_differentialprediction_lm" class="section level4 hasAnchor" number="42.3.3.1">
<h4><span class="header-section-number">42.3.3.1</span> Test Differential Prediction Based on <code>gender</code><a href="differentialprediction.html#gender_differentialprediction_lm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s start with investigating whether differential prediction exists for our <code>interview</code> selection tool in relation to <code>perf_eval</code> based <code>gender</code> subgroup membership (i.e., man, woman).</p>
<p><strong>Step One:</strong> Let’s being by regressing the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code>. Here we are just establishing whether the selection tool shows evidence of criterion-related validity. See the chapters on <a href="criterionrelatedvalidity.html#criterionrelatedvalidity">criterion-related validity using correlation</a> and <a href="predictingcriterionscores.html#predictingcriterionscores">predicting criterion scores using simple linear regression</a> if you would like more information on regression-based approaches to assessing criterion-related validity, including determining whether statistical assumptions have been met. Let’s name our regression model for this first step <code>model.1</code>. Remember, we need to use the <code>summary</code> function from base R to view our model output.</p>
<div class="sourceCode" id="cb1462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1462-1"><a href="differentialprediction.html#cb1462-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool)</span></span>
<span id="cb1462-2"><a href="differentialprediction.html#cb1462-2" tabindex="-1"></a>model<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview, <span class="at">data=</span>DiffPred)</span>
<span id="cb1462-3"><a href="differentialprediction.html#cb1462-3" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perf_eval ~ c_interview, data = DiffPred)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7226 -0.6846  0.0007  0.7494  2.5842 
## 
## Coefficients:
##             Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)  4.70750    0.05444  86.472 &lt; 0.0000000000000002 ***
## c_interview  0.19175    0.04143   4.629           0.00000537 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9738 on 318 degrees of freedom
## Multiple R-squared:  0.06312,    Adjusted R-squared:  0.06018 
## F-statistic: 21.43 on 1 and 318 DF,  p-value: 0.000005366</code></pre>
<p>The regression coefficient for <code>c_interview</code> is statistically significant and positive (<em>b</em> = .192, <em>p</em> &lt; .001), which provides evidence of criterion-related validity. The amount of variance explained by <code>c_interview</code> in <code>perf_eval</code> is small-medium in magnitude (<em>R</em><sup>2</sup> = .063, adjusted <em>R</em><sup>2</sup> = .060, <em>p</em> &lt; .001). See the table below for common rules of thumbs for qualitatively describing <em>R</em><sup>2</sup> values.</p>
<table>
<thead>
<tr class="header">
<th align="center"><em>R</em><sup>2</sup></th>
<th align="center">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">.01</td>
<td align="center">Small</td>
</tr>
<tr class="even">
<td align="center">.09</td>
<td align="center">Medium</td>
</tr>
<tr class="odd">
<td align="center">.25</td>
<td align="center">Large</td>
</tr>
</tbody>
</table>
<p><strong>Step Two:</strong> Next, let’s add the protected class variable <code>gender</code> to our model to investigate whether <em>intercept differences</em> exist. We’ll name this model <code>model.2</code>. For more information on how to interpret and test the statistical assumptions of a multiple linear regression model, check out the <a href="incrementalvalidity.html#incrementalvalidity">chapter on estimating incremental validity</a>. In addition, let’s use the <code>anova</code> function from base R to do a nested model comparison between <code>model.1</code> and <code>model.2</code>. This will tell us whether adding <code>gender</code> to the model significantly improved model fit. Finally, let’s reference the summary/output for each model and specifically the <code>r.squared</code> values to determine what the change in <em>R</em><sup>2</sup> was from one model to the next. The change in <em>R</em><sup>2</sup> gives as an idea of how much (in terms of practical significance) the model fit improved when adding the additional variable. Note that we use the <code>$</code> operator to indicate that we want the <code>r.squared</code> value from the <code>summary(model.2)</code> and <code>summary(model.2)</code> output, and then we do a simple subtraction to get the change in <em>R</em><sup>2</sup>.</p>
<div class="sourceCode" id="cb1464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1464-1"><a href="differentialprediction.html#cb1464-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool) and protected class (gender)</span></span>
<span id="cb1464-2"><a href="differentialprediction.html#cb1464-2" tabindex="-1"></a>model<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">+</span> gender, <span class="at">data=</span>DiffPred)</span>
<span id="cb1464-3"><a href="differentialprediction.html#cb1464-3" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perf_eval ~ c_interview + gender, data = DiffPred)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8125 -0.6629  0.0049  0.7578  2.5245 
## 
## Coefficients:
##             Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)  4.62953    0.07625  60.719 &lt; 0.0000000000000002 ***
## c_interview  0.21058    0.04332   4.861           0.00000184 ***
## genderwoman  0.16634    0.11409   1.458                0.146    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9721 on 317 degrees of freedom
## Multiple R-squared:  0.06936,    Adjusted R-squared:  0.06349 
## F-statistic: 11.81 on 2 and 317 DF,  p-value: 0.00001127</code></pre>
<div class="sourceCode" id="cb1466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1466-1"><a href="differentialprediction.html#cb1466-1" tabindex="-1"></a><span class="co"># Nested model comparison</span></span>
<span id="cb1466-2"><a href="differentialprediction.html#cb1466-2" tabindex="-1"></a><span class="fu">anova</span>(model<span class="fl">.1</span>, model<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: perf_eval ~ c_interview
## Model 2: perf_eval ~ c_interview + gender
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1    318 301.58                           
## 2    317 299.57  1    2.0086 2.1255 0.1459</code></pre>
<div class="sourceCode" id="cb1468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1468-1"><a href="differentialprediction.html#cb1468-1" tabindex="-1"></a><span class="co"># Change in R-squared</span></span>
<span id="cb1468-2"><a href="differentialprediction.html#cb1468-2" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.2</span>)<span class="sc">$</span>r.squared <span class="sc">-</span> <span class="fu">summary</span>(model<span class="fl">.1</span>)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.006239901</code></pre>
<p>The unstandardized regression coefficient associated with <code>gender</code> (or more specifically <code>genderwoman</code>) is not statistically significant (<em>b</em> = .166, <em>p</em> = .146) when controlling for <code>c_interview</code>, which indicates that there is <em>no</em> evidence of intercept differences. Note that the name of the regression coefficient for <code>gender</code> has <code>woman</code> appended to it; this means that the intercept represents the <code>perf_eval</code> scores of women minus those for men. Behind the scenes, the <code>reg_brief</code> function has converted the <code>gender</code> variable to a dichotomous factor, where alphabetically <code>man</code> becomes 0 and <code>woman</code> becomes 1. Because the coefficient is negative, it implies that the intercept value is higher for women relative to men; however, please note that we wouldn’t interpret the direction of this effect because it was not statistically significant. The amount of variance explained by <code>c_interview</code> <em>and</em> <code>gender</code> in <code>perf_eval</code> is small-medium in magnitude (<em>R</em><sup>2</sup> = .069, adjusted <em>R</em><sup>2</sup> = .063, <em>p</em> &lt; .001), which is slightly larger than when just <code>c_interview</code> was included in the model (see Step One above). The nonsignificant <em>F</em>-value (2.126, <em>p</em> = .146) in from the nested model comparison indicates that adding <code>gender</code> to the model did not significantly improve model fit, and thus we will not interpret the change in <em>R</em><sup>2</sup>.</p>
<p>Because there is no evidence of intercept differences for Step Two, we won’t plot/graph the our model, as doing so might mislead someone who sees such a plot without knowing or understanding the results of the model we just estimated. We will now proceed to Step Three.</p>
<p><strong>Step Three:</strong> As the final step, it’s time to add the interaction term (also known as a product term) between <code>c_interview</code> and <code>gender</code> to the model, which creates what is referred to as a <em>multiplicative model</em>. Fortunately, this is very easy to do in R. All we need to do is change the <code>+</code> operator from our previous regression model script to the <code>*</code>, where the <code>*</code> implies an interaction in the context of a model. Conceptually, the <code>*</code> is appropriate because we are estimating a multiplicative model containing an interaction term. Let’s name this model <code>model.3</code>. As before, we’ll do a nested model comparison between the previous model and this model to determine whether there is a significant improvement in model fit. In addition, we’ll estimate change in <em>R</em><sup>2</sup>.</p>
<div class="sourceCode" id="cb1470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1470-1"><a href="differentialprediction.html#cb1470-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool), protected class (gender), </span></span>
<span id="cb1470-2"><a href="differentialprediction.html#cb1470-2" tabindex="-1"></a><span class="co"># and interaction between selection tool and protected class</span></span>
<span id="cb1470-3"><a href="differentialprediction.html#cb1470-3" tabindex="-1"></a>model<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">*</span> gender, <span class="at">data=</span>DiffPred)</span>
<span id="cb1470-4"><a href="differentialprediction.html#cb1470-4" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perf_eval ~ c_interview * gender, data = DiffPred)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.71851 -0.67772  0.01742  0.69477  2.48590 
## 
## Coefficients:
##                         Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)              4.56191    0.07566  60.298 &lt; 0.0000000000000002 ***
## c_interview              0.39426    0.05909   6.672       0.000000000113 ***
## genderwoman              0.15494    0.11091   1.397                0.163    
## c_interview:genderwoman -0.37306    0.08422  -4.430       0.000013026266 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9448 on 316 degrees of freedom
## Multiple R-squared:  0.1238, Adjusted R-squared:  0.1155 
## F-statistic: 14.88 on 3 and 316 DF,  p-value: 0.000000004387</code></pre>
<div class="sourceCode" id="cb1472"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1472-1"><a href="differentialprediction.html#cb1472-1" tabindex="-1"></a><span class="co"># Nested model comparison</span></span>
<span id="cb1472-2"><a href="differentialprediction.html#cb1472-2" tabindex="-1"></a><span class="fu">anova</span>(model<span class="fl">.2</span>, model<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: perf_eval ~ c_interview + gender
## Model 2: perf_eval ~ c_interview * gender
##   Res.Df    RSS Df Sum of Sq      F     Pr(&gt;F)    
## 1    317 299.57                                   
## 2    316 282.06  1    17.514 19.622 0.00001303 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb1474"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1474-1"><a href="differentialprediction.html#cb1474-1" tabindex="-1"></a><span class="co"># Change in R-squared</span></span>
<span id="cb1474-2"><a href="differentialprediction.html#cb1474-2" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.3</span>)<span class="sc">$</span>r.squared <span class="sc">-</span> <span class="fu">summary</span>(model<span class="fl">.2</span>)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.05440861</code></pre>
<p>In our output, we now have an unstandardized regression coefficient called <code>c_interview:gender</code> (or <code>c_interview.gender</code>), which represents our interaction term for <code>c_interview</code> and <code>gender</code>. The regression coefficient associated with the interaction term (<code>c_interview:gender</code>) is negative and statistically significant (<em>b</em> = -.373, <em>p</em> &lt; .001), but we shouldn’t pay too much attention to the sign of the interaction term as it is difficult to interpret it without graphing the regression model in its entirety. We should, however, pay attention to the fact that the interaction term is statistically significant, which indicates that there is evidence of <em>slope differences</em>; in other words, there seems to be multiplicative effect between <code>c_interview</code> and <code>gender</code>. Although we didn’t find evidence of intercept differences in Step Two, here in Step Three, we do find evidence that the criterion-related validities for the selection tool (<code>c_interview</code>) in relation to the criterion (<code>perf_eval</code>) are significantly different from one another; in other words, we found evidence that the slopes for men and women differ. The amount of variance explained by <code>c_interview</code>, <code>gender</code>, <em>and</em> their interaction in relation to <code>perf_eval</code> is medium in magnitude (<em>R</em><sup>2</sup> = .124, adjusted <em>R</em><sup>2</sup> = .115, <em>p</em> &lt; .001), which is larger than when just <code>c_interview</code> and <code>gender</code> were included in the model (see Step Two above). The significant <em>F</em>-value (19.622, <em>p</em> &lt; .001) in from the nested model comparison indicates that adding the interaction term significantly improved model fit, and because there was a significant improvement in model fit, we should interpret the change in <em>R</em><sup>2</sup> (<em>R</em><sup>2</sup> = .054), which indicates that adding the interaction term to the model explained an additional 5.4% of the variance in <code>perf_eval</code>.</p>
<p>Given the statistically significant interaction term, it is appropriate (and helpful) to probe the interaction by plotting it. This will help us understand the form of the interaction. We can do so by creating a plot of the simple slopes. To do so, we will use a package called <code>interactions</code> <span class="citation">(<a href="#ref-interactions">Long 2019</a>)</span>, so if you haven’t already, install and access the package.</p>
<div class="sourceCode" id="cb1476"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1476-1"><a href="differentialprediction.html#cb1476-1" tabindex="-1"></a><span class="co"># Install interactions package if you haven&#39;t already</span></span>
<span id="cb1476-2"><a href="differentialprediction.html#cb1476-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;interactions&quot;</span>)</span>
<span id="cb1476-3"><a href="differentialprediction.html#cb1476-3" tabindex="-1"></a></span>
<span id="cb1476-4"><a href="differentialprediction.html#cb1476-4" tabindex="-1"></a><span class="co"># Note: You may need to install the sandwich package independently if you </span></span>
<span id="cb1476-5"><a href="differentialprediction.html#cb1476-5" tabindex="-1"></a><span class="co"># receive an error when attempting to run the probe_interaction function</span></span>
<span id="cb1476-6"><a href="differentialprediction.html#cb1476-6" tabindex="-1"></a><span class="co"># install.packages(&quot;sandwich&quot;)</span></span></code></pre></div>
<div class="sourceCode" id="cb1477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1477-1"><a href="differentialprediction.html#cb1477-1" tabindex="-1"></a><span class="co"># Access interactions package</span></span>
<span id="cb1477-2"><a href="differentialprediction.html#cb1477-2" tabindex="-1"></a><span class="fu">library</span>(interactions)</span></code></pre></div>
<p>As the first argument in the <code>probe_interaction</code> function from the <code>interactions</code> package, enter the name of the regression model we just created above (<code>model.3</code>). As the second argument, type the name of the variable you are framing as the predictor after <code>pred=</code>, which in our case is the selection tool variable (<code>c_interview</code>). As the third argument, type the name of the variable you are framing as the moderator after <code>modx=</code>, which in our case is the protected class variable (<code>gender</code>). As the fourth argument, enter <code>johnson_neyman=FALSE</code>, as we aren’t requesting the Johnson-Neyman test in this tutorial. Finally, if you choose to, you can use <code>x.label=</code> and <code>y.label=</code> to create more informative names for the predictor and outcome variables, respectively. You could also add, if you should choose to do so, the <code>legend.main=</code> argument to provide a more informative name for the moderator variable, and/or the <code>modx.labels=</code> to provide more informative names for the moderator variable labels.</p>
<div class="sourceCode" id="cb1478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1478-1"><a href="differentialprediction.html#cb1478-1" tabindex="-1"></a><span class="co"># Probe the significant interaction (slope differences)</span></span>
<span id="cb1478-2"><a href="differentialprediction.html#cb1478-2" tabindex="-1"></a><span class="fu">probe_interaction</span>(model<span class="fl">.3</span>, </span>
<span id="cb1478-3"><a href="differentialprediction.html#cb1478-3" tabindex="-1"></a>                  <span class="at">pred=</span>c_interview, </span>
<span id="cb1478-4"><a href="differentialprediction.html#cb1478-4" tabindex="-1"></a>                  <span class="at">modx=</span>gender,</span>
<span id="cb1478-5"><a href="differentialprediction.html#cb1478-5" tabindex="-1"></a>                  <span class="at">johnson_neyman=</span><span class="cn">FALSE</span>,</span>
<span id="cb1478-6"><a href="differentialprediction.html#cb1478-6" tabindex="-1"></a>                  <span class="at">x.label=</span><span class="st">&quot;Interview Score&quot;</span>,</span>
<span id="cb1478-7"><a href="differentialprediction.html#cb1478-7" tabindex="-1"></a>                  <span class="at">y.label=</span><span class="st">&quot;Job Performance&quot;</span>)</span></code></pre></div>
<pre><code>## SIMPLE SLOPES ANALYSIS 
## 
## Slope of c_interview when gender = man: 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.39   0.06     6.67   0.00
## 
## Slope of c_interview when gender = woman: 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.02   0.06     0.35   0.72</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-908-1.png" width="672" /></p>
<p>The plot output shows that the two slopes are indeed different, such that there doesn’t seem to be much of an association between the selection tool (<code>c_interview</code>) and the criterion (<code>perf_eval</code>) for women, but there seems to be a positive association for men. Now take a look at the text output in your console. The simple slopes analysis automatically estimates the regression coefficient (slope) for both levels of the moderator variable (<code>gender</code>: man, woman). Corroborating what we see in the plot, we find that the simple slope for men is indeed statistically significant and positive (<em>b</em> = .39, <em>p</em> &lt; .01), such that for every one unit increase in interview scores, job performance scores tend to go up by .39 units. In contrast, we find that the simple slope for women is nonsignificant (<em>b</em> = .02, <em>p</em> = .72).</p>
<p>In sum, we found evidence of slope differences – but not intercept differences – for the selection tool (<code>c_interview</code>) in relation to the criterion (<code>perf_eval</code>) that were conditional upon the levels/subgroups of the protected class variable (<code>gender</code>). Thus, we can conclude that there is evidence of differential prediction based on gender for this interview selection tool, which means that it would be inappropriate to use a common regression line when predicting scores on the criterion based on the interview selection tool.</p>
<p><strong>Sample Write-Up:</strong> Our HR analytics team recently found evidence in support of the criterion-related validity of a new structured interview selection procedure. As a next step, we investigated whether there might be evidence of differential prediction of the structured interview based on the U.S. protected class of gender. Based on a sample of 370 individuals, we applied a three-step process with moderated multiple linear regression, which is consistent with established principles <span class="citation">(<a href="#ref-siop2018">Society for Industrial &amp; Organizational Psychology 2018</a>; <a href="#ref-cleary1968test">Cleary 1968</a>)</span>. Based on our analyses, we found evidence differential prediction (i.e., predictive bias) based on gender for the new structured interview procedure, and specifically, we found evidence of slope differences. In the first step, we found evidence of criterion-related validity based on a simple linear regression model, as structured interview scores were positively and significantly associated with job performance (<em>b</em> = .192, <em>p</em> &lt; .001), thereby indicating some degree of job-relatedness and -relevance. In the second step, we added the protected class variable associated with gender to the model, resulting in a multiple linear regression model, but did not find evidence of intercept differences based on gender (<em>b</em> = .166, <em>p</em> = .146). In the third step, we added the interaction term between the structured interview and gender variables, resulting in a moderated multiple linear regression model, and we found that gender moderated the association between structured interview scores and job performance scores to a statistically significant extent (<em>b</em> = -.373, <em>p</em> &lt; .001). Based on follow-up simple slopes analyses, we found that the association between structured interview scores and job performance scores was statistically significant for men (<em>b</em> = .39, <em>p</em> &lt; .01), such that for every one unit increase in structured interview scores, job performance scores tended to increase by .39 units; in contrast, the associated between structured interview scores and job performance scores for women was nonsignificant (<em>b</em> = .02, <em>p</em> = .72). In sum, we found evidence slope differences, which means that this structured interview tool shows predictive bias with respect to gender, making the application of a common regression line (i.e., equation) legally problematic within the United States. If possible, this structured interview should be redesigned or the interviewers should be trained to reduce the predictive bias based on gender. In the interim, we caution against using separate regression lines for men and women, as this may be interpreted as running afoul of the U.S. Civil Rights Act of 1991 <span class="citation">(<a href="#ref-saad2002investigating">Saad and Sackett 2002</a>)</span>. A more conservative approach would be to develop a structured interview process that allows for the use of a common regression line across legally protected groups.</p>
</div>
<div id="age_differentialprediction_lm" class="section level4 hasAnchor" number="42.3.3.2">
<h4><span class="header-section-number">42.3.3.2</span> Test Differential Prediction Based on <code>c_age</code><a href="differentialprediction.html#age_differentialprediction_lm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Investigating whether differential prediction exists for <code>c_interview</code> in relation to <code>perf_eval</code> based on the continuous moderator variable <code>c_age</code> will unfold very similarly to the process we used for the dichotomous <code>gender</code> variable from above. The only differences will occur when it comes to estimating and visualizing the intercept differences and simple slopes (assuming we find statistically significant effects). Given this, we will breeze through the steps, which means I will provide less explanation.</p>
<p><strong>Step One:</strong> Regress the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code>.</p>
<div class="sourceCode" id="cb1480"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1480-1"><a href="differentialprediction.html#cb1480-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool)</span></span>
<span id="cb1480-2"><a href="differentialprediction.html#cb1480-2" tabindex="-1"></a>model<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview, <span class="at">data=</span>DiffPred)</span>
<span id="cb1480-3"><a href="differentialprediction.html#cb1480-3" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perf_eval ~ c_interview, data = DiffPred)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7226 -0.6846  0.0007  0.7494  2.5842 
## 
## Coefficients:
##             Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)  4.70750    0.05444  86.472 &lt; 0.0000000000000002 ***
## c_interview  0.19175    0.04143   4.629           0.00000537 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9738 on 318 degrees of freedom
## Multiple R-squared:  0.06312,    Adjusted R-squared:  0.06018 
## F-statistic: 21.43 on 1 and 318 DF,  p-value: 0.000005366</code></pre>
<p>The regression coefficient for <code>c_interview</code> is statistically significant and positive (<em>b</em> = .192, <em>p</em> &lt; .001), which provides evidence of criterion-related validity. The amount of variance explained by <code>c_interview</code> in <code>perf_eval</code> is small-medium in magnitude (<em>R</em><sup>2</sup> = .063, adjusted <em>R</em><sup>2</sup> = .060, <em>p</em> &lt; .001).</p>
<p><strong>Step Two:</strong> Regress the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code> and the protected class variable <code>c_age</code>. In addition, do a nested model comparison, and estimate the change in <em>R</em><sup>2</sup>.</p>
<div class="sourceCode" id="cb1482"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1482-1"><a href="differentialprediction.html#cb1482-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool) and protected class (c_age)</span></span>
<span id="cb1482-2"><a href="differentialprediction.html#cb1482-2" tabindex="-1"></a>model<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">+</span> c_age, <span class="at">data=</span>DiffPred)</span>
<span id="cb1482-3"><a href="differentialprediction.html#cb1482-3" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perf_eval ~ c_interview + c_age, data = DiffPred)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.2596 -0.6087  0.0444  0.6184  2.5522 
## 
## Coefficients:
##             Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)  4.70750    0.04999  94.164 &lt; 0.0000000000000002 ***
## c_interview  0.97806    0.10833   9.028 &lt; 0.0000000000000002 ***
## c_age        0.12863    0.01659   7.752    0.000000000000124 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8943 on 317 degrees of freedom
## Multiple R-squared:  0.2124, Adjusted R-squared:  0.2075 
## F-statistic: 42.75 on 2 and 317 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<div class="sourceCode" id="cb1484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1484-1"><a href="differentialprediction.html#cb1484-1" tabindex="-1"></a><span class="co"># Nested model comparison</span></span>
<span id="cb1484-2"><a href="differentialprediction.html#cb1484-2" tabindex="-1"></a><span class="fu">anova</span>(model<span class="fl">.1</span>, model<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: perf_eval ~ c_interview
## Model 2: perf_eval ~ c_interview + c_age
##   Res.Df    RSS Df Sum of Sq      F             Pr(&gt;F)    
## 1    318 301.58                                           
## 2    317 253.52  1    48.059 60.092 0.0000000000001241 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb1486"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1486-1"><a href="differentialprediction.html#cb1486-1" tabindex="-1"></a><span class="co"># Change in R-squared</span></span>
<span id="cb1486-2"><a href="differentialprediction.html#cb1486-2" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.2</span>)<span class="sc">$</span>r.squared <span class="sc">-</span> <span class="fu">summary</span>(model<span class="fl">.1</span>)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.1492979</code></pre>
<p>The regression coefficient associated with <code>c_age</code> is positive and statistically significant (<em>b</em> = .129, <em>p</em> &lt; .001) when controlling for <code>c_interview</code>, which indicates that there is evidence of intercept differences. Because the coefficient is positive, it implies that the intercept value is significantly higher for older workers relative to younger workers. The amount of variance explained by <code>c_interview</code> <em>and</em> <code>c_age</code> in <code>perf_eval</code> is medium-large in magnitude (<em>R</em><sup>2</sup> = .212, adjusted <em>R</em><sup>2</sup> = .207, <em>p</em> &lt; .001), which is notably larger than when just <code>c_interview</code> was included in the model (see Step One above). The significant <em>F</em>-value (60.092, <em>p</em> &lt; .001) in from the nested model comparison indicates that adding <code>c_age</code> significantly improved model fit, and because there was a significant improvement in model fit, we should interpret the change in <em>R</em><sup>2</sup> (<em>R</em><sup>2</sup> = .149), which indicates that adding <code>c_age</code> to the model explained an additional 14.9% of the variance in <code>perf_eval</code>.</p>
<p>Using the <code>probe_interaction</code> function from the <code>interactions</code> package, we will visualize the intercept differences of the <code>model.2</code> model we specified above. Note that the function automatically categorizes the continuous moderator variable by its mean and 1 standard deviation (SD) below and above the mean. As you can see in the plot, individuals whose age is 1 SD above the mean have the highest intercept value, where the intercept is the value of <code>perf_eval</code> (Job Performance) when <code>interview</code> (Interview) is equal to zero.</p>
<div class="sourceCode" id="cb1488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1488-1"><a href="differentialprediction.html#cb1488-1" tabindex="-1"></a><span class="co"># Visualize intercept differences</span></span>
<span id="cb1488-2"><a href="differentialprediction.html#cb1488-2" tabindex="-1"></a><span class="fu">probe_interaction</span>(model<span class="fl">.2</span>, </span>
<span id="cb1488-3"><a href="differentialprediction.html#cb1488-3" tabindex="-1"></a>                  <span class="at">pred=</span>c_interview, </span>
<span id="cb1488-4"><a href="differentialprediction.html#cb1488-4" tabindex="-1"></a>                  <span class="at">modx=</span>c_age,</span>
<span id="cb1488-5"><a href="differentialprediction.html#cb1488-5" tabindex="-1"></a>                  <span class="at">johnson_neyman=</span><span class="cn">FALSE</span>,</span>
<span id="cb1488-6"><a href="differentialprediction.html#cb1488-6" tabindex="-1"></a>                  <span class="at">x.label=</span><span class="st">&quot;Interview Score&quot;</span>,</span>
<span id="cb1488-7"><a href="differentialprediction.html#cb1488-7" tabindex="-1"></a>                  <span class="at">y.label=</span><span class="st">&quot;Job Performance&quot;</span>)</span></code></pre></div>
<pre><code>## SIMPLE SLOPES ANALYSIS 
## 
## Slope of c_interview when c_age = -8.593122204199181268791 (- 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.98   0.11     9.03   0.00
## 
## Slope of c_interview when c_age = -0.000000000000003164136 (Mean): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.98   0.11     9.03   0.00
## 
## Slope of c_interview when c_age =  8.593122204199174163364 (+ 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.98   0.11     9.03   0.00</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-913-1.png" width="672" /></p>
<p><strong>Step Three:</strong> Now, we will add the interaction term between <code>c_interview</code> and <code>c_age</code> to the model using the <code>*</code> operator. In addition, do a nested model comparison, and estimate the change in <em>R</em><sup>2</sup>.</p>
<div class="sourceCode" id="cb1490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1490-1"><a href="differentialprediction.html#cb1490-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool) and protected class (c_age)</span></span>
<span id="cb1490-2"><a href="differentialprediction.html#cb1490-2" tabindex="-1"></a>model<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">*</span> c_age, <span class="at">data=</span>DiffPred)</span>
<span id="cb1490-3"><a href="differentialprediction.html#cb1490-3" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perf_eval ~ c_interview * c_age, data = DiffPred)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.6271 -0.5798  0.0261  0.5553  2.4924 
## 
## Coefficients:
##                   Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)       4.995359   0.067563  73.937 &lt; 0.0000000000000002 ***
## c_interview       1.711274   0.159937  10.700 &lt; 0.0000000000000002 ***
## c_age             0.263061   0.027431   9.590 &lt; 0.0000000000000002 ***
## c_interview:c_age 0.027267   0.004555   5.986        0.00000000585 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8489 on 316 degrees of freedom
## Multiple R-squared:  0.2926, Adjusted R-squared:  0.2859 
## F-statistic: 43.57 on 3 and 316 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<div class="sourceCode" id="cb1492"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1492-1"><a href="differentialprediction.html#cb1492-1" tabindex="-1"></a><span class="co"># Nested model comparison</span></span>
<span id="cb1492-2"><a href="differentialprediction.html#cb1492-2" tabindex="-1"></a><span class="fu">anova</span>(model<span class="fl">.2</span>, model<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: perf_eval ~ c_interview + c_age
## Model 2: perf_eval ~ c_interview * c_age
##   Res.Df    RSS Df Sum of Sq      F         Pr(&gt;F)    
## 1    317 253.52                                       
## 2    316 227.71  1    25.817 35.827 0.000000005849 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb1494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1494-1"><a href="differentialprediction.html#cb1494-1" tabindex="-1"></a><span class="co"># Change in R-squared</span></span>
<span id="cb1494-2"><a href="differentialprediction.html#cb1494-2" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.3</span>)<span class="sc">$</span>r.squared <span class="sc">-</span> <span class="fu">summary</span>(model<span class="fl">.2</span>)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.08020031</code></pre>
<p>The regression coefficient associated with the interaction term (<code>c_interview:c_age</code>) is positive and statistically significant (<em>b</em> = .027, <em>p</em> &lt; .001), which indicates that there is evidence of <em>slope differences</em>. The amount of variance explained by <code>c_interview</code>, <code>c_age</code>, <em>and</em> their interaction in relation to <code>perf_eval</code> is large in magnitude (<em>R</em><sup>2</sup> = .293, adjusted <em>R</em><sup>2</sup> = .286, <em>p</em> &lt; .001), which is larger than when just <code>c_interview</code> and <code>c_age</code> were included in the model. The significant <em>F</em>-value (35.827, <em>p</em> &lt; .001) in from the nested model comparison indicates that adding the interaction term significantly improved model fit, and because there was a significant improvement in model fit, we should interpret the change in <em>R</em><sup>2</sup> (<em>R</em><sup>2</sup> = .080), which indicates that adding the interaction term to the model explained an additional 8.0% of the variance in <code>perf_eval</code>.</p>
<p>Given the statistically significant interaction term, we will use the <code>probe_interaction</code> function from the <code>interactions</code> package to probe the interaction to plot this multiplicative model that we named <code>model.3</code>.</p>
<div class="sourceCode" id="cb1496"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1496-1"><a href="differentialprediction.html#cb1496-1" tabindex="-1"></a><span class="co"># Probe the significant interaction (slope differences)</span></span>
<span id="cb1496-2"><a href="differentialprediction.html#cb1496-2" tabindex="-1"></a><span class="fu">probe_interaction</span>(model<span class="fl">.3</span>, </span>
<span id="cb1496-3"><a href="differentialprediction.html#cb1496-3" tabindex="-1"></a>                  <span class="at">pred=</span>c_interview, </span>
<span id="cb1496-4"><a href="differentialprediction.html#cb1496-4" tabindex="-1"></a>                  <span class="at">modx=</span>c_age,</span>
<span id="cb1496-5"><a href="differentialprediction.html#cb1496-5" tabindex="-1"></a>                  <span class="at">johnson_neyman=</span><span class="cn">FALSE</span>,</span>
<span id="cb1496-6"><a href="differentialprediction.html#cb1496-6" tabindex="-1"></a>                  <span class="at">x.label=</span><span class="st">&quot;Interview Score&quot;</span>,</span>
<span id="cb1496-7"><a href="differentialprediction.html#cb1496-7" tabindex="-1"></a>                  <span class="at">y.label=</span><span class="st">&quot;Job Performance&quot;</span>)</span></code></pre></div>
<pre><code>## SIMPLE SLOPES ANALYSIS 
## 
## Slope of c_interview when c_age = -8.593122204199181268791 (- 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   1.48   0.13    11.16   0.00
## 
## Slope of c_interview when c_age = -0.000000000000003164136 (Mean): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   1.71   0.16    10.70   0.00
## 
## Slope of c_interview when c_age =  8.593122204199174163364 (+ 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   1.95   0.19    10.16   0.00</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-917-1.png" width="672" /></p>
<p>The plot and the simple slopes analyses output show that the two slopes are indeed different, such that the association between the selection tool (<code>c_interview</code>, Interview) and the criterion (<code>perf_eval</code>, Job Performance) is more positive for older workers (<em>b</em> = 1.95, <em>p</em> &lt; .01), than for average-aged workers (<em>b</em> = 1.71, <em>p</em> &lt; .01) and younger workers (<em>b</em> = 1.48, <em>p</em> &lt; .01). Notably, all three simple slopes are statistically significant and positive, but the slope is more positive for older workers.</p>
<p>In sum, we found evidence of both intercept <em>and</em> slope differences for the selection tool (<code>c_interview</code>) in relation to the criterion (<code>perf_eval</code>) that were conditional upon the age protected class variable (<code>c_age</code>). Thus, it would be inappropriate to use a common regression line when predicting scores on the criterion based on the interview selection tool.</p>
</div>
<div id="race_differentialprediction_lm" class="section level4 hasAnchor" number="42.3.3.3">
<h4><span class="header-section-number">42.3.3.3</span> Test Differential Prediction Based on <code>race</code><a href="differentialprediction.html#race_differentialprediction_lm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To investigate whether differential prediction exists for <code>c_interview</code> in relation to <code>perf_eval</code> based on <code>race</code>, we will follow mostly the same process as we did with the dichotomous variable <code>gender</code> above. However, we will filter our data within the regression function to compare just Black individuals with White individuals, as it is customary to compare just two races/ethnicities at a time. The decision to focus on only Black and White individuals is arbitrary and just for demonstration purposes. Note that in the <code>DiffPred</code> data frame object that both <code>black</code> and <code>white</code> are lowercase category labels in the <code>race</code> variable.</p>
<p><strong>Step One:</strong> Regress the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code>. Add the <code>subset=(race=="black" | race=="white")</code> argument to subset the data such that only those individuals who are Black and White are retained. In doing so, we effectively dichotomize the <code>race</code> variable within the <code>lm</code> function. If you need to review conditional/logical statements when filtering data, check out the <a href="filter.html#filter">chapter on filtering data</a>.</p>
<div class="sourceCode" id="cb1498"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1498-1"><a href="differentialprediction.html#cb1498-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool)</span></span>
<span id="cb1498-2"><a href="differentialprediction.html#cb1498-2" tabindex="-1"></a>model<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview, <span class="at">data=</span>DiffPred,</span>
<span id="cb1498-3"><a href="differentialprediction.html#cb1498-3" tabindex="-1"></a>              <span class="at">subset=</span>(race<span class="sc">==</span><span class="st">&quot;black&quot;</span> <span class="sc">|</span> race<span class="sc">==</span><span class="st">&quot;white&quot;</span>))</span>
<span id="cb1498-4"><a href="differentialprediction.html#cb1498-4" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perf_eval ~ c_interview, data = DiffPred, subset = (race == 
##     &quot;black&quot; | race == &quot;white&quot;))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.72580 -0.66775 -0.00208  0.74761  2.49792 
## 
## Coefficients:
##             Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)  4.71479    0.06817  69.164 &lt; 0.0000000000000002 ***
## c_interview  0.13983    0.05233   2.672              0.00813 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9895 on 210 degrees of freedom
## Multiple R-squared:  0.03288,    Adjusted R-squared:  0.02827 
## F-statistic: 7.139 on 1 and 210 DF,  p-value: 0.008133</code></pre>
<p>We should begin by noting that our effective sample size is now 212 (which we can compute by adding the number of degrees of freedom in our model, 212, to the number of parameters estimated, 2), whereas previously it was 370 when we included individuals of all races. The regression coefficient for <code>c_interview</code> is statistically significant and positive (<em>b</em> = .140, <em>p</em> = .008) based on this reduced sample of 212 individuals, which provides evidence of criterion-related validity. The amount of variance explained by <code>c_interview</code> in <code>perf_eval</code> is small in magnitude (<em>R</em><sup>2</sup> = .033, adjusted <em>R</em><sup>2</sup> = .028, <em>p</em> &lt; .001).</p>
<p><strong>Step Two:</strong> Regress the criterion variable <code>perf_eval</code> on the selection tool variable <code>c_interview</code> and the protected class variable <code>race</code>. In addition, do a nested model comparison, and estimate the change in <em>R</em><sup>2</sup>.</p>
<div class="sourceCode" id="cb1500"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1500-1"><a href="differentialprediction.html#cb1500-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool) and protected class (race)</span></span>
<span id="cb1500-2"><a href="differentialprediction.html#cb1500-2" tabindex="-1"></a>model<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">+</span> race, <span class="at">data=</span>DiffPred,</span>
<span id="cb1500-3"><a href="differentialprediction.html#cb1500-3" tabindex="-1"></a>              <span class="at">subset=</span>(race<span class="sc">==</span><span class="st">&quot;black&quot;</span> <span class="sc">|</span> race<span class="sc">==</span><span class="st">&quot;white&quot;</span>))</span>
<span id="cb1500-4"><a href="differentialprediction.html#cb1500-4" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perf_eval ~ c_interview + race, data = DiffPred, 
##     subset = (race == &quot;black&quot; | race == &quot;white&quot;))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.51207 -0.64712 -0.03035  0.65707  2.28188 
## 
## Coefficients:
##             Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)  4.91079    0.08941  54.922 &lt; 0.0000000000000002 ***
## c_interview  0.12665    0.05131   2.469              0.01437 *  
## racewhite   -0.44041    0.13398  -3.287              0.00119 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9671 on 209 degrees of freedom
## Multiple R-squared:  0.08042,    Adjusted R-squared:  0.07162 
## F-statistic: 9.139 on 2 and 209 DF,  p-value: 0.0001567</code></pre>
<div class="sourceCode" id="cb1502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1502-1"><a href="differentialprediction.html#cb1502-1" tabindex="-1"></a><span class="co"># Nested model comparison</span></span>
<span id="cb1502-2"><a href="differentialprediction.html#cb1502-2" tabindex="-1"></a><span class="fu">anova</span>(model<span class="fl">.1</span>, model<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: perf_eval ~ c_interview
## Model 2: perf_eval ~ c_interview + race
##   Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)   
## 1    210 205.60                                
## 2    209 195.49  1    10.107 10.806 0.001187 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb1504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1504-1"><a href="differentialprediction.html#cb1504-1" tabindex="-1"></a><span class="co"># Change in R-squared</span></span>
<span id="cb1504-2"><a href="differentialprediction.html#cb1504-2" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.2</span>)<span class="sc">$</span>r.squared <span class="sc">-</span> <span class="fu">summary</span>(model<span class="fl">.1</span>)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.04754406</code></pre>
<p>The regression coefficient associated with <code>race</code> (or more specifically <code>racewhite</code>) is negative and statistically significant (<em>b</em> = -.440, <em>p</em> = .001) when controlling for <code>c_interview</code>, which indicates that there is evidence of intercept differences. Because the coefficient is negative and because <code>white</code> is appended to the <code>race</code> variable name, it implies that the intercept value is significantly lower for White individuals compared to Black individuals. The amount of variance explained by <code>c_interview</code> <em>and</em> <code>race</code> in <code>perf_eval</code> is small-medium in magnitude (<em>R</em><sup>2</sup> = .080, adjusted <em>R</em><sup>2</sup> = .072, <em>p</em> &lt; .001). The significant <em>F</em>-value (10.806, <em>p</em> = .001) from the nested model comparison indicates that adding <code>race</code> significantly improved model fit, and because there was a significant improvement in model fit, we should interpret the change in <em>R</em><sup>2</sup> (<em>R</em><sup>2</sup> = .048), which indicates that adding <code>race</code> to the model explained an additional 4.8% of the variance in <code>perf_eval</code>.</p>
<p>Using the <code>probe_interaction</code> function from the <code>interactions</code> package, we will visualize the statistically significant intercept differences. As input to the <code>probe_interaction</code> function, use the the <code>model.2</code> model object from above, and specify the arguments in the <code>probe_interaction</code> function as you did before.</p>
<div class="sourceCode" id="cb1506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1506-1"><a href="differentialprediction.html#cb1506-1" tabindex="-1"></a><span class="co"># Visualize intercept differences</span></span>
<span id="cb1506-2"><a href="differentialprediction.html#cb1506-2" tabindex="-1"></a><span class="fu">probe_interaction</span>(model<span class="fl">.2</span>, </span>
<span id="cb1506-3"><a href="differentialprediction.html#cb1506-3" tabindex="-1"></a>                  <span class="at">pred=</span>c_interview, </span>
<span id="cb1506-4"><a href="differentialprediction.html#cb1506-4" tabindex="-1"></a>                  <span class="at">modx=</span>race,</span>
<span id="cb1506-5"><a href="differentialprediction.html#cb1506-5" tabindex="-1"></a>                  <span class="at">johnson_neyman=</span><span class="cn">FALSE</span>,</span>
<span id="cb1506-6"><a href="differentialprediction.html#cb1506-6" tabindex="-1"></a>                  <span class="at">x.label=</span><span class="st">&quot;Interview Score&quot;</span>,</span>
<span id="cb1506-7"><a href="differentialprediction.html#cb1506-7" tabindex="-1"></a>                  <span class="at">y.label=</span><span class="st">&quot;Job Performance&quot;</span>)</span></code></pre></div>
<pre><code>## SIMPLE SLOPES ANALYSIS 
## 
## Slope of c_interview when race = white: 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.13   0.05     2.47   0.01
## 
## Slope of c_interview when race = black: 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.13   0.05     2.47   0.01</code></pre>
<p><img src="R-for-HR_files/figure-html/unnamed-chunk-922-1.png" width="672" /></p>
<p><strong>Step Three:</strong> Finally, let’s add the interaction term between <code>c_interview</code> and <code>race</code> to the model using the <code>*</code> operator. In addition, do a nested model comparison, and estimate the change in <em>R</em><sup>2</sup>.</p>
<div class="sourceCode" id="cb1508"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1508-1"><a href="differentialprediction.html#cb1508-1" tabindex="-1"></a><span class="co"># Regress perf_eval (criterion) on c_interview (selection tool), protected class (race),</span></span>
<span id="cb1508-2"><a href="differentialprediction.html#cb1508-2" tabindex="-1"></a><span class="co"># and interaction between selection tool and protected class</span></span>
<span id="cb1508-3"><a href="differentialprediction.html#cb1508-3" tabindex="-1"></a>model<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">*</span> race, <span class="at">data=</span>DiffPred,</span>
<span id="cb1508-4"><a href="differentialprediction.html#cb1508-4" tabindex="-1"></a>              <span class="at">subset=</span>(race<span class="sc">==</span><span class="st">&quot;black&quot;</span> <span class="sc">|</span> race<span class="sc">==</span><span class="st">&quot;white&quot;</span>))</span>
<span id="cb1508-5"><a href="differentialprediction.html#cb1508-5" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = perf_eval ~ c_interview * race, data = DiffPred, 
##     subset = (race == &quot;black&quot; | race == &quot;white&quot;))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7314 -0.6396  0.0227  0.6637  2.4205 
## 
## Coefficients:
##                       Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)            4.91180    0.08886  55.275 &lt; 0.0000000000000002 ***
## c_interview            0.21843    0.07020   3.112             0.002122 ** 
## racewhite             -0.46345    0.13370  -3.466             0.000641 ***
## c_interview:racewhite -0.19428    0.10213  -1.902             0.058527 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9611 on 208 degrees of freedom
## Multiple R-squared:  0.09615,    Adjusted R-squared:  0.08311 
## F-statistic: 7.375 on 3 and 208 DF,  p-value: 0.0001015</code></pre>
<div class="sourceCode" id="cb1510"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1510-1"><a href="differentialprediction.html#cb1510-1" tabindex="-1"></a><span class="co"># Nested model comparison</span></span>
<span id="cb1510-2"><a href="differentialprediction.html#cb1510-2" tabindex="-1"></a><span class="fu">anova</span>(model<span class="fl">.2</span>, model<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: perf_eval ~ c_interview + race
## Model 2: perf_eval ~ c_interview * race
##   Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1    209 195.49                              
## 2    208 192.15  1    3.3426 3.6184 0.05853 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb1512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1512-1"><a href="differentialprediction.html#cb1512-1" tabindex="-1"></a><span class="co"># Change in R-squared</span></span>
<span id="cb1512-2"><a href="differentialprediction.html#cb1512-2" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.3</span>)<span class="sc">$</span>r.squared <span class="sc">-</span> <span class="fu">summary</span>(model<span class="fl">.2</span>)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.0157234</code></pre>
<p>The regression coefficient associated with the interaction term (<code>c_interview:racewhite</code>) is <em>not</em> statistically significant (<em>b</em> = -.194, <em>p</em> = .059), which indicates that there is no evidence of <em>slope differences</em>. Given this, we won’t probe the interaction because, well, there is not an interaction to probe. Further, adding the interaction term did not significantly improve model fit, so we won’t interpret change in <em>R</em><sup>2</sup>. Given all this, we won’t probe the interaction because, well, there is not an interaction to probe.</p>
<p>In sum, we found evidence of intercept differences for the selection tool <code>c_interview</code> in relation to the criterion <code>perf_eval</code> that were conditional upon the protected class variable <code>race</code>. Thus, it would be inappropriate to use a common regression line when predicting scores on the criterion based on the interview selection tool.</p>
</div>
</div>
<div id="apatable_mmlr" class="section level3 hasAnchor" number="42.3.4">
<h3><span class="header-section-number">42.3.4</span> APA-Style Results Table<a href="differentialprediction.html#apatable_mmlr" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you want to present the results of your moderated multiple linear regression (MMLR) model to a more statistically inclined audience, particularly an audience that prefers American Psychological Association (APA) style, consider using functions from the <code>apaTables</code> package <span class="citation">(<a href="#ref-R-apaTables">Stanley 2021</a>)</span>.</p>
<p>Using the <code>lm</code> function from base R, as we did above, let’s begin by estimating a MMLR model and naming the model object (<code>model.3</code>).</p>
<div class="sourceCode" id="cb1514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1514-1"><a href="differentialprediction.html#cb1514-1" tabindex="-1"></a><span class="co"># Estimate multiple linear regression model</span></span>
<span id="cb1514-2"><a href="differentialprediction.html#cb1514-2" tabindex="-1"></a>model<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(perf_eval <span class="sc">~</span> c_interview <span class="sc">*</span> gender, <span class="at">data=</span>DiffPred)</span></code></pre></div>
<p>If you haven’t already, install and access the <code>apaTables</code> package using the <code>install.packages</code> and <code>library</code> functions, respectively.</p>
<div class="sourceCode" id="cb1515"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1515-1"><a href="differentialprediction.html#cb1515-1" tabindex="-1"></a><span class="co"># Install package</span></span>
<span id="cb1515-2"><a href="differentialprediction.html#cb1515-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;apaTables&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1516"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1516-1"><a href="differentialprediction.html#cb1516-1" tabindex="-1"></a><span class="co"># Access package</span></span>
<span id="cb1516-2"><a href="differentialprediction.html#cb1516-2" tabindex="-1"></a><span class="fu">library</span>(apaTables)</span></code></pre></div>
<p>The <code>apa.reg.table</code> function from <code>apaTables</code> is pretty straightforward. Simply enter your regression model object (<code>model.3</code>) as the sole parenthetical argument. This will generate a table as output in your Console.</p>
<div class="sourceCode" id="cb1517"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1517-1"><a href="differentialprediction.html#cb1517-1" tabindex="-1"></a><span class="co"># Create APA-style regression table</span></span>
<span id="cb1517-2"><a href="differentialprediction.html#cb1517-2" tabindex="-1"></a><span class="fu">apa.reg.table</span>(model<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## 
## Regression results using perf_eval as the criterion
##  
## 
##                Predictor       b       b_95%_CI sr2  sr2_95%_CI             Fit
##              (Intercept)  4.56**   [4.41, 4.71]                                
##              c_interview  0.39**   [0.28, 0.51] .12  [.06, .19]                
##              genderwoman    0.15  [-0.06, 0.37] .01 [-.01, .02]                
##  c_interview:genderwoman -0.37** [-0.54, -0.21] .05  [.01, .10]                
##                                                                     R2 = .124**
##                                                                 95% CI[.06,.19]
##                                                                                
## 
## Note. A significant b-weight indicates the semi-partial correlation is also significant.
## b represents unstandardized regression weights. 
## sr2 represents the semi-partial correlation squared.
## Square brackets are used to enclose the lower and upper limits of a confidence interval.
## * indicates p &lt; .05. ** indicates p &lt; .01.
## </code></pre>
<p>If we add a <code>filename=</code> as a second argument, we can specify the name of a .doc file that we can write to our working directory. Here, I name the file “APA Multiple Linear Regression Table.doc”. The .doc file that appears in your working directory will be nicely formatted and include critical regression model results in an organized manner.</p>
<div class="sourceCode" id="cb1519"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1519-1"><a href="differentialprediction.html#cb1519-1" tabindex="-1"></a><span class="co"># Create APA-style regression table and write to working directory</span></span>
<span id="cb1519-2"><a href="differentialprediction.html#cb1519-2" tabindex="-1"></a><span class="fu">apa.reg.table</span>(model<span class="fl">.3</span>, <span class="at">filename=</span><span class="st">&quot;APA Moderated Multiple Linear Regression Table.doc&quot;</span>)</span></code></pre></div>
<pre><code>## 
## 
## Regression results using perf_eval as the criterion
##  
## 
##                Predictor       b       b_95%_CI sr2  sr2_95%_CI             Fit
##              (Intercept)  4.56**   [4.41, 4.71]                                
##              c_interview  0.39**   [0.28, 0.51] .12  [.06, .19]                
##              genderwoman    0.15  [-0.06, 0.37] .01 [-.01, .02]                
##  c_interview:genderwoman -0.37** [-0.54, -0.21] .05  [.01, .10]                
##                                                                     R2 = .124**
##                                                                 95% CI[.06,.19]
##                                                                                
## 
## Note. A significant b-weight indicates the semi-partial correlation is also significant.
## b represents unstandardized regression weights. 
## sr2 represents the semi-partial correlation squared.
## Square brackets are used to enclose the lower and upper limits of a confidence interval.
## * indicates p &lt; .05. ** indicates p &lt; .01.
## </code></pre>
<div class="float">
<img src="apa_mmlr_table.png" alt="The apa.reg.table function from the apaTables package can table moderated multiple linear regression model results in a manner that is consistent with the American Psychological Association (APA) style guide. APA-style tables are useful when presenting to academic audiences or audiences with high levels of technical/statistical expertise." />
<div class="figcaption">The apa.reg.table function from the apaTables package can table moderated multiple linear regression model results in a manner that is consistent with the American Psychological Association (APA) style guide. APA-style tables are useful when presenting to academic audiences or audiences with high levels of technical/statistical expertise.</div>
</div>

</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-aguinis1998heterogeneity" class="csl-entry">
Aguinis, Herman, and Charles A Pierce. 1998. <span>“Heterogeneity of Error Variance and the Assessment of Moderating Effects of Categorical Variables: A Conceptual Review.”</span> <em>Organizational Research Methods</em> 1 (3): 296–314.
</div>
<div id="ref-berry2015differential" class="csl-entry">
Berry, Christopher M. 2015. <span>“Differential Validity and Differential Prediction of Cognitive Ability Tests: Understanding Test Bias in the Employment Context.”</span> <em>Annuual Review of Organizational Psychology and Organizational Behavior</em> 2 (1): 435–63.
</div>
<div id="ref-cascio2005applied" class="csl-entry">
Cascio, Wayne F, and Herman Aguinis. 2005. <em>Applied Psychology in Human Resource Management (6th Ed.)</em>. Upper Saddle River, NJ: Pearson Prentice Hall.
</div>
<div id="ref-cleary1968test" class="csl-entry">
Cleary, T Anne. 1968. <span>“Test Bias: Prediction of Grades of Black and White Students in Integrated Colleges.”</span> <em>Journal of Educational Measurement</em> 5 (2): 115–24.
</div>
<div id="ref-fisher2017age" class="csl-entry">
Fisher, Gwenith G, Donald M Truxillo, Lisa M Finkelstein, and Lauren E Wallace. 2017. <span>“Age Discrimination: Potential for Adverse Impact and Differential Prediction Related to Age.”</span> <em>Human Resource Management Review</em> 27 (2): 316–27.
</div>
<div id="ref-R-lessR" class="csl-entry">
Gerbing, David, The School of Business, and Portland State University. 2021. <em><span class="nocase">lessR</span>: Less Code, More Results</em>. <a href="https://CRAN.R-project.org/package=lessR">https://CRAN.R-project.org/package=lessR</a>.
</div>
<div id="ref-interactions" class="csl-entry">
Long, Jacob A. 2019. <em>Interactions: Comprehensive, User-Friendly Toolkit for Probing Interactions</em>. <a href="https://cran.r-project.org/package=interactions">https://cran.r-project.org/package=interactions</a>.
</div>
<div id="ref-saad2002investigating" class="csl-entry">
Saad, Syed, and Paul R Sackett. 2002. <span>“Investigating Differential Prediction by Gender in Employment-Oriented Personality Measures.”</span> <em>Journal of Applied Psychology</em> 87 (4): 667–74.
</div>
<div id="ref-siop2018" class="csl-entry">
Society for Industrial &amp; Organizational Psychology. 2018. <em>Principles for the Validation and Use of Personnel Selection Procedures (5th Ed.)</em>. Bowling Green, OH: Pearson Prentice Hall.
</div>
<div id="ref-R-apaTables" class="csl-entry">
Stanley, David. 2021. <em><span class="nocase">apaTables</span>: Create American Psychological Association (APA) Style Tables</em>. <a href="https://CRAN.R-project.org/package=apaTables">https://CRAN.R-project.org/package=apaTables</a>.
</div>
<div id="ref-stone1994type" class="csl-entry">
Stone-Romero, Eugene F, George M Alliger, and Herman Aguinis. 1994. <span>“Type II Error Problems in the Use of Moderated Multiple Regression for the Detection of Moderating Effects of Dichotomous Variables.”</span> <em>Journal of Management</em> 20 (1): 167–78.
</div>
<div id="ref-R-readr" class="csl-entry">
Wickham, Hadley, Jim Hester, and Jennifer Bryan. 2024. <em>Readr: Read Rectangular Text Data</em>. <a href="https://CRAN.R-project.org/package=readr">https://CRAN.R-project.org/package=readr</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiplecutoff.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="crossvalidation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["R for HR.pdf", "R for HR.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
