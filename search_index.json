[["index.html", "Preface 0.1 Growth of HR Analytics 0.2 Skills Gap 0.3 Project Life Cycle Perspective 0.4 My Philosophy for This Book 0.5 About the Author 0.6 Acknowledgements", " R for HR: An Introduction to Human Resource Analytics Using R BOOK UNDER CONSTRUCTION David E. Caughlin 2021-04-20 Preface This book is free to read and is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. The contents of this book may not be used for commercial purposes. [NOTE: This book is currently under construction, and I anticipate that I will complete a full beta version by July 2021.] 0.1 Growth of HR Analytics The term human resource analytics can mean different things to different people and to different organizations. Further, human resource analytics sometimes goes by other names like people analytics, talent analytics, workforce analytics, and human capital analytics. While some may argue for distinctions between these different names, for this book, I will treat them as interchangeable labels. Moreover, for the purposes of this book, human resource (HR) analytics is defined as the process of collecting, analyzing, interpreting, and reporting people-related data for the purpose of improving decision making, achieving strategic objectives, and sustaining a competitive advantage (Bauer et al. 2020, 34). The foundation of HR analytics formed over a century ago with the emergence of disciplines like industrial and organizational (I/O) psychology. In recent decades, advances in information technology and systems have reduced the time HR professionals spend on transactional and administrative activities, thereby creating more time and opportunity for transformational activities supporting the realization of strategic organizational objectives. HR analytics has the potential to play an integral role in such transformational activities, as it can inform HR system design (e.g., selection tool selection, validation, and process) and high-stakes decision making involving people-related data from the organization. A 2018 survey of companies highlighted the perceived importance of HR analytics but a relative lack of readiness to adopt and integrate HR analytics (Deloitte 2018). 0.2 Skills Gap Although many organizations regard HR analytics as strategically important for organizational success, today many of those same organizations face an HR analytics talent shortage. To some extent, the talent shortage can be attributed to data literacy  or the lack thereof. Historically, academic and professional HR training and development opportunities did not emphasize data-literacy skills, and this omission has left organizations today scrambling to hire external talent or to close the skills gap of existing HR professionals. To address the HR analytics talent shortage and skills gap, organizations have, broadly speaking, two options. First, for some organizations, closing the skills gap may be as straightforward as hiring a quant (e.g., data scientist, statistician), provided the individual works closely with HR professionals when working with data associated with HR systems, polices, and procedures, and identifying HR-specific legal and ethical issues. Second, I would argue that for most organizations perhaps a better alternative is to close the skills gap with among current HR professionals, as their HR-specific knowledge, skills, abilities, and other characteristics (KSAOs) offer tremendous value when deriving insights from HR data as well as a solid domain-specific foundation for subsequently layering on data-literacy KSAOs. Importantly, those with existing HR domain expertise presumably have working knowledge of prevailing employment and labor laws and experience with anticipating and uncovering ethical issues, both of which are necessary when acquiring, managing, analyzing, visualizing, and reporting HR data. At the most basic level, proficiency in HR analytics involves the integration of knowledge, skills, abilities, and other characteristics (KSAOs) associated with HR expertise and data literacy. 0.3 Project Life Cycle Perspective When building efficacy in HR analytics, I have found that its helpful to envision where and how contributions can be made at the project level and which specific KSAOs are required at each phase. To that end, I developed the HR Analytics Project Life Cycle (HRAPLC) as a way to conceptualize the prototypical phases of a generic project life cycle. These phases include: Question Formulation, Data Acquisition, Data Management, Data Analysis, Data Interpretation and Storytelling, and Deployment and Implementation. I dedicate Part 1 of this book to providing a conceptual overview of the HRPLC in Chapters 1-7. The Human Resource Analytics Project Life Cycle (HRAPLC) offers a way to conceptualize the prototypical phases of a generic HR analytics project life cycle. 0.4 My Philosophy for This Book Working with data does not need to be scary or intimidating; yet, over the years, I have interacted with students and professionals who carry with them what I refer to as a numerical phobia or quantitative trauma. Unfortunately, at some point in their lives, some people begin to believe that they are not suited for mathematics, statistics, and/or generally working with data. Given these psychological barriers, a primary objective of this book is to make data analytics  and HR analytics specifically  relevant, accessible, and maybe even a little fun. In early chapters, my intention is to ease the reader into foundational concepts, applications, and tools in order to incrementally build self-efficacy in HR analytics. The tutorials in each chapter are grounded in common and meaningful HR contexts (e.g., validating employee selection tools). As the book progresses, more challenging statistical concepts and data-analytic techniques are introduced. Reading this book and following along with the in-chapter tutorials will not lead to expert-level knowledge and skill; however, my hope is that completing all or portions of this book will do the following: Build excitement for working with data to inform decision making. Instill a sense of intellectual curiosity about data and a hunger to expand boundaries of expertise. Inspire further in-depth training, education, and learning in areas and topics introduced in this book. Enhance data literacy, including knowledge and skills related to (a) critical thinking and logic, (b) mathematics, statistics, and data analysis, and (c) data visualization and storytelling with data. 0.4.1 Rationale for Using R Today, we have the potential to access and use a remarkable number of statistical and data-analytic tools. Examples of such tools include (in no particular order) R, Python, SPSS, SAS, Stata, MatLab, Mplus, Alteryx, Tableau, PowerBI, and Microsoft Excel. Notably, some of these programs can be quite expensive when it comes to lifetime or annual user licensing costs, which can be a barrier to access for many. Programming languages like R and Python have several desirable qualities when it comes to managing, analyzing, and visualizing data. Namely, both are free to use, and both have an ever-growing number of free (add-on) packages with domain- or area-specific functions (e.g., data visualizations). It is beyond the scope of this Preface to provide an exhaustive comparison of the relative merits of R versus Python; however, when it comes to the statistical analysis of data, specifically, I argue that R provides a more user-friendly entry point for beginners as well as more advanced capabilities desired by expert users, especially for ad-hoc analyses. Moreover, the integrated development environment program called RStudio (which sits on top of\" base R) offers useful workflow tools and generally makes for an inviting environment within which the R engine to run. With all that said, Python has been catching up in these regards, and I wouldnt be surprised if Python closes these gaps relative to R in the next few years. I would be remiss if I didnt mention that the Python language is powerful and has capabilities that extend far beyond the management, analysis, and visualization of data. Fortunately, learning R makes learning Python easier (and vice versa), which means that this book can serve as springboard for learning Python or other programming languages. Finally, I believe it to be unlikely that one tool (e.g., program, language) will emerge that is ideal for every task, and thus, I encourage you to build familiarity with multiple tools so that you develop a toolbox of sorts, thereby allowing you to choose the best (or at least better) tool for each task. 0.4.2 Audience I have written this book with current or soon-to-be HR professionals in mind, particularly those who have an interest in upskilling their data-analytic knowledge and skills. With that said, I believe this book can provide a meaningful context for learning key data-analytic concepts, applications, and tools that are applicable beyond the HR context. Relatedly, this book may serve as a gateway to a user-friendly introduction to the programming language called R. 0.4.3 Structure This under-construction version of the book consists of the following parts: Overview of HR Analytics Project Life Cycle: The first chapter in this part describes the HRAPLC in general, and the chapters that follow cover the specific phases of the HRAPLC. Introduction to R: The chapters in this part introduce the R programming language. This part also focuses on how to install and get started with R and RStudio, including a gentle introduction to foundational concepts and operations associated with the R language. Data Acquisition &amp; Management: The chapters in this part focus primarily on how to bring acquired data into the R environment, how to export data from the R environment, and additional techniques and tools necessary for arranging (sorting), joining (merging), manipulating (wrangling), aggregating, and cleaning data. Data Acquisition and Data Management are key phases of the HR Analytics Project Life Cycle. Chapter Supplements: The chapters in this section expand upon the concepts and techniques covered in specific chapters, often by demonstrating alternative methods for achieving the same end. 0.5 About the Author David Caughlin works for Portland State Universitys School of Business where he engages in research and teaching on topics related to organizational behavior, human resource management, and data analytics. David received his B.S. in psychology and B.A. in Spanish from Indiana University, his M.S. in industrial &amp; organizational psychology from Indiana University - Purdue University at Indianapolis, and his Ph.D. in industrial and organizational psychology from Portland State University with concentrations in quantitative methodology and occupational health psychology. His research interests are generally focused on supervisor support, work motivation, and occupational safety and health. His research has been published in peer-reviewed outlets such as Journal of Applied Psychology, Journal of Management, Human Resource Management, Journal of Occupational Health Psychology, and Psychology, Public Policy, and the Law. He co-authored the textbooks Human Resource Management: People, Data, and Analytics and Fundamentals of Human Resource Management: People, Data, and Analytics. In the School of Business, David teaches undergraduate and graduate courses on topics related to human resource management, information systems, and data analytics. In his HR analytics courses, David teaches students how to apply the statistical programming language R to manage, analyze, and visualize HR data to improve strategic decision making; in the process, students build their data literacy and develop their critical-thinking and reasoning skills. He has received the following teaching awards from the School of Business: Teaching Innovation Award (2018), Extra Mile Teaching Excellence Award (2019), and Teaching Innovation Award (2020). In his free time, David enjoys outdoor activities like trail running, skiing, mountain biking, and paddle boarding. 0.6 Acknowledgements My inspiration for writing and compiling the contents of this book stems from interactions with countless colleagues, professional acquaintances, and undergraduate and graduate students, and a broad thank you is in order for anyone with whom I have taught or had a conversation about HR analytics specifically or data analytics in general. Finally, I created this book using the following programs and packages: R (R Core Team 2021), RStudio (RStudio Team 2020), rmarkdown (Xie, Allaire, and Grolemund 2018; Allaire et al. 2021), knitr (Xie 2015, 2014, 2021), and bookdown (Xie 2016, 2020). "],["overviewhraplc.html", "Chapter 1 Overview of HR Analytics Project Life Cycle", " Chapter 1 Overview of HR Analytics Project Life Cycle The Human Resource Analytics Project Life Cycle (HRAPLC) offers a framework for conceptualizing the prototypical phases of a generic project life cycle. When learning how to apply HR analytics, Ive found that its helpful to envision where and how contributions can be made at the project level and which specific knowledge, skills, abilities, and other characteristics (KSAOs) are required at each phase of a project. The HRAPLC phases are as follows. Question Formulation: process of identifying and posing strategy-inspired and -aligned problems and/or questions that can be solved or answered using data. Data Acquisition: process of collecting, retrieving, gathering, and sourcing data that can be used to solve problems and answer questions. Data Management: process of wrangling, cleaning, manipulating, and structuring data. Data Analysis: process of applying mathematical, statistical, and/or computational analyses to data to identify associations, differences, changes, or classes, as well as to predict the likelihood of future events, values, differences, or changes. Data Interpretation and Storytelling: process of making sense of data-analysis findings in the context of the focal problem and/or question, and of disseminating and communicating the findings to different stakeholders. Deployment and Implementation: process of prescribing or taking action based on interpretation of data-analysis findings. The HR Analytics Project Life Cycle (HRAPLC) offers a way to conceptualize the prototypical phases of a generic HR analytics project life cycle. Notably, the phases of the HRAPLC generally align with the steps of the classic scientific process, which include formulating a hypothesis, designing a study, collecting data, analyzing data, and reporting findings. This similarity underscores how HR analytics is consistent with a scientific approach to HR management. and, more generally, to an empirical approach aimed at uncovering truth based on data. Like the scientific process, the HRAPLC is predicated on empiricism, which means truth comes from data. That is, the engine of the HRAPLC runs on data, and these data serve as evidence on which we build knowledge and glean insights. The phases of the HR Analytics Project Life Cycle (HRAPLC) generally align with the classic steps of the scientific process. In the following six chapters, I provide a detailed conceptual overview of each HRAPLC phase, beginning with Question Formulation. "],["questionformulation.html", "Chapter 2 Question Formulation 2.1 Adopting a Strategic Mindset 2.2 Defining Problems &amp; Formulating Questions 2.3 Conclusion", " Chapter 2 Question Formulation The first phase of the HR Analytics Project Life Cycle (HRAPLC) is Question Formulation. Question formulation refers to the process of posing strategy-inspired and -aligned questions or hypotheses (that can be answered using data) in order to investigate why or how a problem occurs, what a problem might lead to or be associated with, or who is affected by the problem. Thoughtful question formulation results in (a) more effective and efficient data acquisition, management, and analysis, and (b) answers that are more useful to stakeholders. Question formulation is closely associated with problem definition, which refers to the process of framing and diagnosing a problem (e.g., challenge, opportunity, threat) for which finding a solution will bring value. The Question Formulation phase of the HR Analytics Project Life Cycle (HRAPLC) involves defining problems and formulating questions. 2.1 Adopting a Strategic Mindset When our goal is to improve the organization and the employee experience, adopting a strategic mindset sets us up for defining the right problems and formulating the right questions. A strategic mindset involves: Familiarity with strategic goals and roles, which requires recognizing and understanding strategic objects of the department and the organization, and the roles that key decision makers and stakeholders play. Understanding of organization systems, which requires the application of systems thinking when defining problems and formulating questions. Focus on opportunities for innovation, which requires thinking broadly and openly prior to narrowing focus. Application of (intellectual) curiosity, which entails asking why, why not, and how type questions. Before defining a problem and formulating a question, it is important to adopt a strategic mindset and to engage in divergent and convergent thinking processes. 2.1.1 Strategy Because adopting a strategy necessitates and understanding of strategy, lets take a moment to review the concept of a strategy. Simply put, a strategy refers to a well-devised and thoughtful plan for achieving an objective (Bauer et al. 2019, 35). Notably, a strategy is future oriented and provides a roadmap towards completion of a desired objective. Moreover, realizing a strategy requires coordinating business activities to achieve both short- and long-term objectives. When creating a new strategy, we often focus on two distinguishable phases: (a) strategy formulation and (b) strategy implementation. 2.1.2 Strategy Formulation Strategy formulation involves planning what to do to achieve organizational objectives  or in other words, the development and/or refinement of a strategy (Bauer et al. 2019, 3536). The prototypical strategy formulation often includes the following steps: Creating a mission statement, articulating a vision, and defining core values. The mission, vision, and values can serve as a compass by guiding organizational actions in the direction of a desired future state and by providing parameters and guidelines for reaching that future state. Analyzing the internal and external environments. Decision-making tools like a SWOT (strengths, weaknesses, opportunities, threats) analysis provide frameworks for understanding and describing the characteristics that are internal to the organization (e.g., employees) and characteristics that are external to the organization (e.g., labor market). Selecting a broad type of strategy. The type of strategy refers to the general approach an organization takes when bringing the mission, vision, and values to life, such as differentiation or cost leadership. Defining specific strategic objectives aimed at satisfying relevant stakeholders. This involves considering the needs of key stakeholders (e.g., customers, investors, shareholders, employees, broader communities) and considering what will result in a sustainable competitive advantage. Finalizing and temporarily crystallizing the strategy prior to strategy implementation. This step often results in a clear strategic plan that summarizes the previous four steps. 2.1.3 Strategy Implementation Once weve completed the strategy formulation phase, were ready to move onto strategy implementation, where strategy implementation refers to the process of following through on the strategic plan developed and/or refined during the strategy formulation phase (Bauer et al. 2019). This phase involves building and leveraging the organizations human capital capabilities in order to enact and realize the strategic plan, and aligning HR policies and practices with the strategic plan. For example, if a strategic objective outlined in the strategic plan requires acquiring, managing, or retaining the best software engineers, then the organization should focus on how HR systems like recruitment, selection, performance management, and reward systems can help support that requirement. 2.1.4 Strategic Human Resource Management When HR management aligns with and supports the realization of organizational strategic objects, strategic human resource management emerges. In other words, strategic human resource management involves a strategy-oriented approach to human resource management. While most specific HR policies and practices will vary across organizations, there are practices that are generally strategically relevant for all organizations, and examples include selectively hiring new employees to ensure sufficiently high qualifications and good fit, and training employees to enhance job- and work-relevant knowledge, skills, abilities, and other characteristics (KSAOs) (Pfeffer 1998). 2.1.4.1 Video Lecture Link to video lecture: https://youtu.be/08whYkgFiQI 2.2 Defining Problems &amp; Formulating Questions The overarching purpose of the Question Formulation phase of the HRAPLC is to define problems and formulate questions for which solutions and answers, respectively, can improve the organization and push it towards its goals. In the sections that follow, we will focus on the processes of problem definition and question formulation, and ultimately learn the value of applying both divergent and convergent thinking during both of these processes. 2.2.1 Defining a Problem With a departments and/or organizations strategy in mind, were ready to define an organizationally relevant problem in need of a solution. While we typically know a problem when we see one, I found its helpful to take a step back and think about what a problem actual is. For our purposes, we can think of a problem as a gap between the current state of affairs and a desired state of affairs. Given that, problem definition refers to the process of framing and diagnosing a problem (e.g., challenge, opportunity, threat) for which finding a solution will be of value. As shown below, key problem definition components often include articulating the problem statement, decision makers and stakeholders, scope, and goals (Chevallier 2016; Conn and McLean 2018). A fully formed problem definition often involves articulating key problem definition components, such as articulating the problem statement, decision makers and stakeholders, scope, and goals. Articulating the problem definition components is appropriate for most problems, including those specific to HR, such as the one in this example. 2.2.2 Formulating a Question Once a general problem has been defined, were ready to begin question formulation, which refers to the process of posing a question or hypothesis to investigate why or how a problem occurs, what a problem might lead to or be associated with, or who is affected by the problem. Question formulation can even help us flesh out the typical problem definition components outlined in the previous section. Just as we did with problem definition, we should continue to apply our strategic mindset when formulating questions. Moreover, we should focus on posing questions for which finding answers hold value for the organization, as doing so can contribute to the following (for example): a better understanding of the focal problem, the identification of potential solutions to the focal problem, solutions that meet the needs of key decision makers and stakeholders, more efficient and targeted literature searches and reviews, and more effective and focused storytelling. So what is a question in this context? A question can be described as general line of inquiry regarding a problem or phenomenon of interest. Examples of questions are as follows. What factors influence voluntary turnover? Does engagement predict voluntary turnover? How does engagement relate to voluntary turnover? Which work characteristics predict voluntary turnover? Why do new employees turn over in the first 6 months? If, based on prior research or theory, an informed prediction can be made, we might choose to restate a question a s hypothesis, where a hypothesis can be thought of as a statement about an expected association, difference, change, or classification. Examples of hypotheses are as follows. Engagement is negatively related to voluntary turnover. Turnover intention mediates the relationship between engagement and voluntary turnover. Autonomy and task significance negatively predict voluntary turnover. New employees who participate in the formal onboarding program are less likely to quit during their first 6 months. Regardless of whether we pose a question or state a hypothesis, its important to remember that question formulation is often an iterative process, which means that answering one question (or testing one hypothesis) often leads to additional questions (or hypotheses). Question formulation is often an iterative process, meaning that answering one question (or testing hypothesis) often leads to additional questions (or hypotheses). Further, we can draw upon existing theory and research to inform the types of questions we pose (or hypotheses we state). A theory provides a way to understand or explain a phenomenon of interest in parsimonious manner. As an example, the theory of planned behavior (Ajzen 1991) is based on a voluminous body of research, and in simplified forms, the basic tenets of the theory are as follows. First, an individuals attitude towards a behavior, perception of the norms associated with the behavior, and sense of control over enacting a behavior contribute to their intention to perform a behavior. Second, an individuals intention to perform a behavior often leads them to perform a behavior. This theory can be applied to any number of behaviors. Given that HR professionals (and organizational leadership) are often concerned with voluntary turnover (i.e., an employee-initiated organizational separation), lets focus on voluntary turnover. Using the theoretical tenets, we can reason that an individuals voluntary turnover behavior might be explained by their attitudes, norms, and sense of control related to voluntary turnover, and ultimately to their intentions to turn over voluntarily. Thus, based on the theory of planned behavior, we might first focus on the proposed link between attitudes and behavioral intention, and formulate the following question: Are more positive attitudes towards leaving the organization associated with a stronger intention to voluntarily turn over? Further, by focusing on the proposed link between behavioral intention and actually enacting the behavior, we might hypothesize the following: Stronger turnover intention is associated with a higher probability of quitting. Existing theories, such as the theory of planned behavior (Azjen, 1991) can be used to inform and direct the types of questions or hypotheses that are posed during question formulation. 2.2.3 Thinking Divergently &amp; Convergently Throughout the processes of defining a problem and formulating a question, it is advisable to apply both divergent and convergent thinking. On the one hand, divergent thinking refers to the process of adopting a broadened and imaginative mindset in which many ideas, possibilities, and alternatives are considered, which can lead to a large quantity of creative or novel ideas; on the other hand, convergent thinking refers to the process of adopting a critical and evaluative mindset in which various alternatives are judged, which can lead to a more refined set of high-quality ideas (Basadur, Graen, and Scandura 1986; Basadur, Runco, and Vega 2000; Reiter-Palmon and Illies 2004). When used effectively, these two ways of thinking can improve problem definition and question formulation. More specifically, once we have adopted a strategic mindset, the identification, framing, and defining of problems should involve: (a) a phase of ideation with divergent thinking, such that many potential ideas, possibilities, and ultimately problems are entertained and considered - with the primary focus being on novelty, creativity, and quantity; and (b) a phase with deliberate convergent thinking, such that the list of potential problems generated during the previous phase is winnowed to those that will contribute the most to the organizations strategic goals, ends, or initiatives. A similar two-phase process can be applied when formulating questions. 2.2.3.1 Video Lecture Link to video lecture: https://youtu.be/w1104yS-zJU 2.3 Conclusion In this chapter, we did a conceptual deep dive into the Question Formulation phase of the HR Analytics Project Life Cycle. In doing so, we reviewed the importance of adopting a strategic mindset, and then engaging in thoughtful problem definition and question formulation. Finally, we learned how a two-phase process of deliberate divergent and convergent thinking can help us identify the most important problems and questions for which solutions and answers, respectively, would provide the most value to the organization. "],["dataacquisition.html", "Chapter 3 Data Acquisition 3.1 Employee Surveys 3.2 Rating Forms 3.3 Surveillance &amp; Monitoring 3.4 Database Queries 3.5 Scraping", " Chapter 3 Data Acquisition Data acquisition refers to the process of collecting, retrieving, gathering, and sourcing data that can be used to solve problems, answer questions, and test hypotheses that were identified during the Question Formulation phase of the HR Analytics Project Life Cycle. Various tools can be used for data acquisition, such as employee surveys, (performance) rating forms, surveillance and monitoring, database queries, and scraping or crawling. In some instances, the required data may already reside in an HR information system (HRIS) or enterprise resource planning (ERP) platform, and such data are often referred to as archival. From ethical, legal, and practical perspectives, my general advice is to acquire data with a purpose. That is, if we dont have a compelling and well-thought-out rationale to collect certain data  especially data about people  then we should probably should resist collecting such data. The Data Acquisition phase of the Human Resource Analytics Project Life Cycle (HRAPLC) involves gathering the data necessary for solving the problem or answering the question from the Question Formulation phase. 3.1 Employee Surveys When it comes to acquiring data about employee attitudes, behaviors, and feelings, the employee survey is perhaps one of the most common (if not the most common) tools. If youre unfamiliar with employee surveys, simply put, they consist of some number of items (e.g., questions) to which employees are asked to respond. Survey items can be open-ended (e.g., Please describe our onboarding experience.) or close-ended with fixed response options (e.g., I am satisfied with my job. [1 = Strongly Disagree, 5 = Strongly Agree]), and they can vary in length, ranging from shorter yet more frequent pulse surveys to longer yet less frequent annual engagement surveys. Further, surveys can be used to deploy multi-item measures of multi-faceted and nuanced concepts (i.e., constructs) such as engagement and organizational citizenship behaviors. The quality of the data acquired using an employee survey depends largely on the quality of the survey content (e.g., quality of item writing), the appropriateness of the survey for the target population, and respondents motivation (or lack thereof) for taking the survey. To learn more about writing high-quality items, avoiding common pitfalls, and other design and administration considerations, I recommend checking out the Google re:Work guide for developing and administering employee surveys (https://rework.withgoogle.com/guides/analytics-run-an-employee-survey), as it distills many best practices into a user-friendly and efficient format. Below, I list some potential advantages and disadvantages of using employee surveys for data acquisition. Advantages: If designed well, they can be efficient and effective tools for acquiring self- or observer-report data on employee personality, attitudes, individual differences, and behaviors as well as perceptions of work, working environment, work-family interface, supervisor behavior, coworker behavior, and client behavior. They tend to be relatively affordable to administer and a variety of platforms exist today to facilitate this process (e.g., Qualtrics, SurveyMonkey). Employees are typically familiar with the concept of a survey and can exert more control over the information that is collected. Disadvantages: Some may argue that the date acquired may be more subjective in nature than the data acquired by other tools, as respondents may succumb to perceived social desirability pressures and/or fake or distort their responses. They can be time-consuming and resource-intensive to respond to and to develop. If surveyed too frequently, employees may experience survey fatigue. 3.2 Rating Forms Rating forms often share some of the same characteristics as employee surveys (e.g, multiple close-ended items) but tend to be more focused on measuring work-related behaviors and job performance. Examples of common types of ratings forms include the behavioral observation scale and the behavioral-anchored rating scale. Given the breadth of the performance domain for most jobs, when targeting performance, ratings forms tend to consist of multiple items or dimensions. For example, the performance domain for the prototypical customer service representative job will involve interacting with customers but will likely also involve administrative tasks, for example, involving the documentation of customer complaints. Below, I offer some advantages and disadvantages of using ratings forms for data acquisition. Advantages: If designed well, they allow raters to produce data efficiently. They can offer a standardized and consistent format that ultimately results in cleaner and more structured data than using no rating form at all to collect the same data. Disadvantages: Achieving sufficiently high reliability across raters can be challenging, even when they are using the same rating form. Some types of ratings forms likely the behavioral-anchored rating scale can be very time-consuming and resource-intensive to develop. Ratings may be influenced by office politics and idiosyncratic rater motivations (e.g., I scored this person lower than they deserved to send a message.) 3.3 Surveillance &amp; Monitoring Surveillance and monitoring offer a more discrete and less obtrusive approach to data acquisition. Examples include tracking system login information (e.g., dates, times), recording video or audio of employees, examining email correspondence, and deploying sensors and other wearable technologies (e.g., sociometric badges). Below, I offer some advantages and disadvantages of using surveillance and monitoring to acquire data. Advantages: They tend to be nonintrusive and operate behind the scenes which can lead to the acquisition of more realistic and authentic employee behavior. Technological advances continue to expand surveillance and monitoring capabilities, such as those designed to measure geolocation, tone of voice, interactions, heart rate, sleep quantity and quality, and exposure to noxious chemicals. Disadvantages: Without clear and transparent communication regarding the use of such tools, employees may perceive a violation of trust. The technologies behind many surveillance and monitoring tools can produce truly big data (e.g., high velocity, massive amounts, unstructured) which can make wrangling and managing the data challenging and time-consuming. Employees may have ethical and privacy concerns about these tools, including about how they data are going to be used by the organization and how they are going to be protected. 3.4 Database Queries When acquiring data that already reside in an information system or enterprise resource planning platform, a database query is often the tool of choice, where A a database query refers to an action in which a request is made to access, acquire, restructure, and/or manipulate data housed in a database. Structured query language (SQL) is an example of a language that is commonly used to access data from a relational database. In many instances, the data retrieved from a database via a query meet the definition of archival data. Below, I offer some potential advantages and disadvantages of using database queries to acquire data. Advantages: They can be an efficient way to gather archival data already residing in an information system or enterprise resource planning platform. They provide an opportunity to leverage data that an organization acquired previously. Disadvantages: Just because data reside in a database does not necessarily mean they are of high quality or are trustworthy. Unless carefully documented, important characteristics and definitions regarding the data residing in a database may be challenging to locate, which means even when queried, the definition and purpose of certain fields (i.e., variables) may remain unclear. 3.5 Scraping Scraping refers to the process of extracting data from websites, documents, and other sources of information. In many cases, we use scraping to gather data that were not originally intended to be used in the way that we plan to use them. For example, to predict changes in the stock market, an analyst might scraped tweets from Twitter over some period of time, use text analysis to code their sentiment, and then correlation tweet sentiment with market performance indicators. Scraping might also be applied to emails, internal company chat applications, and even electronic documents like applicant resumes. Below, I suggest some potential advantages and disadvantages of using scraping as a data-acquisition tool. Advantages: New scraping tools and R packages have made it easier than ever to scrape data. Scraping tools can offer new insights based on previously difficult-to-reach or difficult-to-acquire text data that are rich with contextual information. Disadvantages: Scraping data that arent public or that werent intended to be used in the manner we plan to use them, can raise ethical and privacy concerns. Once scraped, the data often need to be structured into a format for subsequent, which can be a labor-intensive and exhausting process in terms of effort and time. "],["datamanagement.html", "Chapter 4 Data Management", " Chapter 4 Data Management Data management refers to the process of wrangling, cleaning, manipulating, and structuring data. Different tools can be used for data management, such as database management systems and data analysis software programs. The general rule of thumb is that you can expect to spend 80% of your time managing data and about 20% of your time analyzing data. The Data Management phase of the Human Resource Analytics Project Life Cycle (HRAPLC) involves wrangling, cleaning, manipulating, and structuring the data gathered during the Data Acquisition phase. XXXX By default, different spellings and cases (e.g., Beaverton, beverton, beaverton) for what is supposed to be the same category (e.g., Beaverton) will be treated as separate categories by many programs. XXXX XXXX. XXXX XXXX. XXXX XXXX. "],["dataanalysis.html", "Chapter 5 Data Analysis", " Chapter 5 Data Analysis Data analysis refers to the process of applying mathematical, statistical, and/or computational techniques to data to identify associations, differences or changes, or classes (categories), as well as to predict the likelihood of future events, values, or differences or changes. Various tools used in data analysis, such as mathematics, statistics, simulations, and computational modeling. "],["datainterpretationstorytelling.html", "Chapter 6 Data Interpretation &amp; Storytelling", " Chapter 6 Data Interpretation &amp; Storytelling Data interpretation and storytelling refers to the process of making sense of data analysis findings and evaluating questions and hypotheses, as well as disseminating the findings to different stakeholders. To support interpretation and storytelling, data visualization is frequently used (e.g., graphs, charts, plots). "],["deploymentimplementation.html", "Chapter 7 Deployment &amp; Implementation", " Chapter 7 Deployment &amp; Implementation Deployment and implementation refers to the process of prescribing or taking action based on interpretation of data-analysis findings. This phase requires an (a) understanding of stakeholder needs, (b) an understanding of the business context, and (c) knowledge of change management theories and practices. "],["overviewR.html", "Chapter 8 Overview of R &amp; RStudio", " Chapter 8 Overview of R &amp; RStudio XXXX "],["install.html", "Chapter 9 Installing R &amp; RStudio 9.1 Downloading &amp; Installing R 9.2 Downloading &amp; Installing RStudio 9.3 Summary", " Chapter 9 Installing R &amp; RStudio If you have a Windows, Mac, or Linux operating system, you have several ways in which you can begin working in R. Commonly, users install R on their computer along with an integrated development environment (IDE) software application like RStudio. Recently, RStudio Cloud (https://rstudio.cloud) has emerged as an alternative to installing R and RStudio by allowing users to use R and RStudio via the cloud, which notably allows those using the Google Chrome operating system to access R and RStudio. 9.0.0.1 Video Tutorial When it comes to learning how to use and apply R Ive found that some people prefer written tutorials, others prefer video tutorials, and some like to learn using a combination of written and video tutorials. When first starting out, you might find it easier to follow along with a video tutorial, and as you get more comfortable with R, you may begin to prefer the written tutorials that are integrated into each chapter. Generally, the written tutorials contain more information and often more functions and operations, whereas the video tutorial provides the need to know information, functions, and operations. Because this first chapter is just focused on downloading and installing the R and RStudio programs, the written tutorial provided below may suffice; however, if you get stuck, you might find it useful to check out the video tutorial. As a final note, I created the video tutorial embedded in this book using a Windows computer, and thus there might be some minor aesthetic differences in the RStudio interface  as well as differences in hot keys (e.g., Ctrl+C vs. Command+C). Link to video tutorial: https://youtu.be/b18IHQERT4A 9.1 Downloading &amp; Installing R In the following sections, you will learn how to download and install the R program for Windows and Mac operating systems. The base R program must be installed prior to installing the RStudio program. R is open-source software and free to download. 9.1.1 For Windows Operation Systems R can currently run under operating systems as old as Windows Vista (circa 2007). To download R for your Windows operating system for the first time, click on this link: https://cran.r-project.org/bin/windows/base/. Once you are on the R download page, click on the hyperlink to download the current version of R for Windows. Once the file has downloaded, follow the installation prompts. 9.1.2 For Mac Operating Systems The current version of R works with Mac OS X (release 10.6 and higher). To download R for Mac OS X operating system for the first time, click on this link: https://cran.r-project.org/bin/macosx/. If you have Mac OS X 10.11 or higher, click on the hyperlink (with .pkg extension) under the Latest release section to begin your download. If you have Mac OS X 10.10 or lower, click on the appropriate hyperlink (with .pkg extension) under the Binaries for legacy OS X systems section. Once the file has downloaded, follow the installation prompts. I dont advise using a Mac operating system that is older than Mac OS X 10.6 (which came out in 2009), as you may run into issues when using certain R packages for data analysis and visualization. 9.2 Downloading &amp; Installing RStudio RStudio is not required to use R; however, RStudio offers a number of helpful features and a user-friendly interface. More specifically, RStudio is an integrated development environment (IDE) for R. The desktop version of RStudio is free to download. To do so, click on this link: https://rstudio.com/products/rstudio/download/#download. Make sure that you have already installed the R program to your computer (see above). Click on the download button below the RStudio Desktop followed by the version number. Again, this version is free. Under the heading Installers for Supported Platforms, click on the link that corresponds to your operating system. Once the file has downloaded, follow the installation prompts. 9.3 Summary In this chapter, we learned how to install R and RStudio for our Windows or Mac operating systems. "],["gettingstarted.html", "Chapter 10 Getting Started with R 10.1 Orientation to RStudio 10.2 Creating &amp; Saving an R Script 10.3 Creating an RStudio Project 10.4 Orientation to Written Tutorials 10.5 Summary", " Chapter 10 Getting Started with R Like any program, there is bound to be a learning curve. Personally, one of the initial barriers I face when working with a new program is navigating the graphic user interface (GUI). Given that, in this chapter we will begin with a brief orientation to the RStudio program. Subsequent sections will focus on creating and saving R scripts, creating and working with RStudio projects, and how to follow along with written tutorials like the ones presented throughout this book. 10.1 Orientation to RStudio Rather than describe a series of screenshots, I believe one of the best ways to learn how to navigate the RStudio interface is to watch someone else. In the following video, I walk through key (but not all) features of the RStudio interface. This is one of the rare occasions in this book in which only a video tutorial is provided. Please note that in the video I walk through the Windows version of RStudio Desktop; the MacOS version may have slight differences in layout. 10.1.0.1 Video Tutorial Link to video tutorial: https://youtu.be/cq4wixfCuhQ 10.2 Creating &amp; Saving an R Script An R Script is a text editor file in which you can create, edit, and save your R code for a particular task or project. An R Script file has the .R file extension. It is advisable that you type code directly into an R Script file if you wish to use the code again in the future or if you wish to save the code for another session. In general, try to avoid writing code directly into the Console using the command line if you wish to later reproduce your work. An R Script also allows you to make and save annotations (using the # symbol) to explain your code and decision making. Once you typed code (and annotations) into an R Script, you can highlight all of it (or chunks of it) and then click the Run button (or CTRL+Enter for Windows users or Command+Enter for Mac users), which is located in the upper right hand corner of the R Script editor window. In essence, an R Script allows you to save your code and to tell a story about what you have done. As much as you believe youll never forget what you were doing in a particular R session, you will likely forget important details as time passes. Or, imagine a scenario in which someone else inherits your data project; a well-written and -documented R Script file will help them retrace your footsteps and onboard them onto the project. 10.2.0.1 Video Tutorial If you prefer to follow along with screenshots when learning how to navigate a programs interface, feel free to follow along with the written instructions for creating and saving an R script in this section. If, however, you prefer a voiceover of me walking through the interface menus in a video, then by all means follow along with the video below. Link to video tutorial: https://youtu.be/6_CFx5-KmMI 10.2.1 Creating a New R Script To create a new R Script in RStudio, in the drop-down menu, select File &gt; New File &gt; R Script (as shown below). 10.2.2 Using an R Script To use an R Script, simply type into the script interface. To illustrate how to do this, lets type # Adding 2 plus 3 on the first line; note that I began the line with the # symbol, which tells R that any text written to the right is annotation and thus wont be interpreted by R when you select it and click Run. On the next line, lets type 2 + 3. Highlight both lines of script you typed and click the Run button (or CTRL+Enter for Windows users or Command+Enter for Mac users) (as shown below). # Adding 2 plus 3 2 + 3 ## [1] 5 Your Console window should show your output (as shown above). 10.2.3 Saving an R Script Always remember to save your R Script, and do so frequently. To save an R Script in RStudio, in the drop-down menu, select File &gt; Save As (as shown below). After that, a window will open, and you can save the R Script file in a location of your choosing and with a name of your choosing. 10.2.4 Opening a Saved R Script To open a saved R Script in RStudio, in the drop-down menu, select File &gt; Open File (as shown below). After that, a window will open, and you can select the R Script file to open. 10.3 Creating an RStudio Project An RStudio project (or R project) file (.Rproj) is specific to RStudio and allows one to cluster associated scripts and data files into into a single workflow. For example, if you were evaluating a new onboarding program for your company, you could create an RStudio project with a common working directory that ties together any data files and R scripts that are relevant for evaluating the program. Creating an R project is not required for data management, analysis, and visualization work in RStudio, but it can be helpful. For more information on the value of RStudio projects, check out Wickham and Grolemunds (2017) section on RStudio projects: https://r4ds.had.co.nz/workflow-projects.html#rstudio-projects. 10.3.0.1 Video Tutorial To learn how to create an RStudio project, you have the choice between following along with screenshots and written explanations or the voiceover video below. Link to video tutorial: https://youtu.be/WyrJmJWgPiU 10.3.1 Creating a New RStudio Project First, to create a new project in RStudio, in the drop-down menu, select File &gt; New Project. Second, when the Create Project window pops up, select the New Directory option if you have not yet created a working directory that can be used for your project (see Figure 2). [Alternatively, select the Existing Directory option if already have a working directory in place that can be used for your project.] Third, in the Project Type window, select New Project. Fourth, in the Create New Project window, input what you would like to name the new project (in the field under Directory name) and select the location of your working directory. Finally, click the Create Project button. 10.3.2 Opening an Existing RStudio Project To open an existing RStudio project, in the drop-down menu, select File &gt; Open Project. 10.4 Orientation to Written Tutorials Throughout this book, I have included sample R code embedded in chapter tutorials, which I created using RMarkdown. This approach to demonstrating R tools and techniques is common, and thus its good to orient yourself to written tutorials in this format (which can be displayed in HTML or PDF formats). The following video provides an orientation to the in-chapter written tutorials involving R code that you will have the opportunity to follow along with in subsequent chapters. 10.4.0.1 Video Tutorial To learn how to create an RStudio project, you have the choice between following along with screenshots and written explanations or the voiceover video below. Link to video tutorial: https://youtu.be/1Wh6eUYAoZc 10.5 Summary In this chapter, you learned how to set a working directory, create an R script, create an RStudio project, and orient yourself to written R tutorials. First, setting the working directory is often an important step when reading (importing) and writing (exporting objects) in R. You can use the getwd function to check where your current working directory is, whereas the setwd can be used to set a new working directory. Second, writing and saving your R code in an R Script file (.R) is an important step towards reproducible data management, analysis, and visualization. Third, creating an RStudio project can streamline data-analytic projects and provides some user-friendly features. Finally, written R tutorials are commonly presented in either printed (PDF) and web-based (HTML) formats, and thus its worthwhile to familiarize yourself with how to follow along with these tutorial formats. "],["gentleintro.html", "Chapter 11 Basic Features and Operations of the R Language 11.1 R as a Calculator 11.2 Functions 11.3 Packages 11.4 Variable Assignment 11.5 Types of Data 11.6 Vectors 11.7 Lists 11.8 Data Frames 11.9 Annotations 11.10 Summary", " Chapter 11 Basic Features and Operations of the R Language In this chapter, you will learn about basic features of the R language along with key bits of terminology. Think of this chapter as the gentle introduction to R that nearly every book on R includes. Also, it is completely fine if you dont fully grasp certain concepts and functions upon completing this chapter. We will revisit many of these concepts and functions in the HR context in subsequent chapters. Until then, use this chapter as an opportunity to practice writing R code. 11.0.0.1 Video Tutorial When exploring the basic features, operations, and functions feel free to follow along with the written tutorial below or to check out the video. In the video, I offer an abbreviated version of whats covered in the written tutorial and focus on what I think most beginners need to know and understand early on about R. In the written tutorial, I get into some functions and operations that probably wont become relevant until further along in your learning of using R as tool for HR analytics. Link to Video Tutorial: https://youtu.be/yHbVbHEjhLQ 11.0.0.2 Functions &amp; Packages Introduced Function Package print base R class base R str base R install.packages base R library base R is.numeric base R is.integer base R is.character base R is.logical base R as.Date base R as.POSIXct base R c base R data.frame base R names base R 11.1 R as a Calculator In its simplest form, R is a calculator. You can use R to carry out basic arithmetic, algebra, and other mathematical operations. The arithmetic operators in R are + (addition), - (subtraction), * (multiplication), / (division), ^ (exponent), and sqrt (square root). Below, you will find an example of these different arithmetic operators in action. In this book, lines of output are preceded by double hashtags (##); however, in your own R Console, you will not see the double hashtags before your output  unless, that is, you use double hashtags before your lines of script annotations. 3 + 2 ## [1] 5 3 - 2 ## [1] 1 3 * 2 ## [1] 6 3 / 2 ## [1] 1.5 3 ^ 2 ## [1] 9 sqrt(3) ## [1] 1.732051 Note how the six lines of output we generated (see above) appear in the same order in your Console; relatedly, remember that in R (like many other languages) the order of operations is important. In R it doesnt matter whether there are spaces between the numeric values and the arithmetic operators. As such, we can write our code as follows and arrive at the same output. 3+2 ## [1] 5 3-2 ## [1] 1 3*2 ## [1] 6 3/2 ## [1] 1.5 3^2 ## [1] 9 sqrt(3) ## [1] 1.732051 11.2 Functions A function refers to an integrated set of instructions that can be applied consistently. Some functions also accept arguments, where an argument is used to further refine the instructions and resulting operations of the function. In R we can use functions that come standard from base R or functions that come from downloadable packages. Lets take a look at the print function that comes standard with base R, which means that we dont need a special package to access the function. This wont be terribly exciting, but we can enter 3 as an argument within the print function parentheses; in general, arguments will appear within the inclusive parentheses. print(3) ## [1] 3 Note how the print function simply printed the numeric value 3 that we entered. We can also do the classic - yet super cliche - Hello world! example to illustrate how R and the print function handle text/character/string data; except, lets change it to \"Hello HR Analytics!\". print(&quot;Hello HR Analytics!&quot;) ## [1] &quot;Hello HR Analytics!&quot; Note how we have to put text/character/string data in quotation marks. We can use double (\" \") or single quotes (' '). Some people prefer double quotes and some prefer single quotes. I happen to prefer double quotes. Now, lets play around with the class function. The class function is used for determining the data type represented by a datum or by multiple data that are contained in a vector or variable. By entering 3 as an argument in the class variable, we find that the data type is numeric. class(3) ## [1] &quot;numeric&quot; If you would like to learn more about a function and the types of arguments that can be used within the function, you can access the help feature in R to access documentation on the function. The easiest way to do this is to enter ? before the name of the function. Upon doing so, a help window will open; if youre using RStudio, a specific window pane dedicated to Help will open. ?class 11.3 Packages A package is a collection of functions with a common theme or that can be applied to address a similar set of problems. R packages go through a rigorous and laborious development and vetting process before being posted on the CRAN website (https://cran.r-project.org/). There are two functions that are important when it comes to installing and using packages. First, the install.packages function is used to install a package. The name of the package you wish to install should be surrounded with quotation marks (\" \" or ' ') and entered as an argument in the function. For example, if we wish to install the lessR package (Gerbing 2020), we type install.packages(\"lessR\"), as shown below. Please note that the names of packages (and functions, arguments, and objects) are case sensitive in R. install.packages(&quot;lessR&quot;) Once you have installed a package, you use the library function to check out the package from your library of functions. To use the function, enter the exact name of the function without quotation marks. library(lessR) 11.4 Variable Assignment Variable assignment is the process of assigning a value or multiple values to a variable. There are two assignment operators that can be used for variable assignment as well as for (re)naming objects such as tables and data frames: &lt;- and =. Both work the same way. I prefer to use &lt;-, but others prefer =. In the example below, we assign the value 3 to a variable (i.e., object) we are naming x. x &lt;- 3 x = 3 Both functions achieved the same end, and the function that was run most recently overrides the previous attempt at assigning 3 to x. Using the print function we check with this worked. print(x) ## [1] 3 Or, instead of using the print function , we can simply run x by itself. x ## [1] 3 11.5 Types of Data In general, there are four different types of data in R: numeric, character, Date, and logical. 11.5.1 numeric Data numeric data are numbers or numeric values. This data type is ready-made for quantitative analysis. We can apply the is.numeric function to determine whether a value or variable is numeric; if the value or variable entered as an argument is numeric, R will return TRUE, and if it is not numeric, R will return FALSE. [Note that TRUE and FALSE statements dont require quotation marks like text/character/string data, as they are handled differently in R.] Finally, lets see if that \"Hello data science!\" phrase is numeric. is.numeric(3) ## [1] TRUE is.numeric(TRUE) ## [1] FALSE is.numeric(&quot;Hello data science!&quot;) ## [1] FALSE An integer is a special type of numeric data. An integer does not have any decimals, and thus is a whole number. To specify that numeric data are of type integer, L must be appended to the value. For example, to specify that 3 is an integer, it should be written as 3L. To verify that a value is in fact of type integer, we can apply the as.integer function. is.integer(3L) ## [1] TRUE is.integer(3) ## [1] FALSE Alternatively, we can use the class or str functions to determine whether a value or variable is integer or numeric. The function str is used to identify the structure of an object (e.g., data frame, variable, value). class(3L) ## [1] &quot;integer&quot; str(3L) ## int 3 class(3) ## [1] &quot;numeric&quot; str(3) ## num 3 Finally, if we assign a numeric or integer value to a variable, the resulting variable will take on the numeric or integer data type (respectively). x &lt;- 3 class(x) ## [1] &quot;numeric&quot; x &lt;- 3L class(x) ## [1] &quot;integer&quot; 11.5.2 character Data Data of type character do not explicitly or innately have quantitative properties. Sometimes this type of data is called string or text data. Data of type factor is similar to character but handled differently by R; this distinction becomes more important when working with vectors and analyses. That said, many analysis functions automatically convert character to factor for analyses, but when it comes to working with and manipulating data frames, this character versus factor distinction becomes more important. When data are of type character, we place quotation marks (\" \" or ' ') around the text. For example, if the character of interest is old, then we place quotation marks around text like this \"old\". Also note that character data are case sensitive, which means that \"old\" is not the same as \"Old\". Using the function is.character, we can determine whether data are in fact of type character. is.character(&quot;old&quot;) ## [1] TRUE Note how omitting the \" \" results in an error message. is.character(old) ## Error in eval(expr, envir, enclos): object &#39;old&#39; not found Finally, if we assign a numeric or integer value to a variable, the resulting variable will take on the numeric or integer data types. y &lt;- &quot;old&quot; class(y) ## [1] &quot;character&quot; 11.5.3 Date Data When working with dates in R, there are two different types: Date and POSIXct. Date captures just the date, whereas POSIXct captures the date and time. Behind the scenes, R treats Date numerically as the number of days since January 1, 1970, and POSIXct as the number of seconds since January 1, 1970. To specify a value as a date, we can use the as.Date function. z &lt;- as.Date(&quot;1970-03-01&quot;) class(z) ## [1] &quot;Date&quot; If we convert a variable of type Date to numeric using the as.numeric function, the result is the number of days since January 1, 1970. z &lt;- as.Date(&quot;1970-03-01&quot;) as.numeric(z) ## [1] 59 Now we can use the as.POSIXct function to specify a value as a date and time. Note the very specific format in which the data and time are to be written. z &lt;- as.POSIXct(&quot;1970-03-01 13:10&quot;) class(z) ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; If we convert a variable of type POSIXct to numeric using the as.numeric function, the result is the number of seconds since January 1, 1970. z &lt;- as.POSIXct(&quot;1970-03-01 13:10&quot;) as.numeric(z) ## [1] 5173800 11.5.4 logical Data Data that are of type logical can take on values of either TRUE or FALSE, which correspond to the integers 1 and 0, respectively. As mentioned above, although TRUE and FALSE appear to be character or factor data, they are actually logical data, which means they do not require quotation marks (\" \" or ' '). w &lt;- FALSE class(w) ## [1] &quot;logical&quot; is.logical(w) ## [1] TRUE 11.6 Vectors A vector is a group of data elements in a particular order that are all the same data type. To create a vector, we can use the c function, which stands for combine. Within the c function parentheses, we can list the data elements and separate them by commas, as commas separate arguments within a functions parentheses. We can also assign a vector to a variable using either the &lt;- or = operator. We can create vectors for all of the data types: numeric, character, Date, and logical. As an example, lets create a vector of numeric values, and lets call it a. a &lt;- c(1, 4, 7, 11, 19) Using the class and print functions, we can determine the class of our new a object and print its values, respectively. class(a) ## [1] &quot;numeric&quot; print(a) ## [1] 1 4 7 11 19 Lets repeat this process by creating vectors containing integer, character, Date, and logical values. b &lt;- c(3L, 10L, 2L, 5L, 5L) class(b) ## [1] &quot;integer&quot; print(b) ## [1] 3 10 2 5 5 c &lt;- c(&quot;old&quot;, &quot;young&quot;, &quot;young&quot;, &quot;old&quot;, &quot;young&quot;) class(c) ## [1] &quot;character&quot; print(c) ## [1] &quot;old&quot; &quot;young&quot; &quot;young&quot; &quot;old&quot; &quot;young&quot; d &lt;- as.Date(c(&quot;2018-06-01&quot;, &quot;2018-06-01&quot;, &quot;2018-10-31&quot;, &quot;2018-01-01&quot;, &quot;2018-06-01&quot;)) class(d) ## [1] &quot;Date&quot; print(d) ## [1] &quot;2018-06-01&quot; &quot;2018-06-01&quot; &quot;2018-10-31&quot; &quot;2018-01-01&quot; &quot;2018-06-01&quot; e &lt;- c(TRUE, TRUE, TRUE, FALSE, FALSE) class(e) ## [1] &quot;logical&quot; print(e) ## [1] TRUE TRUE TRUE FALSE FALSE We can also perform mathematical operations on vectors. For instance, we can multiply vector a (which we created above) by a numeric value, and as a result each vector value will be multiplied by that value. This is an important type of operation to remember when it comes time to transform a variable. a * 11 ## [1] 11 44 77 121 209 Note that performing mathematical operations on a vector does not automatically change the properties of the vector itself. If you inspect the a vector, you will see that the original data (e.g., 1, 4, 7, 11, 19) remain. print(a) ## [1] 1 4 7 11 19 If we want to overwrite a vector with new values based on our operations, we can use &lt;- or = to name the new vector (which, if named the same thing as the old vector, will override the old vector) and, ultimately, to create a vector with the operations applied to the original values. a &lt;- a * 11 print(a) ## [1] 11 44 77 121 209 To revert back to the original vector values for object a, we can simply specify the original values using the c function once more. a &lt;- c(1, 4, 7, 11, 19) Lets now apply subtraction, addition, and division operators to the vector. Note that R adheres to the standard mathematical orders of operation. (3 + a) / 2 - 1 ## [1] 1.0 2.5 4.0 6.0 10.0 We can also perform mathematical operations on vectors of the same length (i.e., with the same number of data elements). In order, the mathematical operator will be applied to each pair of vector values from the respective vectors. Lets begin by creating a new vector called f. f &lt;- c(3, 1, 3, 5, 3) Both a and f are the same length, which means we can multiply, add, divide, subtract, and exponentiate a * f ## [1] 3 4 21 55 57 a + f ## [1] 4 5 10 16 22 a / f ## [1] 0.3333333 4.0000000 2.3333333 2.2000000 6.3333333 a - f ## [1] -2 3 4 6 16 a ^ f ## [1] 1 4 343 161051 6859 11.7 Lists If we wish to combine data elements into a single list that with different data types, we can use the list function. The list function orders each data element and retains its value. g &lt;- list(1, &quot;dog&quot;, TRUE, &quot;2018-05-30&quot;) print(g) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] &quot;dog&quot; ## ## [[3]] ## [1] TRUE ## ## [[4]] ## [1] &quot;2018-05-30&quot; class(g) ## [1] &quot;list&quot; 11.8 Data Frames A data frame is a specific type of table in which columns represent variables (i.e., fields) and rows represent cases (i.e., observations). We can create a simple data frame object by combining vectors of the same length. Lets begin by creating six vector objects, which we will label a through f. a &lt;- c(1, 4, 7, 11, 19) b &lt;- c(3L, 10L, 2L, 5L, 5L) c &lt;- c(&quot;old&quot;, &quot;young&quot;, &quot;young&quot;, &quot;old&quot;, &quot;young&quot;) d &lt;- as.Date(c(&quot;2018-06-01&quot;, &quot;2018-06-01&quot;, &quot;2018-10-31&quot;, &quot;2018-01-01&quot;, &quot;2018-06-01&quot;)) e &lt;- c(TRUE, TRUE, TRUE, FALSE, FALSE) f &lt;- c(3, 1, 3, 5, 3) Using the data.frame function from base R we can combine the six vectors to create a data frame object. All we need to do is enter the names of the six vectors as separate arguments in the function parentheses. Just as we did with the vectors, we can name the data frame object using the &lt;- operator (or = operator). Lets name this data frame object r. r &lt;- data.frame(a, b, c, d, e, f) Using the print function, we can view the contents of our new data frame object called r. print(r) ## a b c d e f ## 1 1 3 old 2018-06-01 TRUE 3 ## 2 4 10 young 2018-06-01 TRUE 1 ## 3 7 2 young 2018-10-31 TRUE 3 ## 4 11 5 old 2018-01-01 FALSE 5 ## 5 19 5 young 2018-06-01 FALSE 3 We can also rename the columns (i.e., variables) of the data frame object by using the names function from base R along with the c function from base R. names(r) &lt;- c(&quot;TenureSup&quot;, &quot;TenureOrg&quot;, &quot;Age&quot;, &quot;HireDate&quot;, &quot;FTE&quot;, &quot;NumEmp&quot;) To view the changes to our data frame object, use the print function once more. print(r) ## TenureSup TenureOrg Age HireDate FTE NumEmp ## 1 1 3 old 2018-06-01 TRUE 3 ## 2 4 10 young 2018-06-01 TRUE 1 ## 3 7 2 young 2018-10-31 TRUE 3 ## 4 11 5 old 2018-01-01 FALSE 5 ## 5 19 5 young 2018-06-01 FALSE 3 Finally, we can use the class function to verify that the object is in fact a data frame. class(r) ## [1] &quot;data.frame&quot; 11.9 Annotations Part of the value of using a code/script-based program like R is that you can leave notes and explain your decisions and operations. When preceding text, the # symbol indicates that all text that follows on that line is a comment or annotation; as a result, R knows not to interpret or analyze the text that follows. To illustrate annotations, lets repeat the steps from the previous section; however, this time, lets include annotations. # Create six vectors a &lt;- c(1, 4, 7, 11, 19) # Vector a b &lt;- c(3L, 10L, 2L, 5L, 5L) # Vector b c &lt;- c(&quot;old&quot;, &quot;young&quot;, &quot;young&quot;, &quot;old&quot;, &quot;young&quot;) # Vector c d &lt;- as.Date(c(&quot;2018-06-01&quot;, &quot;2018-06-01&quot;, &quot;2018-10-31&quot;, &quot;2018-01-01&quot;, &quot;2018-06-01&quot;)) # Vector d e &lt;- c(TRUE, TRUE, TRUE, FALSE, FALSE) # Vector e f &lt;- c(3, 1, 3, 5, 3) # Vector f # Combine vectors into data frame r &lt;- data.frame(a, b, c, d, e, f) # Print data frame print(r) ## a b c d e f ## 1 1 3 old 2018-06-01 TRUE 3 ## 2 4 10 young 2018-06-01 TRUE 1 ## 3 7 2 young 2018-10-31 TRUE 3 ## 4 11 5 old 2018-01-01 FALSE 5 ## 5 19 5 young 2018-06-01 FALSE 3 # Rename columns in data frame names(r) &lt;- c(&quot;TenureSup&quot;, &quot;TenureOrg&quot;, &quot;Age&quot;, &quot;HireDate&quot;, &quot;FTE&quot;, &quot;NumEmp&quot;) # Print data frame print(r) ## TenureSup TenureOrg Age HireDate FTE NumEmp ## 1 1 3 old 2018-06-01 TRUE 3 ## 2 4 10 young 2018-06-01 TRUE 1 ## 3 7 2 young 2018-10-31 TRUE 3 ## 4 11 5 old 2018-01-01 FALSE 5 ## 5 19 5 young 2018-06-01 FALSE 3 # Determine class of object class(r) ## [1] &quot;data.frame&quot; Can you start to envision how annotated code might help to tell a story about data-related decision-making processes? 11.10 Summary This chapter provided you with a gentle introduction to R. This chapter is by no means comprehensive and there were probably some concepts and functions that still dont quite make sense to you. Hopefully, this chapter provided you with a basic understanding of the basic operations and building blocks of R. Well practice applying many of the operations and functions from this chapter in subsequent chapters, which means youll have many more opportunities to learn and practice. "],["setwd.html", "Chapter 12 Setting a Working Directory 12.1 Summary", " Chapter 12 Setting a Working Directory A working directory refers to the location of a folder within a hierarchical file system. For our purposes, a working directory contains data files associated with a particular task or project. Ideally, a single working directory contains all of the data files you need for a task or project, but in some instances, it might make sense to have multiple working directories for a single project. From our designated working directory, we can read in data files (i.e., import files) to the R environment without adding long paths as prefixes in front of the variable names. Further, anytime you save a plot, data frame, or other object created in R, the default will be to save it to the folder you have set as your working directory (i.e., export files). 12.0.0.1 Video Tutorial As usual, you have the choice to follow along with the written tutorial in this chapter or to watch the video tutorial below. Both versions of the tutorial demonstrate how to identify what your current working directory is and how to set a new working directory. Link to Video Tutorial: https://youtu.be/oSqOqvMkhSE 12.0.0.2 Functions &amp; Packages Introduced Function Package getwd base R setwd base R 12.0.1 Identify the Current Working Directory To determine if a working directory has already been set, and if so, what that working directory is, use the getwd (get working directory) function from base R. Because this function comes standard with our R download, we dont need to install an additional package to access it. For this function, you dont need any arguments within the parentheses; in other words, leave the function parentheses empty. Alternatively, if you are using RStudio, you will see your current working directory next to the word Console in your Console window. # Find your current working directory getwd() 12.0.2 Set a New Working Directory Lets assume that the current working directory is not what we want; meaning, we need to set a new or different working directory. If you need to set a new working directory, you can use the setwd function from base R. Within the parentheses, your only argument will be the working directory in quotation marks. I recommend typing your setwd function into an R Script (.R) file so that it can be saved for future sessions. I also recommend using the # to annotate your script so that you can remind yourself (and others) what you are doing. When it comes to working directories, R likes the forward slash (/) (as opposed to backslash). Remember, the working directory is the location of the data files you wish to access and bring into the R environment. You can access any folder you would like and set it as your working directory. For example, in the code below, I set my working directory to H:/RWorkshop, as that folder at the end of that path contains the data files I would like to work with. The folder (and associated path) you set as your working directory will almost certainly be different than the one I set below. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) Alternatively, you may use the drop-down menus to select a working directory folder. To do so, go to Session &gt; Set Working Directory &gt; Choose Directory, and select the folder where your files live. Upon doing so, your working directory will appear in the Console. You can copy and paste the working directory into your setwd function. Once you have set your working directory, you can verify that it was set to the correct folder by (a) typing getwd() into your console or (b) looking at the working directory listed next to the word Console in your Console window. 12.1 Summary In this chapter, you learned how to get and set a working directory using the getwd and setwd functions from base R. "],["read.html", "Chapter 13 Reading Data into R 13.1 Read a .csv File 13.2 Read a .xlsx File 13.3 Summary 13.4 Chapter Supplement", " Chapter 13 Reading Data into R Reading data refers to the process of importing data from a (working) directory or website into the R environment. When we read a data file into R, we often read it in as a data frame (df), where a data frame is a tabular display with columns representing variables and rows representing cases. Many different data file formats can be read into R as data frames, such as .csv (comma separated values), .xlsx (Excel workbook), .txt (text), .sas7bdat (SAS), and .sav (SPSS). In this chapter, you will learn how to read .csv and .xlsx files into R. 13.0.0.1 Video Tutorial As usual, you have the choice to follow along with the written tutorial in this chapter or to watch the video tutorial below. Both versions of the tutorial demonstrate how to read a .csv file into R; however, in the video tutorial I demonstrate multiple functions that can read in .csv files (read.csv, read_csv, Read), whereas in the written tutorial, I demonstrate just the function I prefer to use (read_csv). In this written tutorial, I also demonstrate how to read in a .xlsx file using the read_excel function as well as some additional operations, and for time considerations, I dont demonstrate those approaches in the video. Link to Video Tutorial: https://youtu.be/smWjqhaxHY8 13.0.0.2 Functions &amp; Packages Introduced Function Package read_csv readr excel_sheets readxl read_excel readxl View base R print base R head base R tail base R names base R colnames base R 13.0.0.3 Initial Steps Please note, that any function that appears in the Initial Steps section has been covered in a previous chapter. If you need a refresher, please view the relevant chapter. In addition, a previous chapter may show you how to perform the same action using different functions or packages. To get started, please save the following data files into a folder on your computer that you will set as your working directory: PersData.csv and PersData_Excel.xlsx. As a reminder, you can access all of the data files referenced in this book by downloading them as a compressed (zipped) folder from the my GitHub site: https://github.com/davidcaughlin/R-Tutorial-Data-Files; once youve followed the link to GitHub, just click Code (or Download) followed by Download ZIP, which will download all of the data files referenced in this book. For the sake of parsimony, I recommend downloading all of the data files into the same folder on your computer, which will allow you to set that same folder as your working directory for each of the chapters in this book. Next, set your working directory by using the setwd function (see below) or by doing it using drop-down menus. Your working directory folder will likely be different than the one shown below; H:/RWorkshop just happens to be the name of the folder that I save my data files to and that I set as my working directory. You can manually set your working directory folder in your drop-down menus by going to Session &gt; Set Working Directory &gt; Choose Directory. If you need a refresher on how to set a working directory, please refer to Setting a Working Directory. # Set your working directory to the folder containing your data file setwd(&quot;H:/RWorkshop&quot;) Finally, I highly recommend that you create a new R Script file (.R), which will allow you to edit and save your script and annotations. To learn more, please refer to Creating &amp; Saving an R Script. 13.1 Read a .csv File One of the easiest data file formats to work with when reading data into R is the .csv (comma-separated values) file format. Many HR analysts and other types of data analysts regularly work with .csv files, and .csv files can be created in Microsoft Excel and Google Sheets (as well as using many other programs). For example, many survey, data-analysis, and data-acquisition platforms allow data to be exported to .csv files. When getting started in R, the way in which the .csv file is formatted can make your life easier. Specifically, the most straightforward .csv file format to read is structured such that (a) the first row contains the names of the variables (i.e., columns, fields), and (b) the second, third, fourth, and fifth rows (and so on) contain the observed scores on the variables (i.e., data), where each row represents a case (i.e., observation, employee). In the chapter supplement section of this chapter, you will have an opportunity to read in .csv files in which the observed values do not begin until the third row or later. As part of the tidyverse of R packages (Wickham 2021; Wickham et al. 2019), the readr package (Wickham and Hester 2020) and its functions can be used to read in a few different data file formats (as long as they are rectangular), including .csv files. To read in .csv files, we will use the read_csv function from the readr package, as it tends to be faster than some of the other functions developed to read in data. There are several other R functions that can read in .csv files (e.g., read.csv, Read), and if youre interested in learning two of those functions, feel free to check out the end-of-book supplement called Reading Data: Chapter Supplement. By default, the read_csv function reads data in as a data frame, where a data frame is a specific type of table in which columns contain variables and rows contain cases. Well, technically, the function reads data in as a tibble (as opposed to a data frame), where a tibble behaves a lot like a data frame. Thus, from here on out in the book, Ill just use the term data frame. If you would like more information about tibbles, check out Wickham and Grolemunds (2017) chapter on tibbles: http://r4ds.had.co.nz/tibbles.html. To use the read_csv function, the readr package must be installed and accessed using the install.packages and library functions, respectively. Type \"readr\" (note the quotation marks) into the parentheses of the install.packages function, and run that line of code. # Install readr package install.packages(&quot;readr&quot;) Next, type readr (without quotation marks) into the parentheses of the library function. In other words, include readr as the library functions sole parenthetical argument. Run that line of code. # Access readr package library(readr) Type the name of the read_csv function, and note that all of the letters in the function name are lowercase. As the sole argument within the functions parentheses and within quotation marks (\" \"), type the exact name of the .csv data file as it is named in your working directory (PersData.csv), and be sure to follow it immediately with the .csv extension. Remember, R is a language where spaces matter in the context of file names; meaning, if there are spaces in your file name, there needs to be spaces when the file name appears in your R code. Remember, the file called PersData.csv should already be saved in your working directory folder (see Initial Steps). # Read .csv file into R as data frame read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male As you can see in your Console, the data frame that appears contains only a handful of rows and columns; nonetheless, this gives you an idea of how the read_csv function works. Often, you will want to assign a data frame to an object that will be stored in your (Global) Environment for subsequent use; once the data are assigned, the object becomes a data frame object. By creating a data frame object, you can manipulate and/or analyze the data within the object using a variety of functions (and without changing the data in the original .csv file). To assign the data frame to an object, we simply (a) use the same read_csv function and argument as above, (b) add either the &lt;- or = operator to the left of the read_csv function, and (c) create a name of our choosing for the data frame object by entering that name to the left of the &lt;- or = operator. You can name your data frame object whatever you would like as long as it doesnt include spaces, doesnt start with a numeral, and doesnt include special characters like * or - (to name a few). I recommend choosing a name that is relatively short but descriptive, and that is not the same as another R function or variable name that you plan to use. Below, I name the new data frame object personaldata; note, however, that I could have just have easily called PersonalData, pd, df, or any other single-word name that doesnt begin with a special character or a numeral. # Read .csv data file into R and name data frame object personaldata &lt;- read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) Using the head function from base R, lets print just the first 6 rows of our data frame object that we named personaldata. This will allow us to verify that everything worked as planned. # Print just the first 6 rows of the data frame object in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male If you are working in RStudio, you will see the data frame object appear in your Global Environment window panel, as shown below. If you click on the name of the data frame object in your Global Environment, a new tab will open up next to your R script editor tab, which will allow you to view the data. Alternatively, you can use the View function from base R with the exact name of the data frame object we just created as the sole parenthetical argument. Note that the View function begins with an uppercase letter. Remember, R is case and space sensitive when it comes to function names. Further, the name of the data frame object you enter into the parentheses of the function must be exactly the same as the name of the object you created. That is, R wont recognize the data frame object if you type it as PersonalData, but R will recognize it if you type it as personaldata. Sometimes it helps to copy and paste the exact names of functions and variables into the function parentheses. # View data within data frame object View(personaldata) Instead of using the View function, you could just run the name of the data frame object by highlighting personaldata in your R Script and clicking Run (or you can enter the name of the data frame object directly into your Console command line and click Enter). Another option is to use the print function (from base R) with the name of the data frame object as the sole argument in the parentheses. Similarly, if you have many rows of data, you can use the head function from base R to see just the first 6 rows of data, or you can use the tail function from base R to see the last 6 rows of data. # Highlight the name of data frame object and run the code to view in Console personaldata ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male # Use print function with the name of the data frame object to view in Console print(personaldata) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male # View just the first 6 rows of the data frame object in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male # View just the last 6 rows of the data frame object in Console tail(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 165 Doe Jane 1/4/2016 female ## 2 125 Franklin Benjamin 1/5/2016 male ## 3 111 Newton Isaac 1/9/2016 male ## 4 198 Morales Linda 1/7/2016 female ## 5 201 Providence Cindy 1/9/2016 female ## 6 282 Legend John 1/9/2016 male If your data file resides in a folder other than your set working directory, then you can type the exact name of the path directory where the file resides followed by a forward slash (/) before the file name. Please note that your path directory will almost certainly be different than the one I show below. # Read data and name data frame object personaldata &lt;- read_csv(&quot;H:/RWorkshop/PersData.csv&quot;) Note that by assigning this data frame to an object called personaldata, we have overwritten the previous version of the object with that same name. In this case, this isnt a big deal because we just read in the exact data using two different methods. If you dont wish to overwrite an existing object, just name the object something unique. When naming objects, I suggest that you avoid the names of functions that you plan to use. When needed, you can also use the read_csv function to read in .csv data from a website. For example, rather than save the .csv file to a folder on your computer, you can read in the raw data directly from my GitHub site. Within the quotation marks (\" \"), simply paste in the following URL: https://raw.githubusercontent.com/davidcaughlin/R-Tutorial-Data-Files/master/PersData.csv. # Read .csv data file into R from a website personaldata &lt;- read_csv(&quot;https://raw.githubusercontent.com/davidcaughlin/R-Tutorial-Data-Files/master/PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) 13.2 Read a .xlsx File Reading in Excel workbook files with more than one worksheet requires a bit more work. To read in a .xlsx file with multiple worksheets, we will use the excel_sheets and read_excel functions from the readxl package (Wickham and Bryan 2019). Be sure to install and access the read_xl package if you havent already. # Install readxl package install.packages(&quot;readxl&quot;) # Access readxl package library(readxl) To view the worksheets within an Excel workbook file, simply type the name of the excel_sheets function, and as the sole parenthetical argument, type the exact name of the data file with the .xlsx extension  all within quotation marks (i.e., \"PersData_Excel.xlsx\"). # View worksheets contained within .xlsx file excel_sheets(&quot;PersData_Excel.xlsx&quot;) ## [1] &quot;Year1&quot; &quot;Year2&quot; Note that the .xlsx file contains two worksheets called Year1 and Year2. We can now reference each of these worksheets when reading in the data from the Excel workbook file. To do so, we will use the read_excel function. As the first argument, enter the exact name of the data file (as named in your working directory), followed by .xlsx  and all within quotation marks (\" \"). As the second argument, type sheets= followed by the name of the worksheet containing the data you wish to read in; lets read in the data from the worksheet called Year1. Finally, either the &lt;- or = operator can be used to name the data frame object. Below, I name the data frame object personaldata_year1 to avoid overwriting the data frame object we created above called personaldata. Remember to type a comma (,) before the second argument, as this is how we separate arguments from one another when there are more than one. # Read data from .xlsx sheet called &quot;Year1&quot; as data frame and assign to object personaldata_year1 &lt;- read_excel(&quot;PersData_Excel.xlsx&quot;, sheet=&quot;Year1&quot;) # Print data frame object in Console print(personaldata_year1) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 2016-01-01 00:00:00 male ## 2 154 McDonald Ronald 2016-01-09 00:00:00 male ## 3 155 Smith John 2016-01-09 00:00:00 male ## 4 165 Doe Jane 2016-01-04 00:00:00 female ## 5 125 Franklin Benjamin 2016-01-05 00:00:00 male ## 6 111 Newton Isaac 2016-01-09 00:00:00 male ## 7 198 Morales Linda 2016-01-07 00:00:00 female ## 8 201 Providence Cindy 2016-01-09 00:00:00 female ## 9 282 Legend John 2016-01-09 00:00:00 male Lets repeat the process for the worksheet called Year2 and assign these data to a new object. # Read data from .xlsx sheet called &quot;Year2&quot; as data frame and assign to object personaldata_year2 &lt;- read_excel(&quot;PersData_Excel.xlsx&quot;, sheet=&quot;Year2&quot;) # Print data frame object in Console print(personaldata_year2) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 2016-01-01 00:00:00 male ## 2 155 Smith John 2016-01-09 00:00:00 male ## 3 165 Doe Jane 2016-01-04 00:00:00 female ## 4 125 Franklin Benjamin 2016-01-05 00:00:00 male ## 5 111 Newton Isaac 2016-01-09 00:00:00 male ## 6 201 Providence Cindy 2016-01-09 00:00:00 female ## 7 282 Legend John 2016-01-09 00:00:00 male ## 8 312 Ramos Jorge 2017-03-01 00:00:00 male ## 9 395 Lucas Nadia 2017-03-04 00:00:00 female 13.3 Summary In this chapter, we learned how to read data into the R environment. Reading data into R is an important first step, and often, it is the step that causes the most problems for new R users. We practiced applying the read_csv function from the readr pack and the read_excel function from the read_xl package to read .csv and .xlsx files, respectively, into the R environment. 13.4 Chapter Supplement In this chapter supplement, I demonstrate additional functions that can be used to read in .csv files and demonstrate how to list the names of data files located in a (working directory) folder and how to skip rows of data when reading in a .csv file. 13.4.0.1 Functions &amp; Packages Introduced Function Package read.csv base R Read lessR list.files base R 13.4.0.2 Initial Steps If required, please refer to the Initial Steps section from this chapter for more information on these initial steps. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) 13.4.1 Additional Functions to Read a .csv File In addition to the read_csv function from the readr package covered earlier in the chapter, we can read .csv files into R using the read.csv function from base R and the Read function from the lessR package, which we will review in this chapter supplement. 13.4.1.1 read.csv Function from Base R The read.csv file comes standard with base R, which means that you dont need to install a package to access the function. As the function name implies, this function is used when the source data file is in .csv format. Typically, the read.csv function requires only a single argument within the parentheses, which will be the exact name of the data file enclosed with quotation marks; the file should be located your working directory folder. Remember, R is a language where case and space sensitivity matters when it comes to names; meaning, if there are spaces in your file name, there needs to be spaces when the file name appears in your R script, and if some letters are upper case in your file name, there needs to be corresponding upper-case letters in your R script. Lets practice reading in a file called PersData.csv by entering the exact name of the file followed by the .csv extension, all within in quotation marks. Remember, the file called PersData.csv should already be saved in your working directory folder (see Initial Steps). # Read data from working directory read.csv(&quot;PersData.csv&quot;) ## id lastname firstname startdate gender ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male As you can see, the data that appear in your Console contains only a handful of rows and columns; nonetheless, this gives you an idea of how the read.csv function works. Often, you will want to assign your data frame to an object that is stored in your Global Environment for subsequent use. By creating a data frame object, you can manipulate and/or analyze the data within the object using a variety of functions (and without changing the data in the source file). To create a data frame object, we simply (a) use the same read.csv function from above, (b) add either a &lt;- or = operator to the left of the read.csv function, and (c) create a name of our choosing for the data frame object by entering that name to the left of the &lt;- or = operator. You can name your data frame object whatever you would like as long as it doesnt include spaces, doesnt start with a numeral, and doesnt include special characters like * or - (to name a few). I recommend choosing a name that is relatively short but descriptive, and that is not the same as another R function or variable name that you plan to use. Below, I name the new data frame object personaldata. # Read in data and name data frame object personaldata &lt;- read.csv(&quot;PersData.csv&quot;) 13.4.1.2 Read Function from lessR Package Just like the read.csv and read_csv functions, the Read function from the lessR package (Gerbing 2020) can read in .csv files; however, it can also read in other file formats like .xls/x, .sas7bdat (SAS), and .sav (SPSS). To use the Read function, the lessR package needs to be installed and accessed using the install.packages and library functions, respectively. # Install lessR package install.packages(&quot;lessR&quot;) # Access lessR package library(lessR) When reading in a .csv file using the Read function, type the exact name of your data file from your working directory as an argument (followed by .csv and surrounded by quotation marks). Further, either the &lt;- or = operator can be used to name the data frame object. # Read data and assign to data frame object personaldata &lt;- Read(&quot;PersData.csv&quot;) ## ## &gt;&gt;&gt; Suggestions ## To read a csv or Excel file of variable labels, var_labels=TRUE ## Each row of the file: Variable Name, Variable Label ## Details about your data, Enter: details() for d, or details(name) ## ## Data Types ## ------------------------------------------------------------ ## character: Non-numeric data values ## integer: Numeric data values, integers only ## ------------------------------------------------------------ ## ## Variable Missing Unique ## Name Type Values Values Values First and last values ## ------------------------------------------------------------------------------------------ ## 1 id integer 9 0 9 153 154 155 ... 198 201 282 ## 2 lastname character 9 0 9 Sanchez McDonald ... Providence Legend ## 3 firstname character 9 0 8 Alejandro Ronald ... Cindy John ## 4 startdate character 9 0 5 1/1/2016 1/9/2016 ... 1/9/2016 1/9/2016 ## 5 gender character 9 0 2 male male male ... female female male ## ------------------------------------------------------------------------------------------ Lets print just the first six rows of the personaldata data frame object to the Console to verify that everything worked as intended. # Print just the first 6 rows of the data frame object in Console head(personaldata) ## id lastname firstname startdate gender ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male For more information on the Read function from the lessR package, check out David Gerbings website: http://www.lessrstats.com/videos.html. 13.4.2 Skip Rows of Data During Read Thus far, I have showcased some of the most common approaches to reading in data files, with an emphasis on reading in .csv files with the first row corresponding to the column (variable) names and the remaining rows containing the substantive data for cases. There are, however, other challenges and considerations you might encounter along the way. For example, some survey platforms like Qualtrics allow for data to be downloaded in .csv format; however, sometimes these platforms include variable name and label information in the second and even third rows of data as opposed to in just the first row. Fortunately, we can skip rows when reading in such data files. Well first learn how to skip rows with the read_csv function from the readr package, and then well learn to do so using the read.csv function from base R and the Read function from the lessR package. Lets pretend that the first row of the PersData.csv data file contains variable names, and the second and third rows contain variable label information and explanations. We can nest the read_csv function (from the readr package) within the names function, which will result in a vector of names from the first row of the data file. Using the &lt;- operator, lets name this vector var_names so that we can reference it in the subsequent step. # Read variable names from first row of data var_names &lt;- names(read_csv(&quot;PersData.csv&quot;)) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) Next, using the read_csv function, we will read in the data file, skip the variable names row and the first two rows of actual values (which adds to three rows), and add the variable names we pulled in the previous step. Notably, the read_csv function assumes that the first of data in your data file contain the variable names when you use the col_names argument, as we will do below. As usual, as the first argument of the read_csv function, type the exact name of the data file you wish to read in within quotation marks (\" \"). As the second argument, type skip=3 to indicate that you wish to skip the first three rows when reading in the data. As the third argument, type col_names= followed by the name of the var_names vector object we created in the previous step. Using the &lt;- operator, lets name this data frame object test. # Read data file (but skip the variable names &amp; rows 1-2) # &amp; introduce variable names test &lt;- read_csv(&quot;PersData.csv&quot;, skip=3, col_names=var_names) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) Finally, lets see the fruits of our labor by printing the contents of the test data frame object to our Console. # Print data frame object in Console print(test) ## # A tibble: 7 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 155 Smith John 1/9/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 111 Newton Isaac 1/9/2016 male ## 5 198 Morales Linda 1/7/2016 female ## 6 201 Providence Cindy 1/9/2016 female ## 7 282 Legend John 1/9/2016 male The read.csv function from base R also allows for us to skip rows; however, to make the function operate like the read_csv function, we need to add the header=FALSE argument to pretend like the first row of data in the data file does not contain variable names. In doing so, we can keep the argument rows=3 the same as we did in the read_csv function above. Alternatively, if we were to set header=TRUE (which is the default setting for this function), then we would need to change the argument rows=3 to rows=2. Its up to you which makes more intuitive sense to you. Finally, instead of col_names, the read.csv function equivalent argument is col.names. # Read data file (but skip the variable names &amp; rows 1-2) # &amp; introduce variable names test &lt;- read.csv(&quot;PersData.csv&quot;, header=FALSE, skip=3, col.names=var_names) # Print data frame object in Console print(test) ## id lastname firstname startdate gender ## 1 155 Smith John 1/9/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 111 Newton Isaac 1/9/2016 male ## 5 198 Morales Linda 1/7/2016 female ## 6 201 Providence Cindy 1/9/2016 female ## 7 282 Legend John 1/9/2016 male Finally, if we take the code from above for the read.csv function and swap read.csv out with Read function (assuming we have already accessed the lessR package using the library function), then we can keep all of the arguments the same. # Read data file (but skip the variable names &amp; rows 1-2) # &amp; introduce variable names test &lt;- Read(&quot;PersData.csv&quot;, header=FALSE, skip=3, col.names=var_names) ## ## &gt;&gt;&gt; Suggestions ## To read a csv or Excel file of variable labels, var_labels=TRUE ## Each row of the file: Variable Name, Variable Label ## Details about your data, Enter: details() for d, or details(name) ## ## Data Types ## ------------------------------------------------------------ ## character: Non-numeric data values ## integer: Numeric data values, integers only ## ------------------------------------------------------------ ## ## Variable Missing Unique ## Name Type Values Values Values First and last values ## ------------------------------------------------------------------------------------------ ## 1 id integer 7 0 7 155 165 125 ... 198 201 282 ## 2 lastname character 7 0 7 Smith Doe ... Providence Legend ## 3 firstname character 7 0 6 John Jane ... Cindy John ## 4 startdate character 7 0 4 1/9/2016 1/4/2016 ... 1/9/2016 1/9/2016 ## 5 gender character 7 0 2 male female ... female male ## ------------------------------------------------------------------------------------------ # Print data frame object in Console print(test) ## id lastname firstname startdate gender ## 1 155 Smith John 1/9/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 111 Newton Isaac 1/9/2016 male ## 5 198 Morales Linda 1/7/2016 female ## 6 201 Providence Cindy 1/9/2016 female ## 7 282 Legend John 1/9/2016 male 13.4.3 List Data File Names in Working Directory If youre like me, and you save a lot of data files into a single folder, sometimes you find yourself flipping back and forth from RStudio to your file folder to see the exact names of the files when youre attempting to read them into your R environment. If you would like to obtain the exact names of files located in a (working) directory, the list.files function from base R comes in handy. This function will return a list of all file names within a particular directory or file names that meet a particular pattern. For our purposes, lets identify all of the .csv data file names contained within our current working directory. As the first argument, type path= followed by the path associated with your working directory. Second, because we are only pulling the file names associated with .csv files, enter the argument all.files=FALSE. Third, type the argument full.names=FALSE to indicate that we do not want the path to precede the file names. Finally, type the argument pattern=\".csv\" to request the names of only those file names that match the regular expression of .csv will be returned. # List data file names in working directory list.files(path=&quot;H:/RWorkshop&quot;, all.files=FALSE, full.names=FALSE, pattern=&quot;.csv&quot;) In your Console, you should see the list of file names you requested. You could then copy specific file names that you wish to read into R. "],["addnames.html", "Chapter 14 Removing and Adding Variable Names 14.1 Remove Variable Names from a Data Frame Object 14.2 Add Variable Names to a Data Frame Object 14.3 Summary", " Chapter 14 Removing and Adding Variable Names Upon reading data into a data frame object, you may encounter situations in which it makes sense to remove the variable names (and not the data associated with the variable names) or to add or replace variables names. In this chapter, you will learn simple techniques for removing the variable names (i.e., column names) from a data frame object and adding (or replacing) variable names in a data frame object. 14.0.0.1 Video Tutorial Link to video tutorial: https://youtu.be/3m32O9f8gAI 14.0.0.2 Functions &amp; Packages Introduced Function Package names base R c base R head base R 14.0.0.3 Initial Steps If you havent already, save the file called PersData.csv into a folder that you will subsequently set as your working directory. Your working directory will likely be different than the one shown below (i.e., \"H:/RWorkshop\"). As a reminder, you can access all of the data files referenced in this book by downloading them as a compressed (zipped) folder from the my GitHub site: https://github.com/davidcaughlin/R-Tutorial-Data-Files; once youve followed the link to GitHub, just click Code (or Download) followed by Download ZIP, which will download all of the data files referenced in this book. For the sake of parsimony, I recommend downloading all of the data files into the same folder on your computer, which will allow you to set that same folder as your working directory for each of the chapters in this book. Next, using the setwd function, set your working directory to the folder in which you saved the data file for this chapter. Alternatively, you can manually set your working directory folder in your drop-down menus by going to Session &gt; Set Working Directory &gt; Choose Directory. Be sure to create a new R script file (.R) or update an existing R script file so that you can save your script and annotations. If you need refreshers on how to set your working directory and how to create and save an R script, please refer to Setting a Working Directory and Creating &amp; Saving an R Script. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) Next, read in the .csv data file called PersData.csv using your choice of read function. In this example, I use the read_csv function from the readr package (Wickham and Hester 2020). If you choose to use the read_csv function, be sure that you have installed and accessed the readr package using the install.packages and library functions. Note: You dont need to install a package every time you wish to access it; in general, I would recommend updating a package installation once ever 1-3 months. For refreshers on installing packages and reading data into R, please refer to Packages and Reading Data into R. # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;readr&quot;) # Access readr package library(readr) # Read data and name data frame (tibble) object personaldata &lt;- read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) # View the names of the variables in the data frame (tibble) object names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; # View data frame (tibble) object personaldata ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male As you can see from the output generated in your console, the personaldata data frame object contains basic employee demographic information. The variable names include: id, lastname, firstname, startdate, and gender. Technically, the read_csv function reads in what is called a tibble object (as opposed to a data frame object), but for our purposes a tibble will behave similarly to a data frame. For more information on tibbles, check out Wickham and Grolemunds (2017) chapter on tibbles: http://r4ds.had.co.nz/tibbles.html. 14.1 Remove Variable Names from a Data Frame Object In some instances, you may wish to remove the variable names from a data frame. For example, I sometimes write (i.e., export) a data frame object Ive been cleaning in R so that I may use the data file with the statistical software program called Mplus (Muthn and Muthn 1998-2018). Because Mplus doesnt accept variable names within its data files, I may drop the variable names from the data frame object prior to writing to my working directory. To remove variable names, just apply the names function with the data frame name as the argument, and then use either the &lt;- operator with NULL to remove the variable names. # Remove variable names names(personaldata) &lt;- NULL # View just the first 6 rows of the data frame object in Console head(personaldata) ## # A tibble: 6 x 5 ## `` `` `` `` `` ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male As you can see, the variable names do not appear in the overwritten personaldata data frame object. 14.2 Add Variable Names to a Data Frame Object In other instances, you might find yourself with a dataset that lacks variable names (or has variable names that need to be replaced), which means that you will need to add those variable names to the data frame. Lets work with the personaldata data frame object from the previous section for practice. To add variable names, we can use the names function from base R, and enter the name of the data frame as the argument. Using the &lt;- operator, we can specify the variable names using the c (combine) function that contains a vector of variable names in quotation marks (\" \") as the arguments. Remember to type a comma (,) between the function arguments, as commas are used to separate arguments from one another when there are more than one. Please note that the its important that the vector of variable names contains the same number of names as the data frame object has columns. # Add (or replace) variable names to data frame object names(personaldata) &lt;- c(&quot;id&quot;, &quot;lastname&quot;, &quot;firstname&quot;, &quot;startdate&quot;, &quot;gender&quot;) # View just the first 6 rows of data in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male Now the data frame object has variable names! 14.3 Summary In this chapter, we reviewed how to remove variable names from a data frame object and how to add variable names to a data frame object using the names, colnames, and c functions, which all come standard with your base R installation. "],["write.html", "Chapter 15 Writing Data from R 15.1 Write Data Frame to Working Directory 15.2 Write Table to Working Directory 15.3 Summary", " Chapter 15 Writing Data from R Writing data refers to the process of exporting data from the R environment to a (working directory) folder. If you collaborate with others who do not work in R, writing data will allow them to use the data you cleaned, managed, or manipulated in the R environment in other software programs. In this chapter, we will focus on how to write a data frame and a table to our working directory folder as .csv files. 15.0.0.1 Video Tutorial As usual, you have the choice to follow along with the written tutorial in this chapter or to watch the video tutorial below. Link to Video Tutorial: https://youtu.be/ORTe8vE7nzU 15.0.0.2 Functions &amp; Packages Introduced Function Package write.csv base R write.table base R table base R 15.0.0.3 Initial Steps If you havent already, save the file called PersData.csv into a folder that you will subsequently set as your working directory. Your working directory will likely be different than the one shown below (i.e., \"H:/RWorkshop\"). As a reminder, you can access all of the data files referenced in this book by downloading them as a compressed (zipped) folder from the my GitHub site: https://github.com/davidcaughlin/R-Tutorial-Data-Files; once youve followed the link to GitHub, just click Code (or Download) followed by Download ZIP, which will download all of the data files referenced in this book. For the sake of parsimony, I recommend downloading all of the data files into the same folder on your computer, which will allow you to set that same folder as your working directory for each of the chapters in this book. Next, using the setwd function, set your working directory to the folder in which you saved the data file for this chapter. Alternatively, you can manually set your working directory folder in your drop-down menus by going to Session &gt; Set Working Directory &gt; Choose Directory. Be sure to create a new R script file (.R) or update an existing R script file so that you can save your script and annotations. If you need refreshers on how to set your working directory and how to create and save an R script, please refer to Setting a Working Directory and Creating &amp; Saving an R Script. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) Next, read in the .csv data file called PersData.csv using your choice of read function. In this example, I use the read_csv function from the readr package (Wickham and Hester 2020). If you choose to use the read_csv function, be sure that you have installed and accessed the readr package using the install.packages and library functions. Note: You dont need to install a package every time you wish to access it; in general, I would recommend updating a package installation once ever 1-3 months. For refreshers on installing packages and reading data into R, please refer to Packages and Reading Data into R. # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;readr&quot;) # Access readr package library(readr) # Read data and name data frame (tibble) object personaldata &lt;- read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) # View the names of the variables in the data frame (tibble) object names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; # View data frame (tibble) object personaldata ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male As you can see from the output generated in your console, the personaldata data frame object contains basic employee demographic information. The variable names include: id, lastname, firstname, startdate, and gender. Technically, the read_csv function reads in what is called a tibble object (as opposed to a data frame object), but for our purposes a tibble will behave similarly to a data frame. For more information on tibbles, check out Wickham and Grolemunds (2017) chapter on tibbles: http://r4ds.had.co.nz/tibbles.html. 15.1 Write Data Frame to Working Directory The write.csv function from base R can be used to write a data frame object to your working directory or to a folder of your choosing. Lets write the personaldata data frame (that we read in and named above) to our working directory. Before doing so, however, lets make a minor change to the data frame to illustrate a scenario in which you clean your data in R and then write the data to a .csv file so that a colleague can work with the data in another program. Specifically, lets remove the lastname variable from the data frame. To do so, type the name of the data frame (personaldata), followed by the $ symbol and then the name of the variable in question (lastname). Next, type the &lt;- operator followed by NULL. This code will remove the variable from the data frame. # Remove variable from data frame personaldata$lastname &lt;- NULL # View data frame object personaldata ## # A tibble: 9 x 4 ## id firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Alejandro 1/1/2016 male ## 2 154 Ronald 1/9/2016 male ## 3 155 John 1/9/2016 male ## 4 165 Jane 1/4/2016 female ## 5 125 Benjamin 1/5/2016 male ## 6 111 Isaac 1/9/2016 male ## 7 198 Linda 1/7/2016 female ## 8 201 Cindy 1/9/2016 female ## 9 282 John 1/9/2016 male As you can see in your Console output, the variable called lastname is no longer present in the data frame object. To write our cleaned\" data frame (personaldata) to our working directory, we use the write.csv function from base R. As the first argument in the parentheses, type the name of the data frame (personaldata). Remember to type a comma (,) before the second argument, as this is how we separate arguments from one another when there are more than one. As the second argument, lets type what we want to name the file that we will create in our working directory. Make sure that the name of the new .csv file is in quotation marks (\" \"). Here, I name the new file Cleaned PersData.csv; it is important that you keep the .csv extension at the end of the name you provide. # Write data frame to working directory write.csv(personaldata, &quot;Cleaned PersData.csv&quot;) If you go to your working directory folder, you will find the file called Cleaned PersData.csv saved there. We can also specify which folder that we want to write our data to using the full path extension and what we would like to name the new .csv file. # Write data frame to folder write.csv(personaldata, &quot;H:/RWorkshop/Cleaned PersData2.csv&quot;) If you go to your working directory folder, you will find the file called **\"Cleaned PersData2.csv*\"**. 15.2 Write Table to Working Directory Sometimes we work with table objects in R. If we wish to write a table to our working directory, we can use the write.table function from base R. Before doing so, we need to create a data table object as an example, which we can do using the table function from base R. To create a table, first, come up with a name for your new table object; in this example, I name the table table_example (because Im so creative). Second, type the &lt;- operator to the right of your new table name to tell R that you are creating a new object. Third, type the name of the table-creation function, which is table. Fourth, in the functions parentheses, as the first argument, enter the name of first variable you wish to use to make the table, and use the $ symbol to indicate that the variable (gender) belongs to the data frame in question (personaldata), which should look like this: personaldata$gender. Fifth, as the second argument, enter the name of the second variable you wish to use to make the table, and use the $ symbol to indicate that the variable (startdate) belongs to the data frame in question (personaldata), which should look like this: personaldata$startdate. # Create table from gender and startdate variables from personaldata data frame table_example &lt;- table(personaldata$gender, personaldata$startdate) # View table in Console table_example ## ## 1/1/2016 1/4/2016 1/5/2016 1/7/2016 1/9/2016 ## female 0 1 0 1 1 ## male 1 0 1 0 4 The table above shows how how many female versus male employees started working on a given date. Now we are ready to write the table called table_example to our working directory using the write.table function. As the first argument, type the name of the table object (table_example). Second, type what we would like to call the file when it is saved in our working directory (**\"Practice Table.csv\"**); be sure to include the .csv extension in the name and wrap it all in quotation marks. Third, use the sep=\",\" argument to specify that the values in the table are separated by commas, as this will be a comma separated values file. Fourth, add the argument col.names=NA to format the table such that the column names will be aligned with their respective values. The reason for this fourth argument is that in our table the first column will contain the row names of one of the variables; if we dont include this argument, the function will by default enter the name of the first column name associated with one of the levels of the variables in the first column, and because the first column actually contains the row names for the table, the row names will be off by one column. The col.names=NA argument simply leaves the first cell in the top row blank so that in the next column to the right, the first column name for one of the variables will appear. [To understand what the table would look like without this fourth argument, simply omit it, and open the resulting file in your working directory to see what happens.] # Write table to working directory write.table(table_example, &quot;Practice Table.csv&quot;, sep=&quot;,&quot;, col.names=NA) If you go to your working directory, you will find the file called Practice Table.csv. 15.3 Summary Writing data from the R environment to your working directory or another folder can be useful, especially when collaborating with those who do not use R. The write.csv function writes a data frame object to a .csv file, whereas the write.table function writes a data table object to a .csv file. "],["arrange.html", "Chapter 16 Arranging (Sorting) Data 16.1 Arrange (Sort) Data 16.2 Summary", " Chapter 16 Arranging (Sorting) Data Arranging (sorting) data refers to the process of ordering rows numerically or alphabetically in a data frame by the values of one or more variables. When sorting data in R, the underlying source data file does not change; rather, the data frame object in the R Global Environment changes. Sorting can make it easier to visually scan raw data, particularly when used in conjunction with the View, head, or tail functions from base R. 16.0.0.1 Video Tutorial As usual, you have the choice to follow along with the written tutorial in this chapter or to watch the video tutorial below. Both versions of the tutorial will show you how to arrange (sort) data with or without the pipe (%&gt;%) operator. If youre unfamiliar with the pipe operator, no need to worry: I provide a brief explanation and demonstration regarding their purpose in both versions of the tutorial. Link to Video Tutorial: https://youtu.be/wVwJQsLNbmw 16.0.0.2 Functions &amp; Packages Introduced Function Package arrange dplyr desc dplyr 16.0.0.3 Initial Steps Please note, that any function that appears in the Initial Steps section has been covered in a previous chapter. If you need a refresher, please view the relevant chapter. In addition, a previous chapter may show you how to perform the same action using different functions or packages. If you havent already, save the file called PersData.csv into a folder that you will subsequently set as your working directory. Your working directory will likely be different than the one shown below (i.e., \"H:/RWorkshop\"). As a reminder, you can access all of the data files referenced in this book by downloading them as a compressed (zipped) folder from the my GitHub site: https://github.com/davidcaughlin/R-Tutorial-Data-Files; once youve followed the link to GitHub, just click Code (or Download) followed by Download ZIP, which will download all of the data files referenced in this book. For the sake of parsimony, I recommend downloading all of the data files into the same folder on your computer, which will allow you to set that same folder as your working directory for each of the chapters in this book. Next, using the setwd function, set your working directory to the folder in which you saved the data file for this chapter. Alternatively, you can manually set your working directory folder in your drop-down menus by going to Session &gt; Set Working Directory &gt; Choose Directory. Be sure to create a new R script file (.R) or update an existing R script file so that you can save your script and annotations. If you need refreshers on how to set your working directory and how to create and save an R script, please refer to Setting a Working Directory and Creating &amp; Saving an R Script. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) Next, read in the .csv data file called PersData.csv using your choice of read function. In this example, I use the read_csv function from the readr package (Wickham and Hester 2020). If you choose to use the read_csv function, be sure that you have installed and accessed the readr package using the install.packages and library functions. Note: You dont need to install a package every time you wish to access it; in general, I would recommend updating a package installation once ever 1-3 months. For refreshers on installing packages and reading data into R, please refer to Packages and Reading Data into R. # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;readr&quot;) # Access readr package library(readr) # Read data and name data frame (tibble) object personaldata &lt;- read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) # View the names of the variables in the data frame (tibble) object names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; # View data frame (tibble) object personaldata ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male As you can see from the output generated in your console, the personaldata data frame object contains basic employee demographic information. The variable names include: id, lastname, firstname, startdate, and gender. Technically, the read_csv function reads in what is called a tibble object (as opposed to a data frame object), but for our purposes a tibble will behave similarly to a data frame. For more information on tibbles, check out Wickham and Grolemunds (2017) chapter on tibbles: http://r4ds.had.co.nz/tibbles.html. 16.1 Arrange (Sort) Data There are different functions we could use to arrange (sort) the data in the data frame, and in this chapter, we will focus on the arrange function from the dplyr package (Wickham et al. 2021). Please note that there are other functions we could use to sort data, and if youre interested, in the Arranging (Sorting) Data: Chapter Supplement, I demonstrate how to use the order function from base R to carry out the same operations we will cover below. Because the arrange function comes from the dplyr package, which is part of the tidyverse of R packages (Wickham 2021; Wickham et al. 2019). If you havent already, install and access the dplyr package using the install.packages and library functions, respectively. # Install dplyr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;dplyr&quot;) # Access dplyr package library(dplyr) Before diving into arranging the data, as a disclaimer, I will demonstrate two techniques for arranging (sorting) data using the arrange function. The first technique uses a pipe which in R is represented by the %&gt;% operator. The pipe operator comes from a package called magrittr (Bache and Wickham 2020), on which the dplyr is partially dependent. In short, a pipe allows a person to more efficiently write code and to improve the readability of the code and overall script. Specifically, a pipe forwards the result or value of one object or expression to a subsequent function. In doing so, one can avoid writing functions in which other functions are nested parenthetically. For more information on the pipe operator, check out Wickham and Grolemunds (2017) chapter on pipes: https://r4ds.had.co.nz/pipes.html. This brings us to the second technique for arranging (sorting) data using the arrange function. The second technique uses a more traditional approach that some may argue lacks the efficiency and readability of the pipe. Conversely, others may argue against the use of pipes altogether. Im not here to settle any pipes versus no pipes debate, and youre welcome to use either technique. If you dont want to learn how to use pipes (or would like to learn how to use them at a later date), feel free to skip to the section below called Without Pipe. 16.1.1 With Pipe To use the with pipe technique, first, type the name of our data frame object, which we previously named personaldata, followed by the pipe (%&gt;%) operator. This will pipe our data frame into the subsequent function. Second, either on the same line or on the next line, type the name of the arrange function, and within the parentheses, enter the variable name startdate as the argument to indicate that we want to arrange (sort) the data by the start date of the employees. The default operation of the arrange function is to arrange (sort) the data in ascending order. If youre wondering where I found the exact names of the variables in the data frame, revisit the use of the names function, which I demonstrated previously in this chapter in the Initial Steps section. # Arrange (sort) data by variable in ascending order (single line) (with pipe) personaldata %&gt;% arrange(startdate) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 198 Morales Linda 1/7/2016 female ## 5 154 McDonald Ronald 1/9/2016 male ## 6 155 Smith John 1/9/2016 male ## 7 111 Newton Isaac 1/9/2016 male ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male Alternatively, we can write this script over two lines and achieve the same output in our Console. # Arrange (sort) data by variable in ascending order (two lines) (with pipe) personaldata %&gt;% arrange(startdate) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 198 Morales Linda 1/7/2016 female ## 5 154 McDonald Ronald 1/9/2016 male ## 6 155 Smith John 1/9/2016 male ## 7 111 Newton Isaac 1/9/2016 male ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male Please note that the operations we have performed thus far have not changed anything in the personaldata data frame object itself; rather, the output in the Console simply shows what it looks like if the data are sorted by the variable in question. We can verify this by viewing the first six rows of data in our data frame object using the head function. As you can see below, nothing changed in the data frame itself. # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male To change the ordering of data in the personaldata data frame object itself, we will need to (re)name the data frame object using the &lt;- variable assignment operator. In this example, I will demonstrate how to overwrite the existing data frame object, and thus I give the data frame object the exact same name as it had originally (i.e., personaldata). To do so, to the left of the &lt;- operator, type what you would like to name the new (updated) sorted data frame object (personaldata). Next, to the right of the &lt;- operator, copy and paste the same code we wrote above. Finally, use the head function from base R to view the first six rows of the new data frame object. # Arrange (sort) data by variable in ascending order and # overwrite existing data frame object (with pipe) personaldata &lt;- personaldata %&gt;% arrange(startdate) # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 198 Morales Linda 1/7/2016 female ## 5 154 McDonald Ronald 1/9/2016 male ## 6 155 Smith John 1/9/2016 male As you can see in the Console output, now the personaldata data frame object has been changed such that the data are arranged (sorted) by the startdate variable. To arrange the data in descending order, just use the desc function from dplyr within the arrange function as shown below. # Arrange (sort) data by variable in ascending order and # overwrite existing data frame object (with pipe) personaldata &lt;- personaldata %&gt;% arrange(desc(startdate)) # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 154 McDonald Ronald 1/9/2016 male ## 2 155 Smith John 1/9/2016 male ## 3 111 Newton Isaac 1/9/2016 male ## 4 201 Providence Cindy 1/9/2016 female ## 5 282 Legend John 1/9/2016 male ## 6 198 Morales Linda 1/7/2016 female To arrange (sort) data by values/levels of two variables, we simply enter the names of two variables as consecutive arguments. Lets enter the gender variable first, followed by the startdate variable. The ordering of the two variables matters; the function sorts initially by the values/levels of the first variable listed and sorts subsequently by the values/levels of the second variable listed, but does so within the values/levels of the first variable listed. As shown below, startdate is sorted within the sorted levels of the gender variable. As a reminder, the default operation of the arrange function is to arrange (sort) the data in ascending order. Remember, we use commas to separate arguments used in a function (if there are more than one arguments). # Arrange (sort) data by two variables in ascending order (with pipe) personaldata %&gt;% arrange(gender, startdate) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 165 Doe Jane 1/4/2016 female ## 2 198 Morales Linda 1/7/2016 female ## 3 201 Providence Cindy 1/9/2016 female ## 4 153 Sanchez Alejandro 1/1/2016 male ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 154 McDonald Ronald 1/9/2016 male ## 7 155 Smith John 1/9/2016 male ## 8 111 Newton Isaac 1/9/2016 male ## 9 282 Legend John 1/9/2016 male Watch what happens when we switch the order of the two variables we are using to sort the data. # Arrange (sort) data by two variables in ascending order (with pipe) personaldata %&gt;% arrange(startdate, gender) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 198 Morales Linda 1/7/2016 female ## 5 201 Providence Cindy 1/9/2016 female ## 6 154 McDonald Ronald 1/9/2016 male ## 7 155 Smith John 1/9/2016 male ## 8 111 Newton Isaac 1/9/2016 male ## 9 282 Legend John 1/9/2016 male As you can see, the order of the two sorting variables matters. To arrange the data in descending order, just use the desc function from dplyr within the arrange function. # Arrange (sort) data by variable in descending order (with pipe) personaldata %&gt;% arrange(desc(gender,startdate)) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 154 McDonald Ronald 1/9/2016 male ## 2 155 Smith John 1/9/2016 male ## 3 111 Newton Isaac 1/9/2016 male ## 4 282 Legend John 1/9/2016 male ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 153 Sanchez Alejandro 1/1/2016 male ## 7 201 Providence Cindy 1/9/2016 female ## 8 198 Morales Linda 1/7/2016 female ## 9 165 Doe Jane 1/4/2016 female Or, we can sort one variable in the default ascending order and the other in descending order. # Arrange (sort) data by two variables in ascending &amp; descending order (with pipe) personaldata %&gt;% arrange(gender, desc(startdate)) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 201 Providence Cindy 1/9/2016 female ## 2 198 Morales Linda 1/7/2016 female ## 3 165 Doe Jane 1/4/2016 female ## 4 154 McDonald Ronald 1/9/2016 male ## 5 155 Smith John 1/9/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 282 Legend John 1/9/2016 male ## 8 125 Franklin Benjamin 1/5/2016 male ## 9 153 Sanchez Alejandro 1/1/2016 male 16.1.2 Without Pipe We can achieve the same output without using the pipe (%&gt;%) operator as with the pipe operator; again, your choice of using or not using the pipe operator is up to you. To use the arrange function without the pipe operator, type the name of the arrange function, and within the parentheses, as the first argument, type the name of the personaldata data frame object, and as the second argument, type the startdate variable, where the latter indicates that we want to arrange (sort) the data frame object by the start date of the employees. The default operation of the arrange function is to arrange (sort) the data in ascending order. Remember, we use commas to separate arguments used in a function (if there are more than one arguments). If youre wondering where I found the exact names of the variables in the data frame, revisit the use of the names function, which I demonstrated previously in this chapter in the Initial Steps section. # Arrange (sort) data by variable in ascending order without pipe arrange(personaldata, startdate) ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 198 Morales Linda 1/7/2016 female ## 5 154 McDonald Ronald 1/9/2016 male ## 6 155 Smith John 1/9/2016 male ## 7 111 Newton Isaac 1/9/2016 male ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male To change the ordering of data in the personaldata data frame object itself, we will need to (re)name the data frame object using the &lt;- variable assignment operator. In this example, I will demonstrate how to overwrite the existing data frame object, and thus I give the data frame object the exact same name as it had originally (i.e., personaldata). To do so, to the left of the &lt;- operator, type what you would like to name the new (updated) sorted data frame object (personaldata). Next, to the right of the &lt;- operator, copy and paste the same code we wrote above. Finally, use the head function from base R to view the first six rows of the new data frame object. # Arrange (sort) data by variable in ascending order and # overwrite existing data frame object without pipe personaldata &lt;- arrange(personaldata, startdate) # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 198 Morales Linda 1/7/2016 female ## 5 154 McDonald Ronald 1/9/2016 male ## 6 155 Smith John 1/9/2016 male To arrange the data in descending order, just use the desc function from dplyr within the arrange function as shown below. # Arrange (sort) data by variable in descending order and # overwrite existing data frame object without pipe personaldata &lt;- arrange(personaldata, desc(startdate)) # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 154 McDonald Ronald 1/9/2016 male ## 2 155 Smith John 1/9/2016 male ## 3 111 Newton Isaac 1/9/2016 male ## 4 201 Providence Cindy 1/9/2016 female ## 5 282 Legend John 1/9/2016 male ## 6 198 Morales Linda 1/7/2016 female To arrange (sort) data by values/levels of two variables, we simply enter the names of two variables as consecutive arguments (after the name of the data frame, which is the first argument). Lets enter the gender variable first, followed by the startdate variable. The ordering of the two variables matters; the function sorts initially by the values/levels of the first variable listed and sorts subsequently by the values/levels of the second variable listed, but does so within the values/levels of the first variable listed. # Arrange (sort) data by variable in ascending order without pipe personaldata &lt;- arrange(personaldata, gender, startdate) As shown in the output above, startdate is sorted within the sorted levels of the gender variable. This also verifies that the default operation of the arrange function is to arrange (sort) the data in ascending order. To arrange the data in descending order, just use the desc function from dplyr within the arrange function as shown below. You can use the desc function on one or both sorting variables. # Arrange (sort) data by one variable in ascending order and # the other in descending order without pipe personaldata &lt;- arrange(personaldata, gender, desc(startdate)) Or we can apply the desc function to both variables. # Arrange (sort) data by both variables descending order without pipe personaldata &lt;- arrange(personaldata, desc(gender, startdate)) 16.2 Summary In this chapter, we learned how to arrange (sort) data by one or more variables using the arrange and desc functions from the dplyr package. This chapter also introduced the pipe (%&gt;%) operator, which can help make code easier to read in some contexts. "],["join.html", "Chapter 17 Joining (Merging) Data 17.1 Horizontal Join (Merge) 17.2 Vertical Join (Merge) 17.3 Summary", " Chapter 17 Joining (Merging) Data Joining refers to the process of matching two data frames by either one or more key variables (i.e., horizontal join) or by variable names or columns (i.e., vertical join). Sometimes a join is referred to as a merge, and thus I will use these terms interchangeably. Broadly speaking, there are two types of joins (merges): horizontal and vertical. 17.0.0.1 Joining Data Horizontally A horizontal join (merge) refers to the process of matching cases (i.e., rows, observations) between two data frames using a key variable (matching variable), which results in distinct sets of variables (i.e., fields, columns) being combined horizontally (laterally) across two data frames. The resulting joined data frame will be wider (in terms of the number of variables) than either of the original data frames in isolation. For example, imagine that we pull data from separate information systems, each with different variables (i.e., fields) but at least some employees (i.e., cases) in common; to combine these two data frames, we can perform a horizontal join. This is often a necessary step when creating a data frame that contains all of the variables we will need in subsequent data analyses. For instance, if we wish to estimate the criterion-related validities (see Selection Tool Validation) using the selection tool scores from one data frame with criterion (e.g., job performance) scores from another data frame, then we could perform a horizontal join. In a horizontal join, cases (or observations) are matched between two data frames using one or more key variables. We will focus on four different types of horizontal joins: Inner join: All unmatched cases (or observations) are dropped, thereby retaining only those cases that are present in both the left (x, first) and right (y, second) data frames. In other words, a case is only included in the merged data frame if it appears in both of the original data data frames. In an inner join, all unmatched cases (or observations) are dropped, thereby retaining only those cases that are present in both the left (x, first) and right (y, second) data frames. Full join: All cases (or observations) are retained, including those cases that do not have a match in the other data data frame. In other words, a case is included in the merged data frame even if it only appears in one of the original data data frames. These type of join leads to the highest number of retained cases under conditions in which both data frames contain unique cases. In a full join, all cases (or observations) are retained, including those cases that do not have a match in the other data data frame. Left join: All cases (or observations) that appear in the left (x, first) data frame are retained, even if they lack a match in the right (y, second) data frame. Consequently, cases from the right data frame that lack a match in the left data frame are dropped in the merged data frame. In a left join, all cases (or observations) that appear in the left (x, first) data frame are retained, even if they lack a match in the right (y, second) data frame. Right join: All cases (or observations) that appear in the right (y, second) data frame are retained, even if they lack a match in the left (x, first) data frame. Consequently, cases from the left data frame that lack a match in the right data frame are dropped in the merged data frame. In a left join, only cases (or observations) that appear in the left (x, first) data frame are retained, even if they lack a match in the right (y, second) data frame. Please note that I have illustrated different types of horizontal joins using a single key variable. It is entirely possible to perform horizontal joins using two or more key variables. For example, imagine that each morning we administered a pulse survey to employees and each afternoon we afternoon we administered a different pulse survey to the same employees, and that we repeated this process for five consecutive workdays. In this instance, we would likely need to horizontally join the data frames using both a unique employee identifier variable and a unique day-of-week variable. 17.0.0.2 Joining Data Vertically A vertical join (merge) refers to the process of matching identical variables from two data frames, which results in distinct sets of cases or observations being combined vertically. The resulting joined data frame will be longer (in terms of the number of cases) than either of the original data frames in isolation. For example, imagine an organization administered the same survey to two facilities (i.e., independent groups) each with unique employees; we could combine the two resulting data frames by performing a vertical join. In a vertical join, identical variables are matched between two data frames, each with distinct sets of cases or observations. 17.0.0.3 Video Tutorial As usual, you have the choice to follow along with the written tutorial in this chapter or to watch the video tutorial below. Both versions of the tutorial will show you how to join (merge) data with or without the pipe (%&gt;%) operator. If youre unfamiliar with the pipe operator, no need to worry: I provide a brief explanation and demonstration regarding their purpose in both versions of the tutorial. Link to Video Tutorial: https://youtu.be/38zsLj-fWo0 17.0.0.4 Functions &amp; Packages Introduced Function Package merge base R right_join dplyr left_join dplyr inner_join dplyr full_join dplyr data.frame base R c base R rep base R rbind base R 17.0.0.5 Initial Steps If you havent already, save the files called PersData.csv and PerfData.csv into a folder that you will subsequently set as your working directory. Your working directory will likely be different than the one shown below (i.e., \"H:/RWorkshop\"). As a reminder, you can access all of the data files referenced in this book by downloading them as a compressed (zipped) folder from the my GitHub site: https://github.com/davidcaughlin/R-Tutorial-Data-Files; once youve followed the link to GitHub, just click Code (or Download) followed by Download ZIP, which will download all of the data files referenced in this book. For the sake of parsimony, I recommend downloading all of the data files into the same folder on your computer, which will allow you to set that same folder as your working directory for each of the chapters in this book. Next, using the setwd function, set your working directory to the folder in which you saved the data file for this chapter. Alternatively, you can manually set your working directory folder in your drop-down menus by going to Session &gt; Set Working Directory &gt; Choose Directory. Be sure to create a new R script file (.R) or update an existing R script file so that you can save your script and annotations. If you need refreshers on how to set your working directory and how to create and save an R script, please refer to Setting a Working Directory and Creating &amp; Saving an R Script. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) Next, read in the .csv data files called PersData.csv and PerfData.csv using your choice of read function. In this example, I use the read_csv function from the readr package (Wickham and Hester 2020). If you choose to use the read_csv function, be sure that you have installed and accessed the readr package using the install.packages and library functions. Note: You dont need to install a package every time you wish to access it; in general, I would recommend updating a package installation once ever 1-3 months. For refreshers on installing packages and reading data into R, please refer to Packages and Reading Data into R. # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;readr&quot;) # Access readr package library(readr) # Read data and name data frame (tibble) objects personaldata &lt;- read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) performancedata &lt;- read_csv(&quot;PerfData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## perf_q1 = col_double(), ## perf_q2 = col_double(), ## perf_q3 = col_double(), ## perf_q4 = col_double() ## ) # View the names of the variables in the data frame (tibble) objects names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; names(performancedata) ## [1] &quot;id&quot; &quot;perf_q1&quot; &quot;perf_q2&quot; &quot;perf_q3&quot; &quot;perf_q4&quot; # View data frame (tibble) objects personaldata ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male performancedata ## # A tibble: 6 x 5 ## id perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 3.9 4.8 4.9 5 ## 2 125 2.1 1.9 2.1 2.3 ## 3 111 3.3 3.3 3.4 3.3 ## 4 198 4.9 4.5 4.4 4.8 ## 5 201 1.2 1.1 1 1 ## 6 282 2.2 2.3 2.4 2.5 As you can see from the output generated in your console, on the one hand, the personaldata data frame object contains basic employee demographic information. The variable names include: id, lastname, firstname, startdate, and gender. On the other hand, the personaldata data frame object contains the same id unique identifer variable as the personaldata data frame object, but instead of employee demographic information, this data frame object includes varuables associated with quarterly employee performance: perf_q1, perf_q2, perf_q3, and perf_q4. In order to better illustrate certain join functions later on in this chapter, well begin by removing the case (i.e., employee) associated with the id variable value of 153 (i.e., Alejandro Sanchez); in terms of a rationale for doing so, lets imagine that Alejandro no longer works for the organization, and thus we would like to remove him from the personaldata data frame. If you dont completely understand the following process for removing this individual from the data frame, no need to worry, as you will learn more in the subsequent chapter on filtering data. Type the name of the data frame object (personaldata) followed by the &lt;- operator to overwrite the existing data frame object. Type the name of the original data frame object (personaldata) followed by brackets ([ ]). Within the brackets ([ ]), type the name of the data frame object (personaldata) again, followed by the $ operator and the name of the variable we wish to use to select the case that will be removed, which in this instance is the id unique identifier variable. The $ operator indicates to R that the id variable belongs to the personaldata data frame. Type the not equal to operator, which is != (the ! means not), followed by the id variable value we wish to use to remove the case (i.e., 153). Type a comma (,) to indicate that we are removing a row, not a column. When referencing rows and columns in R, as we are doing in the brackets ([ ]), rows are entered first (before a comma), and columns are entered second (after a comma). In doing so, we are telling R to retain all rows of data in personaldata except for the one corresponding to id equal to 153. # Remove case with id variable equal to 153 personaldata &lt;- personaldata[personaldata$id != 153,] Check out the first 6 rows of the updated data frame for personaldata, and note that the data corresponding to the case associated with id equal to 153 is gone. # View first 6 rows of first data frame object once more head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 154 McDonald Ronald 1/9/2016 male ## 2 155 Smith John 1/9/2016 male ## 3 165 Doe Jane 1/4/2016 female ## 4 125 Franklin Benjamin 1/5/2016 male ## 5 111 Newton Isaac 1/9/2016 male ## 6 198 Morales Linda 1/7/2016 female 17.1 Horizontal Join (Merge) Recall that a horizontal join (merge) means that cases are matched using one more more key variables, and as a result, variables (i.e., columns, fields) are combined across two data frames. We will review two options for performing horizontal joins. To perform horizontal joins, we will learn how to use the join functions from the the dplyr package (Wickham et al. 2021), which include: right_join, left_join, inner_join, and full_join. Please note that there are other functions we could use to perform horizontal joins, and if youre interested, in the Joining (Merging) Data: Chapter Supplement, I demonstrate how to use the merge function from base R to carry out the same operations we will cover below. Using the aformentioned join functions, we will match cases from the personaldata and performancedata data frames using the id unique identifer variable as a key variable. So how can we verify that id is an appropriate key variable? Well, lets use the names function from base R to retrieve the list of variable names from the two data frames, which we already did above. Nevertheless, lets call up those variable names once more. Simply enter the name of the data frame as a parenthetical argument in the names function. # Retrieve variable names from first data frame names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; # Retrieve variable names from second data frame names(performancedata) ## [1] &quot;id&quot; &quot;perf_q1&quot; &quot;perf_q2&quot; &quot;perf_q3&quot; &quot;perf_q4&quot; As you can see in the variable names listed above, the id variable is common to both data frames, and thus it will serve as our key variable. Now we are almost ready to begin joining the two data frames using the id unique identifer as a key variable. Before doing so, however, we should make sure that we have installed and accessed the dplyr package (if we havent already), as the join functions come from that package. # Install dplyr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;dplyr&quot;) # Access dplyr package library(dplyr) I will demonstrate two techniques for applying the join function. The first technique uses the pipe operator (%&gt;%). The pipe operator comes from a package called magrittr (Bache and Wickham 2020), on which the dplyr is partially dependent. In short, a pipe allows a person to more efficiently write code and to improve the readability of the code and overall script. Specifically, a pipe forwards the result or value of one object or expression to a subsequent function. In doing so, one can avoid writing functions in which other functions are nested parenthetically. For more information on the pipe operator, check out Wickham and Grolemunds (2017) chapter on pipes: https://r4ds.had.co.nz/pipes.html. The second technique for applying the join function takes a more traditional approach in that it involves nested functions being nested parenthetically. If you dont want to learn how to use pipes (or would like to learn how to use them at a later date), feel free to skip to the section below called Without Pipe. 17.1.1 With Pipe Using the pipe (%&gt;%) operator technique, lets begin with what is referred to as an inner join by doing the following: Use the &lt;- symbol to name the joined (merged) data frame that we will create using the one of the dplyr join functions. For this example, I name the new joined data frame mergeddf, which is completely arbitrary; you could name it whatever you would like. Make sure you put the name of the new data frame object to the left of the &lt;- operator. To the right of the &lt;- operator, type the name of the first data frame, which we named personaldata, followed by the pipe (%&gt;%) operator. This will pipe our data frame into the subsequent function. On the same line or on the next line, type the inner_join function, and within the parentheses as the first argument, type the name of the second data frame, which we called performancedata. As the second argument, use the by= argument to indicate the name of the key variable, which in this example is id; make sure the key variable is in quotation marks (\" \"), and remember, object and variable names in R are case and space sensitive. # Inner join (with pipe) mergeddf &lt;- personaldata %&gt;% inner_join(performancedata, by=&quot;id&quot;) # View the joined data frame mergeddf ## # A tibble: 5 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 2 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 3 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 4 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 5 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Now, lets revisit the original data frame objects that we read in initially. # View the first original data frame personaldata ## # A tibble: 8 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 154 McDonald Ronald 1/9/2016 male ## 2 155 Smith John 1/9/2016 male ## 3 165 Doe Jane 1/4/2016 female ## 4 125 Franklin Benjamin 1/5/2016 male ## 5 111 Newton Isaac 1/9/2016 male ## 6 198 Morales Linda 1/7/2016 female ## 7 201 Providence Cindy 1/9/2016 female ## 8 282 Legend John 1/9/2016 male # View the second original data frame performancedata ## # A tibble: 6 x 5 ## id perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 3.9 4.8 4.9 5 ## 2 125 2.1 1.9 2.1 2.3 ## 3 111 3.3 3.3 3.4 3.3 ## 4 198 4.9 4.5 4.4 4.8 ## 5 201 1.2 1.1 1 1 ## 6 282 2.2 2.3 2.4 2.5 In the output, first, note how all of the variables from the original data frames (i.e., personaldata, performancedata) are represented in the merged data frame (i.e., mergeddf). Second, note how the cases are matched by the id key variable. Third, note that the personaldata data frame has 8 cases, the performancedata data frame has 6 cases, and the mergeddf data frame has 6 cases. By default, the merge function performs an inner join and retains only those matched cases that have data in both data frames. Because cases whose id values were 154, 155, and 165 had data in personaldata but not performancedata and because the case with an id value equal to 153 was in performancedata but not personaldata, only the 5 cases that had available data in both data frames were retained. To perform what is referred to as a full join in which we retain all cases and available data, we simply swap out the inner_join function from our previous code with the full_join function. # Full join (with pipe) mergeddf &lt;- personaldata %&gt;% full_join(performancedata, by=&quot;id&quot;) # View the joined data frame mergeddf ## # A tibble: 9 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 2 155 Smith John 1/9/2016 male NA NA NA NA ## 3 165 Doe Jane 1/4/2016 female NA NA NA NA ## 4 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 5 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 6 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 7 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 8 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 ## 9 153 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3.9 4.8 4.9 5 Note how the full_join function retains all available cases that had available data in at least one of the data frames, which in this example is 9 cases. When in doubt, I recommend using the full_join function to retain all available data. To perform what is referred to as a left join in which we retain only those cases with data available in the first (left, x) data frame (personaldata), we use the left_join function instead, while keeping the rest of the previous code the same. # Left join (with pipe) mergeddf &lt;- personaldata %&gt;% left_join(performancedata, by=&quot;id&quot;) # View the joined data frame mergeddf ## # A tibble: 8 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 2 155 Smith John 1/9/2016 male NA NA NA NA ## 3 165 Doe Jane 1/4/2016 female NA NA NA NA ## 4 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 5 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 6 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 7 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 8 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Note how the left_join function retains only those cases for which the first (left, x) data frame (i.e., personaldata) has complete data, which in this case happens to be 8 cases. Notably absent is the case associated with id equal to 153 because the first (left, x) data frame (i.e., personaldata) lacked that case. An NA appears for each case from the second (right, y) data frame that contained missing values on variables from that data frame. To perform what is referred to as a right join in which we retain only those cases with data available in the second (right, y) data frame (performancedata), we use the right_join function instead, while keeping the rest of the previous code the same. # Right join (with pipe) mergeddf &lt;- personaldata %&gt;% right_join(performancedata, by=&quot;id&quot;) # View the joined data frame mergeddf ## # A tibble: 6 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 2 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 3 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 4 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 5 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 ## 6 153 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3.9 4.8 4.9 5 Note how the right_join function retains only those cases for which the joined (second, right, y) data frame (i.e., performancedata) has complete data. Because the first (left, x) data frame lacks data for the case in which id is equal to 153, an NA appears for each case from the first data frame that contained missing values on variables from that data frame. 17.1.2 Without Pipe In this section, I demonstrate the same dplyr join functions as above, except here I demonstrate how to specify the functions without the use of a pipe (%&gt;%) operator. Lets begin with what is referred to as an inner join by doing the following: Use the &lt;- operator to name the joined (merged) data frame that we will create using the one of the dplyr join functions. For this example, I name the new joined data frame mergeddf, which is completely arbitrary; you could name it whatever you would like. Make sure you put the name of the new data frame object to the left of the &lt;- operator. To the right of the &lt;- operator, type the name of the inner_join function. As the first argument within the parentheses, type the name of the first data frame, which we named personaldata. As the second argument, type the name of the second data frame we named performancedata. As the third argument, use the by= argument to indicate the name of the key variable, which in this example is id; make sure the key variable is in quotation marks (\" \"), and remember, object and variable names in R are case and space sensitive. # Inner join (without pipe) mergeddf &lt;- inner_join(personaldata, performancedata, by=&quot;id&quot;) # View the joined data frame mergeddf ## # A tibble: 5 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 2 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 3 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 4 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 5 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Now, lets revisit the original data frame objects that we read in initially. # View the first original data frame personaldata ## # A tibble: 8 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 154 McDonald Ronald 1/9/2016 male ## 2 155 Smith John 1/9/2016 male ## 3 165 Doe Jane 1/4/2016 female ## 4 125 Franklin Benjamin 1/5/2016 male ## 5 111 Newton Isaac 1/9/2016 male ## 6 198 Morales Linda 1/7/2016 female ## 7 201 Providence Cindy 1/9/2016 female ## 8 282 Legend John 1/9/2016 male # View the second original data frame performancedata ## # A tibble: 6 x 5 ## id perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 3.9 4.8 4.9 5 ## 2 125 2.1 1.9 2.1 2.3 ## 3 111 3.3 3.3 3.4 3.3 ## 4 198 4.9 4.5 4.4 4.8 ## 5 201 1.2 1.1 1 1 ## 6 282 2.2 2.3 2.4 2.5 In the output, first, note how all of the variables from the original data frames (i.e., personaldata, performancedata) are represented in the merged data frame (i.e., mergeddf). Second, note how the cases are matched by the id key variable. Third, note that the personaldata data frame has 8 cases, the performancedata data frame has 6 cases, and the mergeddf data frame has 6 cases. By default, the merge function performs an inner join and retains only those matched cases that have data in both data frames. Because cases whose id values were 154, 155, and 165 had data in personaldata but not performancedata and because the case with an id value equal to 153 was in performancedata but not personaldata, only the 5 cases that had available data in both data frames were retained. To perform what is referred to as a full join in which we retain all cases and available data, we simply swap out the inner_join function from our previous code with the full_join function. # Full join (without pipe) mergeddf &lt;- full_join(personaldata, performancedata, by=&quot;id&quot;) # View the joined data frame mergeddf ## # A tibble: 9 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 2 155 Smith John 1/9/2016 male NA NA NA NA ## 3 165 Doe Jane 1/4/2016 female NA NA NA NA ## 4 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 5 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 6 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 7 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 8 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 ## 9 153 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3.9 4.8 4.9 5 Note how the full_join function retains all available cases that had available data in at least one of the data frames, which in this example is 9 cases. When in doubt, I recommend using the full_join function to retain all available data. To perform what is referred to as a left join in which we retain only those cases with data available in the first (left, x) data frame (personaldata), we use the left_join function instead, while keeping the rest of the previous code the same. # Left join (without pipe) mergeddf &lt;- left_join(personaldata, performancedata, by=&quot;id&quot;) # View the joined data frame mergeddf ## # A tibble: 8 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 2 155 Smith John 1/9/2016 male NA NA NA NA ## 3 165 Doe Jane 1/4/2016 female NA NA NA NA ## 4 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 5 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 6 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 7 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 8 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Note how the left_join function retains only those cases for which the first (left, x) data frame (i.e., personaldata) has complete data, which in this case happens to be 8 cases. Notably absent is the case associated with id equal to 153 because the first (left, x) data frame (i.e., personaldata) lacked that case. An NA appears for each case from the second (right, y) data frame that contained missing values on variables from that data frame. To perform what is referred to as a right join in which we retain only those cases with data available in the second (right, y) data frame (performancedata), we use the right_join function instead, while keeping the rest of the previous code the same. # Right join (without pipe) mergeddf &lt;- right_join(personaldata, performancedata, by=&quot;id&quot;) # View the joined data frame mergeddf ## # A tibble: 6 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 2 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 3 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 4 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 5 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 ## 6 153 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3.9 4.8 4.9 5 Note how the right_join function retains only those cases for which the joined (second, right, y) data frame (i.e., performancedata) has complete data. Because the first (left, x) data frame lacks data for the case in which id is equal to 153, an NA appears for each case from the first data frame that contained missing values on variables from that data frame. 17.2 Vertical Join (Merge) To perform a vertical join (merge), we will use the rbind function from base R, which stands for row bind. As a reminder, with a horizontal join, our focus is on joining variables (i.e., columns, fields) from two data frames containing overlapping cases (i.e., rows). In contrast, with a vertical join, our focus is on joining cases from data frames with the same variables. To illustrate how to perform a vertical join, we take a slightly different approach than what we did with horizontal joins. Instead of reading in data files, we will create two toy employee demographic data frames with the exact same variables but different cases. We will use the data.frame function from base R to indicate that we wish to create a data frame object; we use the c (combine) function from base R to combine values into a vector; and we use the rep (replicate) function from base R to replicate the same value a specified number of times. Also note that the : operator, when used between two numbers, creates a vector of consecutive values, beginning with the first value and ending with the second. Please note, that using and understanding the data.frame, c, and rep functions is not consequential for understanding how to do a vertical merge; rather, I merely use these functions in this tutorial to create quick toy data frames that we can use to illustrate how to do a vertical join. For more information on the data.frame function and the c function, please refer to the chapter called Basic Features and Operations of the R Language. # Create data frames with same variables but arbitrary values df1 &lt;- data.frame(id=c(1:6), age=c(21:26), sex=c(rep(&quot;male&quot;, 6))) df2 &lt;- data.frame(id=c(7:10), age=c(27:30), sex=c(rep(&quot;female&quot;, 4))) # View first data frame df1 ## id age sex ## 1 1 21 male ## 2 2 22 male ## 3 3 23 male ## 4 4 24 male ## 5 5 25 male ## 6 6 26 male # View second data frame df2 ## id age sex ## 1 7 27 female ## 2 8 28 female ## 3 9 29 female ## 4 10 30 female Given that these two data frames (i.e., df1, df2) have the exact same variable names (id, age, and sex), we can easily perform a vertical join using the rbind function. To do so, enter the names of the two data frames as arguments, separated by a comma. Use the &lt;- symbol to name the merged data frame something, which for this case, I arbitrarily named it mergeddf2. # Verticle merge mergeddf2 &lt;- rbind(df1, df2) # View the merged data frame mergeddf2 ## id age sex ## 1 1 21 male ## 2 2 22 male ## 3 3 23 male ## 4 4 24 male ## 5 5 25 male ## 6 6 26 male ## 7 7 27 female ## 8 8 28 female ## 9 9 29 female ## 10 10 30 female Note how the two data frames are now stacked on one another. This was possible because they shared the same variables names and variables types (e.g., numeric and character). 17.3 Summary Joining (merging) data frames in R is a useful practice. In this chapter, we learned how to perform a horizontal join using the right_join, left_join, inner_join, and full_join functions from the dplyr package. We also learned how to perform a vertical join using the rbind function from base R. "],["filter.html", "Chapter 18 Filtering Data 18.1 Filter Cases from Data Frame 18.2 Remove Single Variable from Data Frame 18.3 Select Multiple Variables from Data Frame 18.4 Remove Multiple Variables from Data Frame 18.5 Summary", " Chapter 18 Filtering Data Filtering data (i.e., subsetting data) is an important data-management process, as it allows us to (a) select or remove a subset of cases from a data frame based on their scores on one or more variables, or to (b) select or remove a subset of variables from a data frame. 18.0.0.1 Conceptual Review of Logical Operators When our goal is to select or remove a subset of cases (i.e., observations) from a data frame, we typically do so by applying logical operators. You may already be comfortable with the use of logical operators and expressions like greater than (\\(&gt;\\)), less than (\\(&lt;\\)), equal to (\\(=\\)), greater than or equal to (\\(\\ge\\)), and less than or equal to (\\(\\le\\)), but you may be less comfortable with the use of the logical OR and the logical AND. Thus, before we start working with data, lets do a quick review. When we wish to apply a single logical statement, our job is relatively straightforward. To keep things simple, lets focus on a single vector, and well call that vector \\(X\\). For example, we might choose to select only those cases with scores on \\(X\\) that are greater than or equal to (\\(\\ge\\) or \\(&gt;\\)\\(=\\)) 3, thereby retaining scores that are equal to or greater than 3, as highlighted in blue below. In other words, we select only those cases for which their score on \\(X\\) would be true given the logical statement \\(X \\ge 3\\). The vector \\(X\\) has seven possible scores, ranging from 1 to 7. If we apply the logical statement that \\(X\\) is greater than or equal to (\\(\\ge\\)) 3, we select only those cases with scores that are equal to or greater than 3 and up to the maximum possible score of 7. As another example, we might choose to select only those cases with scores on \\(X\\) that are less than or equal to (\\(\\le\\) or \\(&lt;\\)\\(=\\)) 5, thereby retaining scores that are equal to or less than 5, as highlighted in red below. In other words, we select only those cases for which their score on \\(X\\) would be true given the logical statement \\(X \\le 5\\). The vector \\(X\\) has seven possible scores, ranging from 1 to 7. If we apply the logical statement that \\(X\\) is greater than or equal to (\\(\\ge\\)) 3, we select only those cases with scores that are equal to or greater than 3 and down to the minimum possible score of 1. If we apply the logical OR operator, things get a bit more interesting. The logical OR is used when our objective is to select cases based on two logical statements, and if either logical statement is true for a given case, then that case is selected. The logical OR is consistent with idea of a mathematical union (\\(\\cup\\)) from Set Theory. As an example, lets combine the two logical statements from above with the logical OR operator. We retain those cases for which their score on \\(X\\) is greater than or equal to 3 or less than or equal to 5. Given that \\(X\\) has possible scores ranging from 1-7, below, we see that this logic retains all cases, as all scores (1-7) would satisfy one or both of the logical statements. The vector \\(X\\) has seven possible scores, ranging from 1 to 7. If we wish to retain those cases for which X$ is greater than or equal to 3 or less than or equal to 5, we select those cases that satisfy either (or both) logical statements. Using the same to logical statements above, lets replace the logical OR with the logical AND. The logical AND is used when our objective is to select cases based on two logical statements, and if both logical statements are true for a given case, then that case is selected. The logical AND is consistent with idea of a mathematical intersection (\\(\\cap\\)) from Set Theory. In this example, we retain only those cases for which their score on \\(X\\) is greater than or equal to 3 and less than or equal to 5. Given that \\(X\\) has possible scores ranging from 1-7, below, we see that this logic retain only cases with scores within the range 3-5, as only scores of 3, 4, or 5 would satisfy both of the logical statements. The vector \\(X\\) has seven possible scores, ranging from 1 to 7. If we wish to retain those cases for which X$ is greater than or equal to 3 and less than or equal to 5, we select only those cases that satisfy both logical statements. 18.0.0.2 Video Tutorial As usual, you have the choice to follow along with the written tutorial in this chapter or to watch the video tutorial below. Both versions of the tutorial will show you how to filter (subset) data with or without the pipe (%&gt;%) operator. If youre unfamiliar with the pipe operator, no need to worry: I provide a brief explanation and demonstration regarding their purpose in both versions of the tutorial. Link to Video Tutorial: https://youtu.be/izVcbPmu0D0 18.0.0.3 Functions &amp; Packages Introduced Function Package str base R filter dplyr c base R as.Date base R select dplyr subset base R 18.0.0.4 Initial Steps If you havent already, save the files called PersData.csv and PerfData.csv into a folder that you will subsequently set as your working directory. Your working directory will likely be different than the one shown below (i.e., \"H:/RWorkshop\"). As a reminder, you can access all of the data files referenced in this book by downloading them as a compressed (zipped) folder from the my GitHub site: https://github.com/davidcaughlin/R-Tutorial-Data-Files; once youve followed the link to GitHub, just click Code (or Download) followed by Download ZIP, which will download all of the data files referenced in this book. For the sake of parsimony, I recommend downloading all of the data files into the same folder on your computer, which will allow you to set that same folder as your working directory for each of the chapters in this book. Next, using the setwd function, set your working directory to the folder in which you saved the data file for this chapter. Alternatively, you can manually set your working directory folder in your drop-down menus by going to Session &gt; Set Working Directory &gt; Choose Directory. Be sure to create a new R script file (.R) or update an existing R script file so that you can save your script and annotations. If you need refreshers on how to set your working directory and how to create and save an R script, please refer to Setting a Working Directory and Creating &amp; Saving an R Script. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) Next, read in the .csv data files called PersData.csv and PerfData.csv using your choice of read function. In this example, I use the read_csv function from the readr package (Wickham and Hester 2020). If you choose to use the read_csv function, be sure that you have installed and accessed the readr package using the install.packages and library functions. Note: You dont need to install a package every time you wish to access it; in general, I would recommend updating a package installation once ever 1-3 months. For refreshers on installing packages and reading data into R, please refer to Packages and Reading Data into R. # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;readr&quot;) # Access readr package library(readr) # Read data and name data frame (tibble) objects personaldata &lt;- read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) performancedata &lt;- read_csv(&quot;PerfData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## perf_q1 = col_double(), ## perf_q2 = col_double(), ## perf_q3 = col_double(), ## perf_q4 = col_double() ## ) # View the names of the variables in the data frame (tibble) objects names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; names(performancedata) ## [1] &quot;id&quot; &quot;perf_q1&quot; &quot;perf_q2&quot; &quot;perf_q3&quot; &quot;perf_q4&quot; # View data frame (tibble) objects personaldata ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male performancedata ## # A tibble: 6 x 5 ## id perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 3.9 4.8 4.9 5 ## 2 125 2.1 1.9 2.1 2.3 ## 3 111 3.3 3.3 3.4 3.3 ## 4 198 4.9 4.5 4.4 4.8 ## 5 201 1.2 1.1 1 1 ## 6 282 2.2 2.3 2.4 2.5 As you can see from the output generated in your console, on the one hand, the personaldata data frame object contains basic employee demographic information. The variable names include: id, lastname, firstname, startdate, and gender. On the other hand, the personaldata data frame object contains the same id unique identifer variable as the personaldata data frame object, but instead of employee demographic information, this data frame object includes varuables associated with quarterly employee performance: perf_q1, perf_q2, perf_q3, and perf_q4. To make this chapter more interesting (and for the sake of practice), lets use the full_join function from dplyr to join (merge) the two data frames we just read in (personaldata, performancedata) using the id variable as the key variable. Lets arbitrarily name the new joined (merged) data frame mergeddf using the &lt;- operator. For more information on joining data, check out the chapter called Joining (Merging) Data. # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;dplyr&quot;) # Access package library(dplyr) # Full join (without pipe) mergeddf &lt;- full_join(personaldata, performancedata, by=&quot;id&quot;) # View joined (merged) data frame object mergeddf ## # A tibble: 9 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 3 155 Smith John 1/9/2016 male NA NA NA NA ## 4 165 Doe Jane 1/4/2016 female NA NA NA NA ## 5 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 6 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 7 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 8 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 9 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Now we have a joined data frame called mergeddf! 18.1 Filter Cases from Data Frame Sometimes we want to select only a subset of cases from a data frame or table. There are different functions that can achieve this end. For example, the subset function filter from base R will do the trick. With that said, the dplyr package offers the filter function which has some advantages (e.g., faster with larger amounts of data), and thus, we will focus on the filter function in this chapter. If you would like to learn how to use the subset function from base R, check out the chapter supplement called Joining (Merging) Data. In order to properly filter data by cases, we need to know the respective types (classes) of the variables in the data frame. Perhaps the quickest way to find out the type (class) of each variable in the data frame is to use the str (structure) function from base R, and the functions parentheses, just enter the name of the data frame (mergeddf). # Determine class of variables str(mergeddf) ## spec_tbl_df[,9] [9 x 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ id : num [1:9] 153 154 155 165 125 111 198 201 282 ## $ lastname : chr [1:9] &quot;Sanchez&quot; &quot;McDonald&quot; &quot;Smith&quot; &quot;Doe&quot; ... ## $ firstname: chr [1:9] &quot;Alejandro&quot; &quot;Ronald&quot; &quot;John&quot; &quot;Jane&quot; ... ## $ startdate: chr [1:9] &quot;1/1/2016&quot; &quot;1/9/2016&quot; &quot;1/9/2016&quot; &quot;1/4/2016&quot; ... ## $ gender : chr [1:9] &quot;male&quot; &quot;male&quot; &quot;male&quot; &quot;female&quot; ... ## $ perf_q1 : num [1:9] 3.9 NA NA NA 2.1 3.3 4.9 1.2 2.2 ## $ perf_q2 : num [1:9] 4.8 NA NA NA 1.9 3.3 4.5 1.1 2.3 ## $ perf_q3 : num [1:9] 4.9 NA NA NA 2.1 3.4 4.4 1 2.4 ## $ perf_q4 : num [1:9] 5 NA NA NA 2.3 3.3 4.8 1 2.5 ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. id = col_double(), ## .. lastname = col_character(), ## .. firstname = col_character(), ## .. startdate = col_character(), ## .. gender = col_character() ## .. ) Note that the id variable is of type integer; the lastname, firstname, startdate, and gender variables are of type character (string); and the perf_q4, perf_q4, perf_q4, and perf_q4 variables are of type numeric. The variable type will have important implications for how use use the filter function from dplyr. In R, we can apply any one of the following logical operators when filtering our data: Logical Operator Definition &lt; less than &gt; greater than &lt;= less than or equal to &gt;= greater than or equal to == equal to != not equal to | or &amp; and ! not To get started, install and access the dplyr package. # Install package install.packages(&quot;dplyr&quot;) # Access package library(dplyr) I will demonstrate two approaches applying the filter function from dplyr. The first option uses pipe(s), which in R is represented by the %&gt;% operator. The pipe operator comes from a package called magrittr, on which the dplyr is partially dependent. In short, a pipe allows one to more efficiently code/script and to improve the readability of the code/script under certain conditions. Specifically, a pipe forwards the result or value of one object or expression to a subsequent function. In doing so, one can avoid writing functions in which other functions are nested parenthetically. The second option is more traditional and lacks the efficiency and readability of pipes. You can use either approach, and if dont you want to use pipes, skip to the section below called Filter Data without Pipes. For more information on the pipe operator, check out this link: https://r4ds.had.co.nz/pipes.html. 18.1.1 With Pipes Using an approach with pipes, first, use the &lt;- operator to name the filtered data frame that we will create. For this example, I name the new joined data frame filterdf; you could name it whatever you would like. Second, type the name of the first data frame, which we named mergeddf (see above), followed by the pipe (%&gt;%) operator. This will pipe our data frame into the subsequent function. Third, either on the same line or on the next line, type the filter function. Fourth, within the function parentheses, type the name of the variable we wish to filter the data frame by, which in this example is gender. Fourth, type a logical operator, which for this example is ==. Fifth, type a value for the filter variable, which in this example is female; because the gender variable is of type character, we need to put quotation marks (\" \") around the value of the variable that we wish to filter by. Remember, object names in R are case and space sensitive; for instance, gender is different from Gender, and female is different from Female. # Filter in by gender with pipe filterdf &lt;- mergeddf %&gt;% filter(gender==&quot;female&quot;) # View filtered data frame filterdf ## # A tibble: 3 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 165 Doe Jane 1/4/2016 female NA NA NA NA ## 2 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 3 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 Note how the data frame above contains only those cases with female as their gender variable designation. The filter worked as expected. Alternatively, we could filter out those cases in which gender is equal to female using the != (not equal to) logical operator. # Filter out by gender with pipe filterdf &lt;- mergeddf %&gt;% filter(gender!=&quot;female&quot;) # View filtered data frame filterdf ## # A tibble: 6 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 3 155 Smith John 1/9/2016 male NA NA NA NA ## 4 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 5 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 6 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Note how cases with gender equal to female are no longer in the data frame, while every other case is retained. Lets now filter by a variable of type numeric (or integer). Specifically, lets select those cases in which the perf_q2 variable is greater than (&gt;) 4.0. Because the perf_q2 variable is of type numeric, we dont use quotation marks (\" \") around the value we wish to filter by, which in this case is 4.0. # Filter by perf_q2 with pipe filterdf &lt;- mergeddf %&gt;% filter(perf_q2&gt;4.0) # View filtered data frame filterdf ## # A tibble: 2 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 If we wish to filter by two variables, we can apply the logical or (|) operator or and (&amp;) operator. First, lets select those cases in which either gender is equal to female or perf_q2 is greater than 4.0 using the or (|) operator. # Filter by gender or perf_q2 with pipe filterdf &lt;- mergeddf %&gt;% filter(gender==&quot;female&quot; | perf_q2&gt;4.0) # View filtered data frame filterdf ## # A tibble: 4 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 165 Doe Jane 1/4/2016 female NA NA NA NA ## 3 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 4 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 Watch what happens if we apply the logical and (&amp;) operator with the same syntax as above. # Filter by gender and perf_q2 with pipe filterdf &lt;- mergeddf %&gt;% filter(gender==&quot;female&quot; &amp; perf_q2&gt;4.0) # View filtered data frame filterdf ## # A tibble: 1 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 We can also use the logical or (|) operator to select two values of the same variable. # Filter by two values of firstname with pipe filterdf &lt;- mergeddf %&gt;% filter(firstname==&quot;John&quot; | firstname==&quot;Jane&quot;) # View filtered data frame filterdf ## # A tibble: 3 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 155 Smith John 1/9/2016 male NA NA NA NA ## 2 165 Doe Jane 1/4/2016 female NA NA NA NA ## 3 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Or we can select two ranges of values from the same variable using the logical or (|) operator, assuming the variable is of type numeric, integer, or date. # Filter by two ranges of values of perf_q1 with pipe filterdf &lt;- mergeddf %&gt;% filter(perf_q1&lt;=2.5 | perf_q1&gt;=4.0) # View filtered data frame filterdf ## # A tibble: 4 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 2 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 3 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 4 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 The filter function can also be used to remove multiple specific cases (such as from a unique identifier variable), which might be useful when youve identified outliers that need to be removed. As a first step, identify a vector of values that need to be removed. In this example, lets pretend that cases with id variable values of 198 and 201 no longer work for this company, so they should be removed from the sample. To create a vector of these two values, use the c function like this: c(198,201). Next, because you are now filtering by a vector, you will need to use the %in% operator, which is an operator that instructs R to go through each value of the filter variable (id) and identify instances of 198 and 201 (c(198,201)); if the values match, then those cases are retained. However, because we entered ! in front of the filter variable, this actually reverses our logic and instructs R to remove those cases in which a value of the filter variable matches a value contained in the vector. # Filter out id of 198 and 201 with pipe filterdf &lt;- mergeddf %&gt;% filter(!id %in% c(198,201)) # View filtered data frame filterdf ## # A tibble: 7 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 3 155 Smith John 1/9/2016 male NA NA NA NA ## 4 165 Doe Jane 1/4/2016 female NA NA NA NA ## 5 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 6 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 7 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Note that in the output above cases with id variable values equal to 198 and 201 are no longer present. If you remove the ! in front of the filter variable, only cases 198 and 201 are retained. # Filter in id of 198 and 201 with pipe filterdf &lt;- mergeddf %&gt;% filter(id %in% c(198,201)) # View filtered data frame filterdf ## # A tibble: 2 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 2 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 And if you wanted to remove just a single case, you could use the unique identifier variable (id) and the following script/code. # Filter out id of 198 with pipe filterdf &lt;- mergeddf %&gt;% filter(id!=198) # View filtered data frame filterdf ## # A tibble: 8 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 3 155 Smith John 1/9/2016 male NA NA NA NA ## 4 165 Doe Jane 1/4/2016 female NA NA NA NA ## 5 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 6 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 7 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 8 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 When working with variables of type Date, things can get a bit trickier. When we applied the str function from base R (see above), we found that the startdate variable was read in and joined as a character variable as opposed to a date variable. As such, we need to convert the startdate variable using the as.Date function from base R. First, type the name of the data frame object (mergeddf), followed by the $ operator and the name of whatever you want to call the new variable (startdate2); remember, the $ operator tells R that a variable belongs to (or will belong to) a particular data frame. Second, type the &lt;- operator. Third, type the name of the as.Date function. Fourth, in the function parentheses, as the first argument, enter the as.character function with the name of the data frame object (mergeddf), followed by the $ operator and the name the original variable (startdate) as the sole argument. Fifth, as the second argument in the as.Date function, type format=\"%m/%d/%Y\" to indicate the format for the data variable; note that the capital Y in %Y implies a 4-digit year, whereas a lower case would imply a 2-digit year. # Convert character startdate variable to the Date type startdate2 variable mergeddf$startdate2 &lt;- as.Date(as.character(mergeddf$startdate), format=&quot;%m/%d/%Y&quot;) To verify that the new startdate2 variable is of type date, use the str function from base R, and enter the name of the data frame object (mergeddf) as the sole argument. As you will see, the new startdate2 variable is now of type Date. # Verify that the startdate2 variable is now a variable of type Date str(mergeddf) ## spec_tbl_df[,10] [9 x 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ id : num [1:9] 153 154 155 165 125 111 198 201 282 ## $ lastname : chr [1:9] &quot;Sanchez&quot; &quot;McDonald&quot; &quot;Smith&quot; &quot;Doe&quot; ... ## $ firstname : chr [1:9] &quot;Alejandro&quot; &quot;Ronald&quot; &quot;John&quot; &quot;Jane&quot; ... ## $ startdate : chr [1:9] &quot;1/1/2016&quot; &quot;1/9/2016&quot; &quot;1/9/2016&quot; &quot;1/4/2016&quot; ... ## $ gender : chr [1:9] &quot;male&quot; &quot;male&quot; &quot;male&quot; &quot;female&quot; ... ## $ perf_q1 : num [1:9] 3.9 NA NA NA 2.1 3.3 4.9 1.2 2.2 ## $ perf_q2 : num [1:9] 4.8 NA NA NA 1.9 3.3 4.5 1.1 2.3 ## $ perf_q3 : num [1:9] 4.9 NA NA NA 2.1 3.4 4.4 1 2.4 ## $ perf_q4 : num [1:9] 5 NA NA NA 2.3 3.3 4.8 1 2.5 ## $ startdate2: Date[1:9], format: &quot;2016-01-01&quot; &quot;2016-01-09&quot; &quot;2016-01-09&quot; ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. id = col_double(), ## .. lastname = col_character(), ## .. firstname = col_character(), ## .. startdate = col_character(), ## .. gender = col_character() ## .. ) Now we are ready to filter using the new startdate2 variable. When specify the value of the startdate2 variable by which you wish to filter by, make sure to use the as.Date function once more with the date (formatted as YYYY-MM-DD) in quotation marks (\" \") as the sole argument. Here, I filter for those cases in which their startdate2 values are greater than 2016-01-07. # Filter by startdate2 with pipe filterdf &lt;- mergeddf %&gt;% filter(startdate2 &gt; as.Date(&quot;2016-01-07&quot;)) # View filtered data frame print(filterdf) ## # A tibble: 5 x 10 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 154 McDonald Ronald 1/9/2016 male NA NA NA NA 2016-01-09 ## 2 155 Smith John 1/9/2016 male NA NA NA NA 2016-01-09 ## 3 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 2016-01-09 ## 4 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 2016-01-09 ## 5 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 2016-01-09 18.1.2 Without Pipes We can also filter using the filter function from the dplyr package without using the pipe (%&gt;%) operator. Note how I simply move the name of the data frame object from before the pipe (%&gt;%) operator to the first argument in the filter function. Everything else remains the same. For simplicity, I dont display the output below as it is the same as the output as above using pipes. Your decision whether to use a pipe operator is completely up to you. Lets filter the mergeddf data frame object such that only those cases for which the gender variable is equal to female are retained. Note how we apply the equal to (==) logical operator. A table of logical operators is presented towards the beginning of this tutorial. # Filter in by gender without pipe filterdf &lt;- filter(mergeddf, gender==&quot;female&quot;) # View filtered data frame filterdf Now lets filter out those cases in which gender is not equal to female. We apply the not equal to (!=) logical operator to do so. # Filter in by gender without pipe filterdf &lt;- filter(mergeddf, gender!=&quot;female&quot;) # View filtered data frame filterdf Filter the data frame such that we retain those cases for which the perf_q2 variable is greater than (&gt;) 4.0. Because the perf_q2 variable is numeric, we dont put the value 4.0 in quotation marks. # Filter by perf_q2 without pipe filterdf &lt;- filter(mergeddf, perf_q2&gt;4.0) # View filtered data frame filterdf Using the logical or operator (|), select those cases for which gender is equal to female or for which perf_q2 is greater than 4.0. # Filter by gender or perf_q2 without pipe filterdf &lt;- filter(mergeddf, gender==&quot;female&quot; | perf_q2&gt;4.0) # View filtered data frame filterdf Using the logical and operator (&amp;), select those cases for which gender is equal to female and for which perf_q2 is greater than 4.0. Note the difference in the resulting filtered data frame. # Filter by gender and perf_q2 without pipe filterdf &lt;- filter(mergeddf, gender==&quot;female&quot; &amp; perf_q2&gt;4.0) # View filtered data frame filterdf Using the logical or operator (|), select those cases for which firstname is equal to John or for which firstname is equal to Jane. In other words, select those individuals whose names are either John or Jane. # Filter by two values of firstname without pipe filterdf &lt;- filter(mergeddf, firstname==&quot;John&quot; | firstname==&quot;Jane&quot;) # View filtered data frame filterdf Using the logical or operator (|), select the range of cases for which perf_q1 is less than equal to (&lt;=) 2.5 or for which perf_q1 is greater than or equal (&gt;=) to 4.0. # Filter by two ranges of values of perf_q1 without pipe filterdf &lt;- filter(mergeddf, perf_q1&lt;=2.5 | perf_q1&gt;=4.0) # View filtered data frame filterdf The filter function can also be used to remove multiple specific cases (such as from a unique identifier variable), which might be useful when youve identified outliers that need to be removed. As a first step, identify a vector of values that need to be removed. In this example, lets pretend that cases with id variable values of 198 and 201 no longer work for this company, so they should be removed from the sample. To create a vector of these two values, use the c function like this: c(198,201). Next, because you are now filtering by a vector, you will need to use the %in% operator, which is an operator that instructs R to go through each value of the filter variable (id) and identify instances of 198 and 201 (c(198,201)); if the values match, then those cases are retained. However, because we entered ! in front of the filter variable, this actually reverses our logic and instructs R to remove those cases in which a value of the filter variable matches a value contained in the vector. # Filter out id of 198 and 201 without pipe filterdf &lt;- filter(mergeddf, !id %in% c(198,201)) # View filtered data frame filterdf Or if you wish to retain only those cases for which the id variable is equal to 198 and 201, drop the not operator (!) from the previous script. # Filter in id of 198 and 201 without pipe filterdf &lt;- filter(mergeddf, id %in% c(198,201)) # View filtered data frame filterdf You can also drop specific cases one by one using the not equal to operator (!=) and the a unique identifier value associated with the case you wish to remove. We accomplish the same result as above but use two steps instead. Also, note that in the second step below, the new data frame object (filterdf) is used as the first argument because we want to retain the changes we made in the prior step (i.e., dropping case with id equal to 198). # Filter in id of 198 without pipe filterdf &lt;- filter(mergeddf, id!=198) # Filter in id of 201 without pipe filterdf &lt;- filter(filterdf, id!=201) # View filtered data frame filterdf When working with variables of type Date, things can get a bit trickier. When we applied the str function from base R (see above), we found that the startdate variable was read in and joined as a character variable as opposed to a date variable. As such, we need to convert the startdate variable using the as.Date function from base R. First, type the name of the data frame object (mergeddf), followed by the $ operator and the name of whatever you want to call the new variable (startdate2); remember, the $ operator tells R that a variable belongs to (or will belong to) a particular data frame. Second, type the &lt;- operator. Third, type the name of the as.Date function. Fourth, in the function parentheses, as the first argument, enter the as.character function with the name of the data frame object (mergeddf), followed by the $ operator and the name the original variable (startdate) as the sole argument. Fifth, as the second argument in the as.Date function, type format=\"%m/%d/%Y\" to indicate the format for the data variable; note that the capital Y in %Y implies a 4-digit year, whereas a lower case would imply a 2-digit year. To verify that the new startdate2 variable is of type date, on the next line, use the str function from base R, and enter the name of the data frame object (mergeddf) as the sole argument. As you will see, the new startdate2 variable is now of type Date. # Convert character startdate variable to the date type startdate2 variable mergeddf$startdate2 &lt;- as.Date(as.character(mergeddf$startdate), format=&quot;%m/%d/%Y&quot;) # Verify that the startdate2 variable is now a variable of type date str(mergeddf) Now we are ready to filter using the new startdate2 variable. When specify the value of the startdate2 variable by which you wish to filter by, make sure to use the as.Date function once more with the date (formatted as YYYY-MM-DD) in quotation marks (\" \") as the sole argument. Here, I filter for those cases in which their startdate2 values are greater than 2016-01-07. # Filter by startdate2 without pipe filterdf &lt;- filter(mergeddf, startdate2 &gt; as.Date(&quot;2016-01-07&quot;)) # View filtered data frame print(filterdf) 18.2 Remove Single Variable from Data Frame If you just need to remove a single variable from a data frame, using the NULL object in R in conjunction with the &lt;- operator can designate which variable to drop. For example, if we wish to drop the startdate variable from the mergeddf data frame, we simply note that startdate belongs to mergeddf by joining them with $. Next, we set &lt;- NULL adjacent to mergeddf$startdate to indicate that we wish to remove that variable from that data frame. # Remove variable mergeddf$startdate &lt;- NULL # View updated data frame mergeddf ## # A tibble: 9 x 9 ## id lastname firstname gender perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 153 Sanchez Alejandro male 3.9 4.8 4.9 5 2016-01-01 ## 2 154 McDonald Ronald male NA NA NA NA 2016-01-09 ## 3 155 Smith John male NA NA NA NA 2016-01-09 ## 4 165 Doe Jane female NA NA NA NA 2016-01-04 ## 5 125 Franklin Benjamin male 2.1 1.9 2.1 2.3 2016-01-05 ## 6 111 Newton Isaac male 3.3 3.3 3.4 3.3 2016-01-09 ## 7 198 Morales Linda female 4.9 4.5 4.4 4.8 2016-01-07 ## 8 201 Providence Cindy female 1.2 1.1 1 1 2016-01-09 ## 9 282 Legend John male 2.2 2.3 2.4 2.5 2016-01-09 18.3 Select Multiple Variables from Data Frame If you wish to select multiple variables from a data frame (and remove all others), the select function from the dplyr package is quite useful and intuitive. Below, I demonstrate how to select multiple variables with and without pipes. If you dont want to use pipes, feel free to skip down to the section called Without Pipes. 18.3.1 With Pipe Using the pipe (%&gt;%) operator, first, decide whether you want to override an existing data frame or create a new data frame based on our selection; here, I override the mergeddf data frame using the &lt;- operator, which results in mergeddf &lt;-. Second, type the name of the original data frame (mergeddf), followed by the pipe (%&gt;%) operator. Third, type the name of the select function. Fourth, in the parentheses, list the names of the variables you wish to select as arguments; all variables that are not listed will be dropped. Here, we are selecting (to retain) the id, perf_q1, gender, lastname, and firstname variables. Note that the updated date frame includes the selected variables in the order in which you listed them. # Select multiple variables with pipe mergeddf &lt;- mergeddf %&gt;% select(id, perf_q1, gender, lastname, firstname) # View updated data frame mergeddf ## # A tibble: 9 x 5 ## id perf_q1 gender lastname firstname ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 3.9 male Sanchez Alejandro ## 2 154 NA male McDonald Ronald ## 3 155 NA male Smith John ## 4 165 NA female Doe Jane ## 5 125 2.1 male Franklin Benjamin ## 6 111 3.3 male Newton Isaac ## 7 198 4.9 female Morales Linda ## 8 201 1.2 female Providence Cindy ## 9 282 2.2 male Legend John 18.3.2 Without Pipe If you decide not to use the pipe (%&gt;%) operator, the syntax remains almost the same except the name of the original data frame object (mergeddf) is moved from before the pipe (%&gt;%) operator to the first argument in the select function. Everything else remains the same. # Select multiple variables without pipe mergeddf &lt;- select(mergeddf, id, gender, lastname, firstname) # View updated data frame mergeddf 18.4 Remove Multiple Variables from Data Frame If you wish to remove multiple variables from a data frame, the select function from dplyr will work just fine. I demonstrate how to use this function with and without pipes. If you dont want to use pipes, feel free to skip down to the section called Without Pipes. 18.4.1 With Pipe Using the pipe (%&gt;%) operator, first, decide whether you want to override an existing data frame or create a new data frame from the subset; here, I override the mergeddf data frame using the &lt;- operator, which results in mergeddf &lt;-. Second, type the name of the original data frame (mergeddf), followed by the pipe (%&gt;%) operator. Third, enter the select function. Fourth, use the c (combine) function with - in front of it to note that you want to select all other variables except the ones listed in the c function. # Remove multiple variables with pipe mergeddf &lt;- mergeddf %&gt;% select(-c(lastname, firstname)) # View updated data frame mergeddf ## # A tibble: 9 x 3 ## id perf_q1 gender ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 153 3.9 male ## 2 154 NA male ## 3 155 NA male ## 4 165 NA female ## 5 125 2.1 male ## 6 111 3.3 male ## 7 198 4.9 female ## 8 201 1.2 female ## 9 282 2.2 male Removing a single variable can also be done using the select function. To do so, just list a single variable with - in front of it (as the sole argument) to indicate that you wish to drop that variable. # Remove single variable with pipe mergeddf &lt;- mergeddf %&gt;% select(-gender) # View updated data frame mergeddf ## # A tibble: 9 x 2 ## id perf_q1 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 153 3.9 ## 2 154 NA ## 3 155 NA ## 4 165 NA ## 5 125 2.1 ## 6 111 3.3 ## 7 198 4.9 ## 8 201 1.2 ## 9 282 2.2 18.4.2 Without Pipe If you decide not to use the pipe (%&gt;%) operator, the syntax remains mostly the same except the name of the original data frame object (mergeddf) is moved from before the pipe (%&gt;%) operator to the first argument in the select function. Everything else remains the same. # Remove multiple variables without pipe mergeddf &lt;- select(mergeddf, -c(lastname, firstname)) # View updated data frame mergeddf And heres the non-pipe equivalent to removing a single variable using this approach. # Remove single variable without pipe mergeddf &lt;- mergeddf %&gt;% select(-gender) # View updated data frame mergeddf 18.5 Summary Applying filters and creating subsets of cases (rows) and variables (columns) from a data frame is an important part of data management. The dplyr package has two useful functions that can be used for these purposes: filter and select. "],["clean.html", "Chapter 19 Cleaning Data", " Chapter 19 Cleaning Data Cleaning data is an essential part of the Data Management phase of the HR Analytics Project Life Cycle. When we clean data, broadly speaking, we identify, correct, or remove problematic observations, scores, or variables. More specifically, data cleaning often entails (but is not limited to): Identifying and correcting data-entry errors and inconsistent coding Evaluating missing data and determining how to handle them Flagging and correcting out-of-bounds scores for variables Addressing open-ended and/or other responses from employee surveys Flagging and potentially removing untrustworthy variables With categorical (i.e., nominal, ordinal) variables containing text values, sometimes different spellings or formatting (e.g., uppercase, lowercase) are used (mistakenly) to represent the same category. Such issues broadly fall under data-entry errors and inconsistent coding reason for data cleaning. While the human eye can usually discern what the intended category is, many software programs and programming languages will be unable to automatically or correctly determine which text values represent which category. For example, in the table below, the facility variable is categorical and contains text values meant to represent different facilities at this hypothetical organization. Human eyes can quickly pick out that there are two facility locations represented in this table: Beaverton and Portland. With that said, for the R programming language, without direction, the different spellings and different cases (i.e., lowercase vs. uppercase B) for the Beaverton facility (i.e., Beaverton, beaverton, beverton) will be treated as unique categories (i.e., facilities in this context). Often this is the result of data-entry errors and/or the lack of data validation. To clean the Facility variable, we could convert all instances of beaverton and beverton to Beaverton. Data-entry errors and inconsistent coding: In this table, different spelling and letter cases (e.g., uppercase vs. lowercase) appear for what is supposed to be the same facility location: Beaverton. Missing data (i.e., missing scores) for certain observations (i.e., cases) should also be addressed during data cleaning. For the Facility variable in the table shown below, note how facility location data are missing for the employees with IDs EP9746 and EP9952. In this example, we could likely find other employee records or contact the employees (or their supervisors) in question to verify the facility location where these to employees work. Provided we find the facility locations for these two employees, we could then replace the missing values with the correct facility location information. In other instances, it may prove to be more difficult to replace missing data, such as when organization administers an anonymous employee survey and certain respondents have missing responses to certain questions or items. In such instances, we may decide to tolerate a small percentage of missing data (e.g., &lt; 10%) when we go to analyze the data; however, if the percentage of missing data is sufficiently large and if we plan to analyze the data to make inferences about underlying population from which the sample data were attained, we may begin to think more seriously about whether the data are missing completely at random, missing at random, or missing at not at random. A proper discussion of missing data theory is beyond the scope of this chapter. In some instances, we might encounter out-of-bounds scores, which refer to values that simply are too high or low, or that are just unrealistic or implausible to be correct. In the table below, the Base Salary variable includes salaries that are all below 75,000  with the notable exception of salary associated with employee ID EP0214. Lets imagine that this table is only supposed to include data for a specific job category; knowing that, a base salary of 789,120,000 seems excessively high in a global sense and extraordinarily high in a local sense. It could be that someone entered the base salary data incorrectly for this employee, perhaps by adding four extra zeroes at the end of the actual base salary amount. In this case, we would try to find verify the correct base salary for this individual and then make the correction to the data. Out-of-bounds scores: In this table, the base salary for the individual with employee ID EP0214 seems extraordinarily high and is almost certainly a data entry error. If the example above seems a bit far-fetched to you, Ill provide you with a personal example of just a single zero being mistakenly added to the end of a paycheck. After my fourth year of graduate school, I decided to teach a summer course as an adjunct faculty member, which happened to be an introductory human resource management course. During the week in which I was covering employee compensation, I received a paycheck with one extra zero added to my pay for that month, which of course increased my monthly pay 10-fold. As much as I would have enjoyed holding onto that extra money, I quickly reached out to the a representative from the universitys HR department, and the person addressed the error very quickly. At the end of the conversation, the HR representative said jokingly, The irony is not lost on us that we made this payroll error for someone who is teaching a unit on employee compensation. When an open-ended response or other response field is provided (as opposed to a close-ended response field with predetermined response options), the individual who enters the data can type in whatever they would like (in most instances) provided that they limit their response to the allotted space. This challenge crops up frequently in employee surveys, such as when employees may select an other response for one survey question that then branches them to a follow-up question that is open-ended. In the table below, survey respondents close-ended response options for the Number of Direct Reports variable include an Other option; respondents who responded with Other had an opportunity to indicate their number of direct reports using an open-ended survey question associated with the Number of Direct Reports (Other) variable. When cleaning such data, we often must determine what to do with the affect variables on a case-by-case basis. For example, the individual who responded to the survey associated with a unique identifier of 2 responded with Not a supervisor. If this survey was intended to acquire data from supervisors only, then we might decide to remove the row of data associated with that individuals response, as they likely do not fit our definition of the target population. Open-ended and/or other responses: In this table, survey respondents close-ended response options for the Number of Direct Reports variable include an Other option; for respondents who responded with Other, they then had an opportunity to indicate their number of direct reports using an open-ended survey question associated with the Number of Direct Reports (Other) variable. Finally, sometimes scores for a variable (or even missing scores for a variable) seem off, incorrect, or implausible  or in other words, untrustworthy. For example, in the table below, a variable called Training Post Test is meant to include the scores on a post-training assessment; yet, we can see that the individual with employee ID EP1475 has a score of 99 even though the adjacent variable indicates that the individual did not complete the training. Now, its entirely possible that this person (and others) were part of a control group (i.e., comparison group) intended to be used as part of a training evaluation design, but that then begs the question why only one individual in this table has a training post-test score. At first glance, data associated with the Training Post Test variable seem untrustworthy, and they very well may be in reality. As a next step, we would want to do some sleuthing to figure out what errors or issues may be at work in these data, and whether we should remove the potentially untrustworthy variable in question. Untrustworthy variables: In this table, data are missing for all but employee ID EP1475 on the Training Post Test variable, and furthermore, the Completed Training variable indicates that none of the employees who appear in the table received training. "],["create-portfolio.html", "Creating a Data Analytics Portfolio", " Creating a Data Analytics Portfolio When searching for a job in data analytics, it can be tricky to (a) demonstrate what you know how to do or have done previously and (b) distinguish yourself from other job candidates. Creating a portfolio of your work can be one way to set yourself apart on the job market and can, in some instances, help compensate for fewer years of relevant work experience. In this document, I will provide some suggestions on how to set up a portfolio, with an emphasis on applying the R programming language. 19.0.0.1 Identify a content area or context that excites you. In the Human Resource (HR) Analytics certificate, we obviously focus on the HR context and various HR content areas. Try to be more specific than that, though. For example, are you interested in employee sensing (e.g., engagement surveys), separation and retention, recruitment and selection, training and development, reward systems, or workforce planning? In your portfolio, you can present multiple projects that highlight different content areas and contexts, but I recommend focusing your first portfolio project on an area (a) that you are really passionate about and (b) in which you have some prior work experience (even if not in the application of data analytics/science to that area). 19.0.0.2 Identify an area of data analytics that excites you. Begin by reflecting on what type of work you intrinsically enjoy at the moment and what work you would like to continue doing in the near future. For example, you might enjoy one of the following more than others: question formulation (e.g., problem definition), data acquisition (e.g., measure development), data management (e.g., data wrangling), data analysis (e.g., model building), or storytelling (e.g., data visualization or dashboard creation). Ideally, you will want to create a portfolio that highlights your strengths in each of the areas you wish to emphasize. With that being said, its also good to show at least some level of proficiency in non-emphasized areas as well. 19.0.0.3 Figure out what knowledge, skills, abilities your ideal employer wants  or what it needs but doesnt yet realize it needs. At the very least, youll want to figure out what knowledge, skills, or abilities the employer expects to see in ideal job candidates. You might be able to glean some of these expectations from the job posting itself or from the organizations website. In addition, you find examples of expected knowledge, skills, and abilities in published white papers, peer-reviewed publications, or the LinkedIn profiles of other individuals who hold similar job at that organization. Even better, try to attain direct insider information from those who currently work at that organization. A portfolio also provides you with an opportunity to showcase tools, applications, knowledge, skills, or abilities that the organization likely needs to attain strategic objectives but does not yet realize or recognize. This might be especially relevant in situations in which you suspect that the organizations data analytics capabilities are less mature or when you believe you might be overqualified. 19.0.0.4 Decide whether you want your portfolio to teach, showcase, or do both. Both teaching and showcasing can be useful ways to illustrate your knowledge, skills, and abilities. If you go the teaching route, your portfolio project will likely take the form of a tutorial. A well thought out tutorial can be a good method for showing that you understand the concepts and technical applications well enough to teach another person how to do the same. If you go the showcasing route, your portfolio project will focus less on teaching and more on highlighting what you are capable of doing. If your portfolio consists of multiple projects, you might find it worthwhile to include at least one teaching project and at least one showcasing project. 19.0.0.5 Find an appropriate dataset. There are many different places in which you can find toy datasets or public datasets that are free to use. Though, youll want to be absolutely certain that the dataset youve chosen is free to use and publicly available. That is, you do not want to use proprietary or private data for your portfolio. Examples of repositories for data sets include: My GitHub repository called R Tutorial Data Files, which are all datasets that Ive simulated using R; This GitHub repository called Awesome Public Datasets; Kaggle; This Stanford University website has links to a variety of public datasets. If you cant find an appropriate dataset, you can always simulate one using R, which is more involved and complicated. Rich Landers (University of Minnesota) website includes this tool, which can be used to simulate simple datasets. 19.0.0.6 Create an immersive environment for the intended audience. It can be tempting to just manage, analyze, and visualize a bunch of data without providing any context or backstory. Because context matters, I recommend creating an immersive environment that orients the intended audience to the context, including variable definitions. This can be down via writing, audio, or video. By establishing an immersive environment, the problem youre attempting to solve or the question youre attempting to answer will be more meaningful  and ideally will illustrate a clear purpose (e.g., helping an organization to attain a strategic objective). 19.0.0.7 Articulate a clear problem (question) that can be solved (answered) with the available data. Its important to make sure that your portfolio project is problem- or question-focused. That is, use your portfolio to show how you can go from a problem definition (or question formulation) to a solution (or answer). In doing so, you can demonstrate your ability to conduct meaningful and purposeful data analytics. For a refresher on problem definition and question formulation, check out this video. 19.0.0.8 Write (and annotate) your code with an emphasis on clarity. Your code provides a behind-the-scenes glimpse at your decision-making processes so make sure its clear and understandable. For positions that expect candidates to have less advanced programming skills, you can focus on writing code that is understandable to a broad audience and that illustrates you understand foundational concepts, operations, and techniques. It might not be the most efficient or elegant code, but it should be clear and free of errors. For positions that expect candidates to have more advanced programming skills, youll want to focus on writing code that is stable, reproducible, efficient, and elegant. Regarding efficiency and elegance, youll want to consider how long it takes your code to run and how this might be more consequential at scale, and ideally, youll want to write less code when possible. Be sure to include clear annotations that help explain your many decisions. 19.0.0.9 If your portfolio project includes data analysis or visualization, make sure that youve chosen an appropriate analysis or visualization given the problem/question and available data. You can run all sorts of analyses and attain results  even when the analyses are not appropriate or meaningful given the problem/question and/or available data. If you are performing statistical analysis of the data, youll want to make sure that the statistical assumptions for a particular analysis have been reasonably satisfied; better yet, demonstrate in your portfolio how you tested relevant statistical assumptions. All else being equal, its best to choose the simplest and most easily interpretable analysis. For example, if youre interested in comparing the means for two independent samples, then there are statistical equivalent ways to analyze the data: independent-samples t-test, one-way analysis of variance, simple linear regression, and structural equation modeling. In this example, the independent-samples t-test will likely be the simplest analysis to run and communicate given the goal of comparing the means for two independent samples. I like to think of it using this metaphor: If your objective is to get some almond milk from your corner grocery story, you could walk (independent-samples t-test) or you could drive a Ferrari (structural equation modeling); both will get you there, but one is less resource intensive. 19.0.0.10 Focus on good storytelling. Make sure your portfolio project tells an accurate yet compelling story. While writing sophisticated code or running advanced analyses may impressive some, at the end of the day, your portfolio project should tell a good (and hopefully memorable) story. For a review of classic storytelling principles, check out this video. 19.0.0.11 Solicit friendly feedback prior to sharing your portfolio with an employer. Everyone makes errors, and its better to have a friend or colleague catch those errors prior to sharing the portfolio with an employer. Friends or colleagues can also provide feedback on how intuitive, comprehensible, or appropriate your portfolio is. So who should you ask for feedback? Ideally, you should seek feedback from individuals who have greater expertise in the area than you to make sure youve done everything correctly or appropriately, but it can also be helpful to seek feedback from people who you expect will have a similar level of expertise as the intended audience, as this latter group may help you create a portfolio that is not overly complex for the given audience. 19.0.0.12 Select a platform that will allow you to share your portfolio. There are many different ways in you can share a portfolio, and its important to select a platform that a hiring manager will be familiar with (or at least figure out how to intuitively access) and that has at least some relevance to the position to which youre applying. One of the simplest ways to share a platform would be to share a static document (e.g., PDF). A static document may not impress some hiring managers, but if the position to which youre applying will involve writing a lot of technical reports, then a static document might be appropriate. Further, in some instances, part or all of your portfolio might consist of published articles  although this might be most relevant for more specialized research roles. Further, in RStudio, you can create an RMarkdown file to embed code; in fact, there are packages called blogdown and bookdown that allow you to assemble multiple RMarkdown files into a coherent structure. Other platforms include: YouTube video, a playlist, or an entire channel containing multiple videos; GitHub repository; Medium article; Personal website; Tableau or PowerBI; Shiny web application. 19.0.0.13 Update your portfolio regularly. Youll want your portfolio to feel fresh and contemporary, which means that youll need to update your portfolio with some regularity (e.g., once or twice a year). In addition, be sure to check periodically in which some of the packages/functions youre using have been updated, which could affect how your code works. One way to work around this is to use a dependency management package like packrat. Although using a dependency management package will help to ensure that your code works properly over time, it doesnt guard against stale-looking code that references deprecated functions. "],["arrange-supplement.html", "Arranging (Sorting) Data: Chapter Supplement order Function from Base R", " Arranging (Sorting) Data: Chapter Supplement In addition to the arrange function from the dplyr package covered in Arranging (Sorting) Data, we can use the order function from base R to arrange (sort) data by values for one or more variable. Because this function comes from base R, we do not need to install and access an additional package like we do with the arrange functions, which some may find advantageous. Functions &amp; Packages Introduced Function Package order base R c base R Initial Steps If required, please refer to the Initial Steps section from the chapter for more information on these initial steps. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;readr&quot;) # Access readr package library(readr) # Read data and name data frame (tibble) object personaldata &lt;- read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) # View the names of the variables in the data frame (tibble) object names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; # View data frame (tibble) object personaldata ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male order Function from Base R To sort a data frame object in ascending order based on a single variable, we will use the order function from base R to do the following: Type the name of the data frame object that you wish to arrange (sort) (personaldata). Insert brackets ([ ]), which allow us to reference rows or columns depending on how we format the brackets. If we type a function or value before the comma, we are indicating that we wish to apply operations to row(s), and if we type a function or value after the comma, we are indicating that we wish to apply operations to column(s). To sort the data frame into ascending rows by the startdate variable, type the name of the order function before the comma in the brackets. As the sole parenthetical argument of the order function, type the name of the personaldata data frame object, followed by the $ operator and the name of the variable by which we wish to sort the data frame, which to reiterate is the startdate variable. The $ operator signals to R that a variable belongs to a particular data frame object. By default, the order function sorts in ascending order. # Arrange (sort) data by variable in ascending order personaldata[order(personaldata$startdate),] ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 198 Morales Linda 1/7/2016 female ## 5 154 McDonald Ronald 1/9/2016 male ## 6 155 Smith John 1/9/2016 male ## 7 111 Newton Isaac 1/9/2016 male ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male To change the ordering of data in the personaldata data frame object itself, we will need to (re)name the data frame object using the &lt;- variable assignment operator. In this example, I will demonstrate how to overwrite the existing data frame object, and thus I give the data frame object the exact same name as it had originally (i.e., personaldata). To do so, to the left of the &lt;- operator, type what you would like to name the new (updated) sorted data frame object (personaldata). Next, to the right of the &lt;- operator, copy and paste the same code we wrote above. Finally, use the head function from base R to view the first six rows of the new data frame object. # Arrange (sort) data by variable in ascending order # and overwrite existing data frame object personaldata &lt;- personaldata[order(personaldata$startdate),] # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 165 Doe Jane 1/4/2016 female ## 3 125 Franklin Benjamin 1/5/2016 male ## 4 198 Morales Linda 1/7/2016 female ## 5 154 McDonald Ronald 1/9/2016 male ## 6 155 Smith John 1/9/2016 male To sort in descending order, add the argument decreasing=TRUE within the order function parentheses. Remember, we use commas to separate arguments used in a function (if there are two or more arguments). # Arrange (sort) data by variable in descending order personaldata &lt;- personaldata[order(personaldata$startdate, decreasing=TRUE),] # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 154 McDonald Ronald 1/9/2016 male ## 2 155 Smith John 1/9/2016 male ## 3 111 Newton Isaac 1/9/2016 male ## 4 201 Providence Cindy 1/9/2016 female ## 5 282 Legend John 1/9/2016 male ## 6 198 Morales Linda 1/7/2016 female If we wish to sort a data frame object by two variables, as the second argument in the order function parentheses, simply add the name of the data frame object, followed by the $ operator and the name of the second second variable. We will sort the data frame in by gender and startdate. The ordering of the two variables matters; the function sorts initially by the values/levels of the first variable listed and sorts subsequently by the values/levels of the second variable listed, but does so within the values/levels of the first variable listed. As shown below, startdate is sorted within the sorted levels of the gender variable. The default operation of the arrange function is to arrange (sort) the data in ascending order. # Arrange (sort) data by two variables in ascending order personaldata &lt;- personaldata[order(personaldata$gender, personaldata$startdate),] # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 165 Doe Jane 1/4/2016 female ## 2 198 Morales Linda 1/7/2016 female ## 3 201 Providence Cindy 1/9/2016 female ## 4 153 Sanchez Alejandro 1/1/2016 male ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 154 McDonald Ronald 1/9/2016 male To sort by one of the variables in descending order and the other variable by the default ascending order, we need to add the decreasing= argument, but because we have two variables, we need to provide a vector containing logical values (TRUE, FALSE) to indicate which variable we wish to apply a descending order. If the logical value is TRUE for the decreasing= argument, then we sort in descending variable. Using the c (combine) function from base R, we create a vector of two logical values whose order corresponds to the order in which we listed the two variables in the order function. For example, if the argument is decreasing=c(FALSE, TRUE), then we sort the first variable in the default ascending order and the second variable in descending order, which is what we do below. # Arrange (sort) data by gender in ascending order and # startdate in descending order personaldata &lt;- personaldata[order(personaldata$gender, personaldata$startdate, decreasing=c(FALSE, TRUE)),] # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 165 Doe Jane 1/4/2016 female ## 2 198 Morales Linda 1/7/2016 female ## 3 201 Providence Cindy 1/9/2016 female ## 4 153 Sanchez Alejandro 1/1/2016 male ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 154 McDonald Ronald 1/9/2016 male Or, you could sort by both variables in descending order by change the argument to decreasing=c(TRUE, TRUE). # Arrange (sort) data by gender and id variables descending order personaldata &lt;- personaldata[order(personaldata$gender, personaldata$startdate, decreasing=c(TRUE, TRUE)),] # View just the first 6 rows of the data frame in Console head(personaldata) ## # A tibble: 6 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 154 McDonald Ronald 1/9/2016 male ## 2 155 Smith John 1/9/2016 male ## 3 111 Newton Isaac 1/9/2016 male ## 4 282 Legend John 1/9/2016 male ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 153 Sanchez Alejandro 1/1/2016 male "],["join-supplement.html", "Joining (Merging) Data: Chapter Supplement merge Function from Base R", " Joining (Merging) Data: Chapter Supplement In addition to the join functions from the dplyr package covered in Joining (Merging) Data, we can use the merge function from base R to perform a horizontal join. Because this function comes from base R, we do not need to install and access an additional package like we do with the join functions, which some may find advantageous. Functions &amp; Packages Introduced Function Package names base R merge base R Initial Steps If required, please refer to the Initial Steps section from the chapter for more information on these initial steps. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;readr&quot;) # Access readr package library(readr) # Read data and name data frame (tibble) objects personaldata &lt;- read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) performancedata &lt;- read_csv(&quot;PerfData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## perf_q1 = col_double(), ## perf_q2 = col_double(), ## perf_q3 = col_double(), ## perf_q4 = col_double() ## ) # View the names of the variables in the data frame (tibble) objects names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; names(performancedata) ## [1] &quot;id&quot; &quot;perf_q1&quot; &quot;perf_q2&quot; &quot;perf_q3&quot; &quot;perf_q4&quot; # View data frame (tibble) objects personaldata ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male performancedata ## # A tibble: 6 x 5 ## id perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 3.9 4.8 4.9 5 ## 2 125 2.1 1.9 2.1 2.3 ## 3 111 3.3 3.3 3.4 3.3 ## 4 198 4.9 4.5 4.4 4.8 ## 5 201 1.2 1.1 1 1 ## 6 282 2.2 2.3 2.4 2.5 # Remove case with id variable equal to 153 personaldata &lt;- personaldata[personaldata$id != 153,] merge Function from Base R We will use the merge function to horizontally match cases from the personaldata and performancedata data frames using id as a key variable. To identify what the key variable is, lets use the names function from base R to retrieve the list of variable names from the two data frames, which we already did above. Nevertheless, lets call up those variable names once more. Simply enter the name of the data frame as a parenthetical argument in the names function. # Retrieve variable names from first data frame names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; # Retrieve variable names from second data frame names(performancedata) ## [1] &quot;id&quot; &quot;perf_q1&quot; &quot;perf_q2&quot; &quot;perf_q3&quot; &quot;perf_q4&quot; As you can see in the variable names listed above, the id variable is common to both data frames, and thus it will serve as our key variable. Lets begin with what is referred to as an inner join: Use the &lt;- operator to name the joined data frame that we create using the merge function. For this example, I name the new joined data frame mergeddf, which is completely arbitrary; you could name it whatever you would like. Type the name of the new joined data frame to the left of the &lt;- operator. To the right of the &lt;- operator, type the name of the merge function. Within the merge function parentheses, we will provide the arguments needed to make this join a reality. First, enter the name of one of the data frames (e.g., personaldata), followed by a comma. Second, enter the name of of the other data frame (e.g., performancedata), followed by a comma. Third, use the by= argument to indicate the name of the key variable (e.g., id); make sure the key variable is in quotation marks (\" \"), and remember, object and variable names in R are case and space sensitive. # Inner join mergeddf &lt;- merge(personaldata, performancedata, by=&quot;id&quot;) # View the joined data frame mergeddf ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## 1 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 2 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 3 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 4 201 Providence Cindy 1/9/2016 female 1.2 1.1 1.0 1.0 ## 5 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Now, lets revisit the original data frame objects that we read in initially. # View the first original data frame personaldata ## # A tibble: 8 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 154 McDonald Ronald 1/9/2016 male ## 2 155 Smith John 1/9/2016 male ## 3 165 Doe Jane 1/4/2016 female ## 4 125 Franklin Benjamin 1/5/2016 male ## 5 111 Newton Isaac 1/9/2016 male ## 6 198 Morales Linda 1/7/2016 female ## 7 201 Providence Cindy 1/9/2016 female ## 8 282 Legend John 1/9/2016 male # View the second original data frame performancedata ## # A tibble: 6 x 5 ## id perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 3.9 4.8 4.9 5 ## 2 125 2.1 1.9 2.1 2.3 ## 3 111 3.3 3.3 3.4 3.3 ## 4 198 4.9 4.5 4.4 4.8 ## 5 201 1.2 1.1 1 1 ## 6 282 2.2 2.3 2.4 2.5 In the output, first, note how all of the variables from the original data frames (i.e., personaldata, performancedata) are represented in the merged data frame (i.e., mergeddf). Second, note how the cases are matched by the id key variable. Third, note that the personaldata data frame has 8 cases, the performancedata data frame has 6 cases, and the mergeddf data frame has 6 cases. By default, the merge function performs an inner join and retains only those matched cases that have data in both data frames. Because cases whose id values were 154, 155, and 165 had data in personaldata but not performancedata and because the case with an id value equal to 153 was in performancedata but not personaldata, only the 5 cases that had available data in both data frames were retained. To perform what is referred to as a full join in which we retain all cases and available data, we can add the all= argument to our previous code and specify the logical value TRUE. # Full join mergeddf &lt;- merge(personaldata, performancedata, by=&quot;id&quot;, all=TRUE) # View the joined data frame mergeddf ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## 1 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 2 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 3 153 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3.9 4.8 4.9 5.0 ## 4 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 5 155 Smith John 1/9/2016 male NA NA NA NA ## 6 165 Doe Jane 1/4/2016 female NA NA NA NA ## 7 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 8 201 Providence Cindy 1/9/2016 female 1.2 1.1 1.0 1.0 ## 9 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Note how the full_join function retains all available cases that had available data in at least one of the data frames, which in this example is 9 cases. When in doubt, I recommend using the full_join function to retain all available data. To perform what is referred to as a left join in which we retain only those cases with data available in the first (left, x) data frame (personaldata), we use the all.x=TRUE argument instead. # Left join mergeddf &lt;- merge(personaldata, performancedata, by=&quot;id&quot;, all.x=TRUE) # View the joined data frame mergeddf ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## 1 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 2 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 3 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 4 155 Smith John 1/9/2016 male NA NA NA NA ## 5 165 Doe Jane 1/4/2016 female NA NA NA NA ## 6 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 7 201 Providence Cindy 1/9/2016 female 1.2 1.1 1.0 1.0 ## 8 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Note how the left join retains only those cases for which the first (left, x) data frame (i.e., personaldata) has complete data, which in this case happens to be 8 cases. Notably absent is the case associated with id equal to 153 because the first (left, x) data frame (i.e., personaldata) lacked that case. An NA appears for each case from the second (right, y) data frame that contained missing values on variables from that data frame. To perform what is referred to as a right join in which we retain only those cases with data available in the second (right, y) data frame (performancedata), we use the all.y=TRUE argument instead. # Right join mergeddf &lt;- merge(personaldata, performancedata, by=&quot;id&quot;, all.y=TRUE) # View the joined data frame mergeddf ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## 1 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 2 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 3 153 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3.9 4.8 4.9 5.0 ## 4 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 5 201 Providence Cindy 1/9/2016 female 1.2 1.1 1.0 1.0 ## 6 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Note how the right join retains only those cases for which the joined (second, right, y) data frame (i.e., performancedata) has complete data. Because the first (left, x) data frame lacks data for the case in which id is equal to 153, an NA appears for each case from the first data frame that contained missing values on variables from that data frame. "],["filter-supplement.html", "Filtering Data: Chapter Supplement subset Function from Base R Filter by Pattern Contained within String", " Filtering Data: Chapter Supplement In addition to the filter function from the dplyr package covered in Filtering Data, we can use the subset function from base R to subset cases from a data frame and to select cases from a data frame. Because this function comes from base R, we do not need to install and access an additional package like we do with the filter function, which some may prefer or find advantageous. Further, we can also apply the str_detect function from the stringr package with either the subset or the filter function to filter by a text pattern contained within a string (e.g., character) variable. Functions &amp; Packages Introduced Function Package subset base R str_detect stringr Initial Steps If required, please refer to the Initial Steps section from the chapter for more information on these initial steps. # Set your working directory setwd(&quot;H:/RWorkshop&quot;) # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;readr&quot;) # Access readr package library(readr) # Read data and name data frame (tibble) objects personaldata &lt;- read_csv(&quot;PersData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## lastname = col_character(), ## firstname = col_character(), ## startdate = col_character(), ## gender = col_character() ## ) performancedata &lt;- read_csv(&quot;PerfData.csv&quot;) ## ## -- Column specification ------------------------------------------------------------------------------------ ## cols( ## id = col_double(), ## perf_q1 = col_double(), ## perf_q2 = col_double(), ## perf_q3 = col_double(), ## perf_q4 = col_double() ## ) # View the names of the variables in the data frame (tibble) objects names(personaldata) ## [1] &quot;id&quot; &quot;lastname&quot; &quot;firstname&quot; &quot;startdate&quot; &quot;gender&quot; names(performancedata) ## [1] &quot;id&quot; &quot;perf_q1&quot; &quot;perf_q2&quot; &quot;perf_q3&quot; &quot;perf_q4&quot; # View data frame (tibble) objects personaldata ## # A tibble: 9 x 5 ## id lastname firstname startdate gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male ## 2 154 McDonald Ronald 1/9/2016 male ## 3 155 Smith John 1/9/2016 male ## 4 165 Doe Jane 1/4/2016 female ## 5 125 Franklin Benjamin 1/5/2016 male ## 6 111 Newton Isaac 1/9/2016 male ## 7 198 Morales Linda 1/7/2016 female ## 8 201 Providence Cindy 1/9/2016 female ## 9 282 Legend John 1/9/2016 male performancedata ## # A tibble: 6 x 5 ## id perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 3.9 4.8 4.9 5 ## 2 125 2.1 1.9 2.1 2.3 ## 3 111 3.3 3.3 3.4 3.3 ## 4 198 4.9 4.5 4.4 4.8 ## 5 201 1.2 1.1 1 1 ## 6 282 2.2 2.3 2.4 2.5 # Install readr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;dplyr&quot;) # Access package library(dplyr) # Full join (without pipe) mergeddf &lt;- full_join(personaldata, performancedata, by=&quot;id&quot;) # View joined (merged) data frame object mergeddf ## # A tibble: 9 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 3 155 Smith John 1/9/2016 male NA NA NA NA ## 4 165 Doe Jane 1/4/2016 female NA NA NA NA ## 5 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 6 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 7 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 8 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 9 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 subset Function from Base R As an alternative to the filter function from the dplyr package, we will learn how to use the subset function from base R to filter cases from a data frame and to select or remove variables from a data frame. 19.0.1 Filter Cases from Data Frame Well begin by filtering cases from a data frame object. In R, we can apply any one of the following logical operators when filtering cases from a data frame or table object. Logical Operator Definition &lt; less than &gt; greater than &lt;= less than or equal to &gt;= greater than or equal to == equal to != not equal to | or &amp; and ! not To filter cases from a data frame object using the subset function from base R, use the &lt;- operator to name the filtered data frame that we are about to create. For this example, I name the new joined data frame filterdf; you could name it whatever you would like. To the right of the &lt;- operator, type the name of subset function from base R. As the first argument in the function, enter the name of the data frame we created above (mergeddf). As the second argument, type the name of the variable we wish to filter the data frame by, which in this example is gender followed by a logical/conditional argument. For this example, we wish to to retain only those cases in which gender is equal to female, and we do so using this logical arguent gender==\"female\". Because the gender variable is of type character, we need to put quotation marks (\" \") around the value of the variable that we wish to filter by. Remember, object names in R are case and space sensitive; for instance, gender is different from Gender, and female is different from Female. # Filter by gender filterdf &lt;- subset(mergeddf, gender==&quot;female&quot;) # View filtered data frame filterdf ## # A tibble: 3 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 165 Doe Jane 1/4/2016 female NA NA NA NA ## 2 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 3 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 Note how the data frame above contains only those cases with female as their gender variable designation. The filter worked as expected. Alternatively, we could filter out those cases in which gender is equal to female using the != (not equal to) logical operator. # Filter by gender filterdf &lt;- subset(mergeddf, gender!=&quot;female&quot;) # View filtered data frame filterdf ## # A tibble: 6 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 3 155 Smith John 1/9/2016 male NA NA NA NA ## 4 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 5 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 6 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Note how cases with gender equal to female are no longer in the data frame, while every other case is retained. Lets now filter by a variable of type numeric (or integer). Specifically, lets select those cases in which the perf_q2 variable is greater than (&gt;) 4.0. Because the perf_q2 variable is of type numeric, we dont use quotation marks (\" \") around the value we wish to filter by, which in this case is 4.0. # Filter by perf_q2 filterdf &lt;- subset(mergeddf, perf_q2&gt;4.0) # View filtered data frame filterdf ## # A tibble: 2 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 If we wish to filter by two variables, we can apply the logical or (|) operator or and (&amp;) operator. First, lets select those cases in which either gender is equal to female or perf_q2 is greater than 4.0 using the or (|) operator. # Filter by gender or perf_q2 filterdf &lt;- subset(mergeddf, gender==&quot;female&quot; | perf_q2&gt;4.0) # View filtered data frame filterdf ## # A tibble: 4 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 165 Doe Jane 1/4/2016 female NA NA NA NA ## 3 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 4 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 Watch what happens if we apply the logical and (&amp;) operator with the same syntax as above. # Filter by gender and perf_q2 filterdf &lt;- subset(mergeddf, gender==&quot;female&quot; &amp; perf_q2&gt;4.0) # View filtered data frame filterdf ## # A tibble: 1 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 We can also use the logical or (|) operator to select two values of the same variable. # Filter by two values of firstname filterdf &lt;- subset(mergeddf, firstname==&quot;John&quot; | firstname==&quot;Jane&quot;) # View filtered data frame filterdf ## # A tibble: 3 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 155 Smith John 1/9/2016 male NA NA NA NA ## 2 165 Doe Jane 1/4/2016 female NA NA NA NA ## 3 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Or we can select two ranges of values from the same variable using the logical or (|) operator, assuming the variable is of type numeric, integer, or date. # Filter by two ranges of values of perf_q1 filterdf &lt;- subset(mergeddf, perf_q1&lt;=2.5 | perf_q1&gt;=4.0) # View filtered data frame filterdf ## # A tibble: 4 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 2 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 3 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 ## 4 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 The subset function can also be used to remove multiple specific cases (such as from a unique identifier variable), which might be useful when youve identified outliers that need to be removed. As a first step, identify a vector of values that need to be removed. In this example, lets pretend that cases with id variable values of 198 and 201 no longer work for this company, so they should be removed from the sample. To create a vector of these two values, use the c function like this: c(198,201). Next, because you are now filtering by a vector, you will need to use the %in% operator, which is an operator that instructs R to go through each value of the filter variable (id) and identify instances of 198 and 201 (c(198,201)); if the values match, then those cases are retained. However, because we entered ! in front of the filter variable, this actually reverses our logic and instructs R to remove those cases in which a value of the filter variable matches a value contained in the vector. # Filter out id of 198 and 201 filterdf &lt;- subset(mergeddf, !id %in% c(198,201)) # View filtered data frame filterdf ## # A tibble: 7 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 3 155 Smith John 1/9/2016 male NA NA NA NA ## 4 165 Doe Jane 1/4/2016 female NA NA NA NA ## 5 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 6 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 7 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 Note that in the output above cases with id variable values equal to 198 and 201 are no longer present. If you remove the ! in front of the filter variable, only cases 198 and 201 are retained. # Filter in id of 198 and 201 filterdf &lt;- subset(mergeddf, id %in% c(198,201)) # View filtered data frame filterdf ## # A tibble: 2 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 198 Morales Linda 1/7/2016 female 4.9 4.5 4.4 4.8 ## 2 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 You can also drop specific cases one by one using the not equal to operator (!=) and the a unique identifier value associated with the case you wish to remove. We accomplish the same result as above but use two steps instead. Also, note that in the second step below, the new data frame object (filterdf) is used as the first argument because we want to retain the changes we made in the prior step (i.e., dropping case with id equal to 198). # Filter out id of 198 filterdf &lt;- subset(mergeddf, id!=198) # Filter out id of 201 filterdf &lt;- subset(filterdf, id!=201) # View filtered data frame filterdf ## # A tibble: 7 x 9 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 153 Sanchez Alejandro 1/1/2016 male 3.9 4.8 4.9 5 ## 2 154 McDonald Ronald 1/9/2016 male NA NA NA NA ## 3 155 Smith John 1/9/2016 male NA NA NA NA ## 4 165 Doe Jane 1/4/2016 female NA NA NA NA ## 5 125 Franklin Benjamin 1/5/2016 male 2.1 1.9 2.1 2.3 ## 6 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 ## 7 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 When working with variables of type Date, things can get a bit trickier. When we applied the str function from base R (see above), we found that the startdate variable was read in and joined as a character variable as opposed to a date variable. As such, we need to convert the startdate variable using the as.Date function from base R. First, type the name of the data frame object (mergeddf), followed by the $ operator and the name of whatever you want to call the new variable (startdate2); remember, the $ operator tells R that a variable belongs to (or will belong to) a particular data frame. Second, type the &lt;- operator. Third, type the name of the as.Date function. Fourth, in the function parentheses, as the first argument, enter the as.character function with the name of the data frame object (mergeddf), followed by the $ operator and the name the original variable (startdate) as the sole argument. Fifth, as the second argument in the as.Date function, type format=\"%m/%d/%Y\" to indicate the format for the data variable; note that the capital Y in %Y implies a 4-digit year, whereas a lower case would imply a 2-digit year. # Convert character startdate variable to the Date type startdate2 variable mergeddf$startdate2 &lt;- as.Date(as.character(mergeddf$startdate), format=&quot;%m/%d/%Y&quot;) To verify that the new startdate2 variable is of type Date, use the str function from base R, and enter the name of the data frame object (mergeddf) as the sole argument. As you will see, the new startdate2 variable is now of type Date. # Verify that the startdate2 variable is now a variable of type Date str(mergeddf) ## spec_tbl_df[,10] [9 x 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ id : num [1:9] 153 154 155 165 125 111 198 201 282 ## $ lastname : chr [1:9] &quot;Sanchez&quot; &quot;McDonald&quot; &quot;Smith&quot; &quot;Doe&quot; ... ## $ firstname : chr [1:9] &quot;Alejandro&quot; &quot;Ronald&quot; &quot;John&quot; &quot;Jane&quot; ... ## $ startdate : chr [1:9] &quot;1/1/2016&quot; &quot;1/9/2016&quot; &quot;1/9/2016&quot; &quot;1/4/2016&quot; ... ## $ gender : chr [1:9] &quot;male&quot; &quot;male&quot; &quot;male&quot; &quot;female&quot; ... ## $ perf_q1 : num [1:9] 3.9 NA NA NA 2.1 3.3 4.9 1.2 2.2 ## $ perf_q2 : num [1:9] 4.8 NA NA NA 1.9 3.3 4.5 1.1 2.3 ## $ perf_q3 : num [1:9] 4.9 NA NA NA 2.1 3.4 4.4 1 2.4 ## $ perf_q4 : num [1:9] 5 NA NA NA 2.3 3.3 4.8 1 2.5 ## $ startdate2: Date[1:9], format: &quot;2016-01-01&quot; &quot;2016-01-09&quot; &quot;2016-01-09&quot; ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. id = col_double(), ## .. lastname = col_character(), ## .. firstname = col_character(), ## .. startdate = col_character(), ## .. gender = col_character() ## .. ) Now we are ready to filter using the new startdate2 variable. When specify the value of the startdate2 variable by which you wish to filter by, make sure to use the as.Date function once more with the date (formatted as YYYY-MM-DD) in quotation marks (\" \") as the sole argument. Here, I filter for those cases in which their startdate2 values are greater than 2016-01-07. # Filter by startdate2 filterdf &lt;- subset(mergeddf, startdate2 &gt; as.Date(&quot;2016-01-07&quot;)) # View filtered data frame print(filterdf) ## # A tibble: 5 x 10 ## id lastname firstname startdate gender perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 154 McDonald Ronald 1/9/2016 male NA NA NA NA 2016-01-09 ## 2 155 Smith John 1/9/2016 male NA NA NA NA 2016-01-09 ## 3 111 Newton Isaac 1/9/2016 male 3.3 3.3 3.4 3.3 2016-01-09 ## 4 201 Providence Cindy 1/9/2016 female 1.2 1.1 1 1 2016-01-09 ## 5 282 Legend John 1/9/2016 male 2.2 2.3 2.4 2.5 2016-01-09 19.0.2 Select Single Variable from Data Frame To display a single variable from a data frame in our Console, within the subset function, we can enter the data frame object as the first argument (filterdf) and select= followed by the name of a single variable (startdate). Using the &lt;- operator, we can create a new data frame object and assign the single variable to that new object. Here, Im calling this new object temp, as that signals to me that the object will be temporary and thus not used for subsequent operations. # Select only one variable from a data frame temp &lt;- subset(mergeddf, select=startdate) # Print data frame print(temp) ## # A tibble: 9 x 1 ## startdate ## &lt;chr&gt; ## 1 1/1/2016 ## 2 1/9/2016 ## 3 1/9/2016 ## 4 1/4/2016 ## 5 1/5/2016 ## 6 1/9/2016 ## 7 1/7/2016 ## 8 1/9/2016 ## 9 1/9/2016 19.0.3 Select Multiple Variables from Data Frame If our goal is to select multiple variables from a data frame (and remove all others), we can use the subset function as follows. As we did above, name new data frame object using the &lt;- operator, and here we will overwrite the filterdf objec we previously created. As the first argument in the subset function, type the name of your original data frame object (mergeddf). As the second argument, type select= followed by a vector of variable name you wish to select/retain. The order in which you enter the variable names will correspond to the order in which they appear in the new data frame object. Use the c (combine) function from base R with each variable name you wish to select as arguments separated by commas. # Select multiple variables filterdf &lt;- subset(mergeddf, select=c(id, gender, lastname, firstname)) # Print data frame print(filterdf) ## # A tibble: 9 x 4 ## id gender lastname firstname ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 153 male Sanchez Alejandro ## 2 154 male McDonald Ronald ## 3 155 male Smith John ## 4 165 female Doe Jane ## 5 125 male Franklin Benjamin ## 6 111 male Newton Isaac ## 7 198 female Morales Linda ## 8 201 female Providence Cindy ## 9 282 male Legend John 19.0.4 Remove Single Variable from Data Frame If you need to remove a single variable from a data frame, you can simply type the minus (-) operator before the name of the variable you wish to remove. # Select only one variable from a data frame filterdf &lt;- subset(mergeddf, select=-startdate) # Print data frame print(filterdf) ## # A tibble: 9 x 9 ## id lastname firstname gender perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 153 Sanchez Alejandro male 3.9 4.8 4.9 5 2016-01-01 ## 2 154 McDonald Ronald male NA NA NA NA 2016-01-09 ## 3 155 Smith John male NA NA NA NA 2016-01-09 ## 4 165 Doe Jane female NA NA NA NA 2016-01-04 ## 5 125 Franklin Benjamin male 2.1 1.9 2.1 2.3 2016-01-05 ## 6 111 Newton Isaac male 3.3 3.3 3.4 3.3 2016-01-09 ## 7 198 Morales Linda female 4.9 4.5 4.4 4.8 2016-01-07 ## 8 201 Providence Cindy female 1.2 1.1 1 1 2016-01-09 ## 9 282 Legend John male 2.2 2.3 2.4 2.5 2016-01-09 19.0.5 Remove Multiple Variables from Data Frame If you wish to remove multiple variables from a data frame, you can apply the same syntax as you did when selecting multiple variables, except insert a minus (-) operator in from the of the c function. This tells the function to not select those variables. Here, we remove the id and gender variables from the mergeddf data frame by overwriting the original mergeddf object. # Remove multiple variables mergeddf &lt;- subset(mergeddf, select= -c(id, gender)) # Print data frame print(mergeddf) ## # A tibble: 9 x 8 ## lastname firstname startdate perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 Sanchez Alejandro 1/1/2016 3.9 4.8 4.9 5 2016-01-01 ## 2 McDonald Ronald 1/9/2016 NA NA NA NA 2016-01-09 ## 3 Smith John 1/9/2016 NA NA NA NA 2016-01-09 ## 4 Doe Jane 1/4/2016 NA NA NA NA 2016-01-04 ## 5 Franklin Benjamin 1/5/2016 2.1 1.9 2.1 2.3 2016-01-05 ## 6 Newton Isaac 1/9/2016 3.3 3.3 3.4 3.3 2016-01-09 ## 7 Morales Linda 1/7/2016 4.9 4.5 4.4 4.8 2016-01-07 ## 8 Providence Cindy 1/9/2016 1.2 1.1 1 1 2016-01-09 ## 9 Legend John 1/9/2016 2.2 2.3 2.4 2.5 2016-01-09 Filter by Pattern Contained within String In some cases, we may wish to filter cases from a data frame object based on a pattern contained within a string (i.e., text, characters). For example, using the mergeddf data frame object we created above, perhaps we would like to select those cases for which their firstname string (i.e., value) contains a capital (J). To do so, we can use the str_detect function from the stringr package within either the subset function from base R or the filter function from the dplyr package. To get started, make sure that you have installed and accessed the stringr package. # Install stringr package if you haven&#39;t already # [Note: You don&#39;t need to install a package every # time you wish to access it] install.packages(&quot;stringr&quot;) # Access stringr package library(stringr) Given that this chapter supplement has focused thus far on the subset function from base R, lets continue to use that function, but please note that you could just as easily use the filter function from the dplyr package. Using the &lt;- operator, well assign the resulting subset data frame to an object that Im calling sub_mergeddf. To the right of the &lt;- operator, type the name of the subset function as usual, and as the first argument, type the name of the original data frame object that weve been working with called mergeddf. As the second argument, type the name of the str_detect function. As the first argument within the str_detect function, type the name of the variable we wish to filter by, which in this example is firstname; as the second argument and within quotation marks (\" \"), type a pattern you would like to detect within text strings from the firstname variable. For this example, lets detect any text string containing an uppercase J while noting that case sensitivity matters (e.g., J vs. j). In other words, we are filtering the data frame such that we will retain only those cases for which their firstname variable text strings (i.e., values) contain an uppercase J. # Select cases for which firstname variable contains a &quot;J&quot; # Note that case sensitivity matters (e.g., &quot;j&quot; vs. &quot;J&quot;) sub_mergeddf &lt;- subset(mergeddf, str_detect(firstname, &quot;J&quot;)) Now lets print the new data frame object we created. # Print the data frame object print(sub_mergeddf) ## # A tibble: 3 x 8 ## lastname firstname startdate perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 Smith John 1/9/2016 NA NA NA NA 2016-01-09 ## 2 Doe Jane 1/4/2016 NA NA NA NA 2016-01-04 ## 3 Legend John 1/9/2016 2.2 2.3 2.4 2.5 2016-01-09 Note how the str_detect function helped us retain only those cases for which firstname contained an uppercase J. Notably missing are the individuals named Alejandro and Benjamin because, although they have a j within their first names, their names contain a lowercase j as opposed to an uppercase J. Using the same code as above, lets swap out the uppercase J for a lowercase j. # Select cases for which firstname variable contains a &quot;j&quot; # Note that case sensitivity matters (e.g., &quot;j&quot; vs. &quot;J&quot;) sub_mergeddf &lt;- subset(mergeddf, str_detect(firstname, &quot;j&quot;)) # Print the data frame object print(sub_mergeddf) ## # A tibble: 2 x 8 ## lastname firstname startdate perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 Sanchez Alejandro 1/1/2016 3.9 4.8 4.9 5 2016-01-01 ## 2 Franklin Benjamin 1/5/2016 2.1 1.9 2.1 2.3 2016-01-05 Because we filtered for a lowercase j, now our data frame object only includes Benjamin and Alejandro. If you wish to retain only those cases for which the string begins with a particular pattern, use the ^ operator before the pattern. # Select cases for which firstname variable starts with a &quot;J&quot; sub_mergeddf &lt;- subset(mergeddf, str_detect(firstname, &quot;^J&quot;)) # Print the data frame object print(sub_mergeddf) ## # A tibble: 3 x 8 ## lastname firstname startdate perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 Smith John 1/9/2016 NA NA NA NA 2016-01-09 ## 2 Doe Jane 1/4/2016 NA NA NA NA 2016-01-04 ## 3 Legend John 1/9/2016 2.2 2.3 2.4 2.5 2016-01-09 To retain only those cases for which the string ends with a particular pattern, use the $ operator after the pattern. # Select cases for which firstname variable ends with a &quot;n&quot; sub_mergeddf &lt;- subset(mergeddf, str_detect(firstname, &quot;n$&quot;)) # Print the data frame object print(sub_mergeddf) ## # A tibble: 3 x 8 ## lastname firstname startdate perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 Smith John 1/9/2016 NA NA NA NA 2016-01-09 ## 2 Franklin Benjamin 1/5/2016 2.1 1.9 2.1 2.3 2016-01-05 ## 3 Legend John 1/9/2016 2.2 2.3 2.4 2.5 2016-01-09 To retain only those cases for which the string contains any of the elements from set of elements anywhere in the text, wrap the brackets [ ] operator around the set of pattern elements. # Select cases for which firstname contains any of the elements &quot;d&quot; or &quot;m&quot; sub_mergeddf &lt;- subset(mergeddf, str_detect(firstname, &quot;[dm]&quot;)) # Print the data frame object print(sub_mergeddf) ## # A tibble: 5 x 8 ## lastname firstname startdate perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 Sanchez Alejandro 1/1/2016 3.9 4.8 4.9 5 2016-01-01 ## 2 McDonald Ronald 1/9/2016 NA NA NA NA 2016-01-09 ## 3 Franklin Benjamin 1/5/2016 2.1 1.9 2.1 2.3 2016-01-05 ## 4 Morales Linda 1/7/2016 4.9 4.5 4.4 4.8 2016-01-07 ## 5 Providence Cindy 1/9/2016 1.2 1.1 1 1 2016-01-09 Finally, if you would like to retain only those cases for which the str_detect logical statements are FALSE, then you can insert the not (!) operator before the name of the function. # Select cases for which firstname does not contain any of the elements &quot;d&quot; or &quot;m&quot; sub_mergeddf &lt;- subset(mergeddf, ! str_detect(firstname, &quot;[dm]&quot;)) # Print the data frame object print(sub_mergeddf) ## # A tibble: 4 x 8 ## lastname firstname startdate perf_q1 perf_q2 perf_q3 perf_q4 startdate2 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 Smith John 1/9/2016 NA NA NA NA 2016-01-09 ## 2 Doe Jane 1/4/2016 NA NA NA NA 2016-01-04 ## 3 Newton Isaac 1/9/2016 3.3 3.3 3.4 3.3 2016-01-09 ## 4 Legend John 1/9/2016 2.2 2.3 2.4 2.5 2016-01-09 "],["references.html", "References", " References Ajzen, Icek. 1991. The Theory of Planned Behavior. Organizational Behavior and Human Decision Processes 50: 179211. Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2021. Rmarkdown: Dynamic Documents for r. https://CRAN.R-project.org/package=rmarkdown. Bache, Stefan Milton, and Hadley Wickham. 2020. Magrittr: A Forward-Pipe Operator for r. https://CRAN.R-project.org/package=magrittr. Basadur, Min, George B Graen, and Terri A Scandura. 1986. Training Effects on Attitudes Toward Divergent Thinking Among Manufacturing Engineers. Journal of Applied Psychology 71: 61217. Basadur, Min, Mark A Runco, and Luis A Vega. 2000. Understanding How Creative Thinking Skills, Attitudes and Behaviors Work Together: A Causal Process Model. Journal of Creative Behavior 34: 77100. Bauer, Talya N., Berrin Erdogan, David E. Caughlin, and Donald M. Truxillo. 2019. Human Resource Management: People, Data, and Analytics. Thousand Oaks, California: Sage. . 2020. Fundamentals of Human Resource Management: People, Data, and Analytics. Thousand Oaks, California: Sage. Chevallier, Arnaud. 2016. Strategic Thinking in Complex Problem Solving. New York, New York: Oxford University Press. Conn, Charles, and Robert McLean. 2018. Bulletproof Problem Solving: The One Skill That Changes Everything. Hoboken, New Jersey: Wiley. Deloitte. 2018. Global Human Capital Trends Report 2018. Westlake, Texas: Deloitte University Press. Gerbing, David. 2020. lessR: Less Code, More Results. https://CRAN.R-project.org/package=lessR. Muthn, B O, and L K Muthn. 1998-2018. Mplus Version 8.3. Los Angeles, California: Muthn &amp; Muthn. Pfeffer, Jeffrey. 1998. Seven Practices of Successful Organizations. California Management Review 40: 96124. R Core Team. 2021. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Reiter-Palmon, Roni, and Jody J Illies. 2004. Leadership and Creativity: Understanding Leadership from a Creative Problem-Solving Perspective. Leadership Quarterly 15: 5577. RStudio Team. 2020. RStudio: Integrated Development Environment for r. Boston, MA: RStudio, PBC. http://www.rstudio.com/. Wickham, Hadley. 2021. Tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy DAgostino McGowan, Romain Franois, Garrett Grolemund, et al. 2019. Welcome to the tidyverse. Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686. Wickham, Hadley, and Jennifer Bryan. 2019. Readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl. Wickham, Hadley, Romain Franois, Lionel Henry, and Kirill Mller. 2021. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr. Wickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Visualize, Model, Transform, Tidy, and Import Data. Sebastopol, California: OReilly Media, Inc. https://r4ds.had.co.nz/n. Wickham, Hadley, and Jim Hester. 2020. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr. Xie, Yihui. 2014. Knitr: A Comprehensive Tool for Reproducible Research in R. In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. . 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/. . 2016. Bookdown: Authoring Books and Technical Documents with R Markdown. Boca Raton, Florida: Chapman; Hall/CRC. https://github.com/rstudio/bookdown. . 2020. Bookdown: Authoring Books and Technical Documents with r Markdown. https://github.com/rstudio/bookdown. . 2021. Knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/. Xie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown. "]]
